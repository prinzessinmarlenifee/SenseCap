{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPSBbDmeNZiJIRRoP/MAE9E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prinzessinmarlenifee/SenseCap/blob/main/Data_Augmentation_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Vergleich Data Augmentation Factors"
      ],
      "metadata": {
        "id": "fDyXd_RnJLH5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Inhalt"
      ],
      "metadata": {
        "id": "W0xIaSh7VMsR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mehrere Modelle mit verschiedenen Augmentierungsgraden (augment_factor) vergleichen\n",
        "\n",
        "Modelle nicht immer neu trainieren ‚Äì lieber einmal speichern/laden\n",
        "\n",
        "Nicht nur Accuracy, sondern gezielt Precision & Recall f√ºr \"Action\" beobachten\n",
        "\n",
        "Eine sch√∂ne üìä Vergleichsgrafik zum Augmentierungsgrad\n",
        "\n",
        "\n",
        "üì¶ Zusammengefasst:\n",
        "Teil\tWas du brauchst\n",
        "\n",
        "üìÅ Modell-Dateien\t -  global_aug_factor_0.keras, global_aug_factor_1.keras, ...\n",
        "\n",
        "\n",
        "üìÑ Validierungsdaten - \tX_val.npy, y_val.npy\n",
        "\n",
        "\n",
        "üî° LabelEncoder\tlabel_encoder.pkl (oder neu erstellen bei gleichem Dataset)"
      ],
      "metadata": {
        "id": "nzuaW6FqVKqv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üß™ Schritt 1: Setup"
      ],
      "metadata": {
        "id": "7U0lIMOrVYdi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ue4ENBIzJDkD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.models import load_model\n",
        "import joblib  # falls du LabelEncoder gespeichert hast\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üìÇ Schritt 2: Pfade & Klassen setzen"
      ],
      "metadata": {
        "id": "cHfJm9AvVf8z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Anpassen auf dein Setup\n",
        "model_dir = \"/content/drive/MyDrive/mtb_project/final_models_global\"\n",
        "X_val_path = \"/content/drive/MyDrive/mtb_project/X_val.npy\"\n",
        "y_val_path = \"/content/drive/MyDrive/mtb_project/y_val.npy\"\n",
        "le_path = \"/content/drive/MyDrive/mtb_project/label_encoder.pkl\"  # wenn gespeichert, nach v4.2 f3 passiert\n",
        "\n",
        "# Laden\n",
        "X_val = np.load(X_val_path)\n",
        "y_val = np.load(y_val_path)\n",
        "le = joblib.load(le_path)\n"
      ],
      "metadata": {
        "id": "FQLyfF3XVhsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üîç Schritt 3: Analysefunktion"
      ],
      "metadata": {
        "id": "2W7VOVxWVqQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model_path, X_val, y_val, le, target_class=\"Action\"):\n",
        "    model = load_model(model_path)\n",
        "    y_pred_probs = model.predict(X_val, verbose=0)\n",
        "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "    report = classification_report(\n",
        "        y_val, y_pred,\n",
        "        target_names=le.classes_,\n",
        "        output_dict=True\n",
        "    )\n",
        "\n",
        "    # Optional anzeigen\n",
        "    print(f\"\\nüìÑ Report f√ºr {os.path.basename(model_path)}\")\n",
        "    print(classification_report(y_val, y_pred, target_names=le.classes_))\n",
        "\n",
        "    # Werte extrahieren\n",
        "    precision = report[target_class][\"precision\"]\n",
        "    recall = report[target_class][\"recall\"]\n",
        "    f1 = report[target_class][\"f1-score\"]\n",
        "    acc = report[\"accuracy\"]\n",
        "\n",
        "    return precision, recall, f1, acc\n"
      ],
      "metadata": {
        "id": "EKj5FK0yVpsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üîÅ Schritt 4: Alle Modelle evaluieren"
      ],
      "metadata": {
        "id": "mghg63ioVpRe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "augment_factors = [0, 1, 2, 3]  # oder mehr\n",
        "metrics_dict = {}\n",
        "\n",
        "for factor in augment_factors:\n",
        "    model_path = os.path.join(model_dir, f\"global_aug_factor_{factor}.keras\")\n",
        "    precision, recall, f1, acc = evaluate_model(model_path, X_val, y_val, le, target_class=\"Action\")\n",
        "    metrics_dict[factor] = {\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": f1,\n",
        "        \"accuracy\": acc\n",
        "    }\n"
      ],
      "metadata": {
        "id": "U_2Pfyb6V3SF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üìä Schritt 5: Plotten"
      ],
      "metadata": {
        "id": "5gN3N1IgV9hs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_metrics(metrics_dict):\n",
        "    factors = sorted(metrics_dict.keys())\n",
        "    precision = [metrics_dict[f][\"precision\"] for f in factors]\n",
        "    recall = [metrics_dict[f][\"recall\"] for f in factors]\n",
        "    f1 = [metrics_dict[f][\"f1\"] for f in factors]\n",
        "    acc = [metrics_dict[f][\"accuracy\"] for f in factors]\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(factors, precision, label=\"Precision (Action)\", marker=\"o\")\n",
        "    plt.plot(factors, recall, label=\"Recall (Action)\", marker=\"o\")\n",
        "    plt.plot(factors, f1, label=\"F1-Score (Action)\", marker=\"o\")\n",
        "    plt.plot(factors, acc, label=\"Accuracy (Overall)\", linestyle=\"--\", marker=\"x\")\n",
        "    plt.title(\"üìà Einfluss von Augmentierungsgrad auf Action-Klassifikation\")\n",
        "    plt.xlabel(\"Augmentierungsfaktor\")\n",
        "    plt.ylabel(\"Score\")\n",
        "    plt.ylim(0, 1.05)\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "sVd0xxTdV-CJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üéØ Plot starten\n",
        "plot_metrics(metrics_dict)\n"
      ],
      "metadata": {
        "id": "B3ObyCojWIdb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}