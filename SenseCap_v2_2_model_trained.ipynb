{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNzF6GaWrDAjctSwBB/lVJz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prinzessinmarlenifee/SenseCap/blob/main/SenseCap_v2_2_model_trained.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sjgPMqQLDD-q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Versuch 2: Fused Excel sheets ohne sync\n",
        "\n"
      ],
      "metadata": {
        "id": "hKNNiSrdDEqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hk6qFLbhDJlr",
        "outputId": "42c04301-6a0b-4f33-d61b-6df3dc9ec2d1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import packages\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "layers = tf.keras.layers\n",
        "models = tf.keras.models\n"
      ],
      "metadata": {
        "id": "OtTD-qyzDXoH"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- PARAMETER ---\n",
        "sampling_rate = 60       # 60 Hz nach SDI-Algorithmus\n",
        "window_size = 60         # 1 Sekunde = 60 Frames\n",
        "step_size = 30           # 50% Überlappung\n",
        "\n",
        "# Basisverzeichnis (sollte die 18 Session-Ordner enthalten)\n",
        "base_dir = '/content/drive/MyDrive/ML-MTB-Modell/IMU-Sessions/'\n"
      ],
      "metadata": {
        "id": "8d9oN1zpDqKo"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sessions einlesen"
      ],
      "metadata": {
        "id": "bcvlHHFOD36z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "session_dirs = sorted([\n",
        "    d for d in os.listdir(base_dir)\n",
        "    if os.path.isdir(os.path.join(base_dir, d))\n",
        "])\n",
        "print(f\"Gefundene Sessions: {len(session_dirs)} -> {session_dirs}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqMHmK7wD2YX",
        "outputId": "4b6ed95e-90bf-4e87-bf5e-f75b0288e016"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gefundene Sessions: 13 -> ['Session_01', 'Session_02', 'Session_03', 'Session_04', 'Session_05', 'Session_06', 'Session_07', 'Session_09', 'Session_10', 'Session_11', 'Session_12', 'Session_13', 'Session_14']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fuktionen zum LAbel-Parsing und Datei finden"
      ],
      "metadata": {
        "id": "8puFV7gaEAMI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5.1 parse_hot_labels: Liest die _hot.json-Datei ein, erstellt für jeden Frame ein Label\n",
        "def parse_hot_labels(json_path, total_frames):\n",
        "    with open(json_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "    entries = data['button_presses'].strip().split(';')\n",
        "\n",
        "    label_changes = []\n",
        "    for entry in entries:\n",
        "        if ':' in entry:\n",
        "            label, frame = entry.strip().split(':')\n",
        "            label = label.strip()\n",
        "            # Korrigiere evtl. \"Peadling\" → \"Pedaling\"\n",
        "            if label.lower() == 'peadling':\n",
        "                label = 'Pedaling'\n",
        "            label_changes.append((int(frame.strip()), label))\n",
        "\n",
        "    frame_labels = ['Unknown'] * total_frames\n",
        "    for i, (start_frame, label) in enumerate(label_changes):\n",
        "        end_frame = label_changes[i + 1][0] if i + 1 < len(label_changes) else total_frames\n",
        "        for f in range(start_frame, min(end_frame, total_frames)):\n",
        "            frame_labels[f] = label\n",
        "    return frame_labels\n",
        "\n",
        "# 5.2 find_sensor_file: Findet CSV-Datei, deren Name mit dem Prefix beginnt (Head_, Wrist_, Seat_)\n",
        "def find_sensor_file(folder, prefix):\n",
        "    for f in os.listdir(folder):\n",
        "        if f.lower().startswith(prefix.lower()):\n",
        "            return os.path.join(folder, f)\n",
        "    raise FileNotFoundError(f\"❌ Keine Datei mit Prefix '{prefix}' in {folder} gefunden.\")\n",
        "\n",
        "# 5.3 find_hot_file: Findet JSON-Datei, deren Name auf \"_hot.json\" endet\n",
        "def find_hot_file(folder):\n",
        "    for f in os.listdir(folder):\n",
        "        if f.lower().endswith('_hot.json'):\n",
        "            return os.path.join(folder, f)\n",
        "    raise FileNotFoundError(f\"❌ Keine Datei mit Suffix '_hot.json' in {folder} gefunden.\")\n"
      ],
      "metadata": {
        "id": "lo3wDSUeD-TT"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Fensterung für drei Sensoren kombinieren"
      ],
      "metadata": {
        "id": "FYZhfgCTESe4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def window_data_multiple_sensors(head_data, wrist_data, seat_data, frame_labels):\n",
        "    X_windows, y_windows = [], []\n",
        "    total_frames = len(frame_labels)\n",
        "\n",
        "    # Annahme: head_data, wrist_data, seat_data haben alle dieselbe Anzahl Zeilen = total_frames\n",
        "    for start in range(0, total_frames - window_size + 1, step_size):\n",
        "        end = start + window_size\n",
        "\n",
        "        win_h = head_data[start:end]    # (window_size, 6)\n",
        "        win_w = wrist_data[start:end]\n",
        "        win_s = seat_data[start:end]\n",
        "        window = np.concatenate([win_h, win_w, win_s], axis=1)  # → (window_size, 18)\n",
        "\n",
        "        label_window = frame_labels[start:end]\n",
        "        dominant_label = Counter(label_window).most_common(1)[0][0]\n",
        "        if dominant_label == 'Unknown':\n",
        "            continue\n",
        "\n",
        "        X_windows.append(window)\n",
        "        y_windows.append(dominant_label)\n",
        "\n",
        "    return np.array(X_windows), np.array(y_windows)\n"
      ],
      "metadata": {
        "id": "_RKQP4OGEKi5"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#debug\n",
        "print(f\"🔍 Session {sess_dir} → Fenster: {len(X_win)}, Shape: {X_win.shape if len(X_win) > 0 else 'n/a'}\")\n"
      ],
      "metadata": {
        "id": "zBEtLxfeeqLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_csv_headers(path, label):\n",
        "    with open(path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "    print(f\"\\n📋 {label} → Datei: {os.path.basename(path)}\")\n",
        "    print(\"   Zeile 0:\", lines[0].strip())\n",
        "    print(\"   Zeile 1:\", lines[1].strip())\n",
        "\n",
        "print_csv_headers(head_path, 'Head')\n",
        "print_csv_headers(wrist_path, 'Wrist')\n",
        "print_csv_headers(seat_path, 'Seat')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9aYhfR4i7aA3",
        "outputId": "488d5977-ac0c-48b0-b2c4-20bcc9365f63"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📋 Head → Datei: Head_D422CD004576_20230801_075834.csv\n",
            "   Zeile 0: PacketCounter,SampleTimeFine,Euler_X,Euler_Y,Euler_Z,Acc_X,Acc_Y,Acc_Z,Gyr_X,Gyr_Y,Gyr_Z,\n",
            "   Zeile 1: 0, 416010770, -4.522172451019287, 48.04213333129883, 21.0351619720459, 0, 0, 0, 0, 0, 0,\n",
            "\n",
            "📋 Wrist → Datei: Wrist_D422CD004550_20230801_075834.csv\n",
            "   Zeile 0: PacketCounter,SampleTimeFine,Euler_X,Euler_Y,Euler_Z,Acc_X,Acc_Y,Acc_Z,Gyr_X,Gyr_Y,Gyr_Z,\n",
            "   Zeile 1: 0, 532295258, -42.42717361450195, 45.996009826660156, -55.192440032958984, 0, 0, 0, 0, 0, 0,\n",
            "\n",
            "📋 Seat → Datei: Seat_D422CD00456D_20230801_075834.csv\n",
            "   Zeile 0: PacketCounter,SampleTimeFine,Euler_X,Euler_Y,Euler_Z,Acc_X,Acc_Y,Acc_Z,Gyr_X,Gyr_Y,Gyr_Z\n",
            "   Zeile 1: 0,409881162,2202328491210930,-6035955047607420,-8357672119140620,0.00000000000000,0.00000000000000,0.00000000000000,0.00000000000000,0.00000000000000,0.00000000000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#7. Daten einlesen und Fenster / Labels erzeugen\n",
        "→ Nach Ausführung siehst du für jede Session etwa: “→ 153 Fenster, 3 Klassen” etc."
      ],
      "metadata": {
        "id": "yjBHXCZBEaWp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Vorbereitung\n",
        "sessions_X = []\n",
        "sessions_y = []\n",
        "valid_sessions = []  # <- neue Liste! mit nur valid sessions\n",
        "skipped_sessions = []\n",
        "\n",
        "#features definieren:\n",
        "features = ['Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z']\n",
        "\n",
        "#Funktionen für Daten einlesen\n",
        "def smart_feature_filter(df):\n",
        "    # alles lowercase und leerzeichenfrei vergleichen\n",
        "    keep = [col for col in df.columns if any(kw in col.lower() for kw in ['euler', 'acc', 'gyr'])]\n",
        "    return df[keep]\n",
        "\n",
        "def print_csv_headers(path, label):\n",
        "    with open(path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "    print(f\"\\n📋 {label} → Datei: {os.path.basename(path)}\")\n",
        "    print(\"   Zeile 0:\", lines[0].strip())\n",
        "    print(\"   Zeile 1:\", lines[1].strip())\n",
        "\n",
        "\n",
        "def inspect_sensor_csv(path):\n",
        "    df = pd.read_csv(path, sep=',', skiprows=1)\n",
        "    df.columns = df.columns.str.strip()\n",
        "    print(f\"📊 {os.path.basename(path)}: {df.shape[1]} Spalten\")\n",
        "    print(\"   → Spaltennamen:\", df.columns.tolist())\n",
        "\n",
        "\n",
        "#def load_sensor_csv(path, expected_columns=None):\n",
        " # df = pd.read_csv(path, sep=',', skiprows=1)\n",
        "  #df.columns = df.columns.str.strip()\n",
        "  #if expected_columns:\n",
        "   #   df = df[expected_columns]\n",
        "#  df = df.apply(pd.to_numeric, errors='coerce').fillna(0).astype(np.float32)\n",
        " # return df.values\n",
        "\n",
        "\n",
        "#def load_sensor_csv(path):\n",
        "#    df = pd.read_csv(path, sep=',', skiprows=1)\n",
        "#    df.columns = df.columns.str.strip()\n",
        "#    df = smart_feature_filter(df)\n",
        "#    df = df.apply(pd.to_numeric, errors='coerce').fillna(0).astype(np.float32)\n",
        "#    return df.values\n",
        "\n",
        "\n",
        "def load_sensor_csv(path):\n",
        "  import csv\n",
        "\n",
        "  # Erste zwei Zeilen lesen\n",
        "  with open(path, 'r') as f:\n",
        "      reader = csv.reader(f)\n",
        "      first_line = next(reader)\n",
        "      second_line = next(reader)\n",
        "\n",
        "  # Prüfen ob erste Zeile ein Header ist (z. B. mit bekannten Schlüsselwörtern)\n",
        "  first_line_str = \",\".join(first_line).lower()\n",
        "  if any(kw in first_line_str for kw in ['euler', 'acc', 'gyr']):\n",
        "      skip = 0\n",
        "  else:\n",
        "      skip = 1\n",
        "\n",
        "  # Einlesen\n",
        "  df = pd.read_csv(path, sep=',', skiprows=skip)\n",
        "  df.columns = df.columns.str.strip()\n",
        "\n",
        "  # Features filtern\n",
        "  df = smart_feature_filter(df)\n",
        "\n",
        "  # Numerisch umwandeln und NaN behandeln\n",
        "  df = df.apply(pd.to_numeric, errors='coerce').fillna(0).astype(np.float32)\n",
        "\n",
        "      return df.values\n",
        "\n",
        "print(f\"🔍 {os.path.basename(path)}: Header {'erste Zeile' if skip==0 else 'zweite Zeile'}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# --- Hauptschleife ---\n",
        "for sess_dir in session_dirs:\n",
        "    print(f\"\\n📂 Lade Session: {sess_dir}\")\n",
        "    session_path = os.path.join(base_dir, sess_dir)\n",
        "\n",
        "\n",
        "    # 7.1 Sensor-Dateien finden\n",
        "    head_path  = find_sensor_file(session_path, 'Head_')\n",
        "    wrist_path = find_sensor_file(session_path, 'Wrist_')\n",
        "    seat_path  = find_sensor_file(session_path, 'Seat_')\n",
        "\n",
        "    # 7.2 Hot-JSON-Datei finden\n",
        "    hot_path = find_hot_file(session_path)\n",
        "\n",
        "    inspect_sensor_csv(head_path)\n",
        "    inspect_sensor_csv(wrist_path)\n",
        "    inspect_sensor_csv(seat_path)\n",
        "\n",
        "\n",
        "    #print csv-heads for debugging & checking (oben definierte function print_csv_headers)\n",
        "    #print_csv_headers(head_path, 'Head')\n",
        "    #print_csv_headers(wrist_path, 'Wrist')\n",
        "    #print_csv_headers(seat_path, 'Seat')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # 7.3 IMU-Daten laden\n",
        "    #funktion um imu laden\n",
        "    #aktuelles Problem: header in der zweiten Zeile, seperator ',' , erkennt nur zwei spalten beim einlesen\n",
        "\n",
        "\n",
        "\n",
        "    head_data  = load_sensor_csv(head_path)\n",
        "    wrist_data = load_sensor_csv(wrist_path)\n",
        "    seat_data  = load_sensor_csv(seat_path)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    print(f\"📊 Sensorlängen: Head={head_data.shape}, Wrist={wrist_data.shape}, Seat={seat_data.shape}\")\n",
        "\n",
        "    #expected_features = 27  # 3 Sensoren × 9 Features (oben definiert)\n",
        "   # if X_win.shape[1:] != (window_size, expected_features):\n",
        "    #      print(f\"⚠️ Session {sess_dir} hat Format {X_win.shape[1:]}, wird übersprungen.\")\n",
        "     #     skipped_sessions.append(sess_dir)\n",
        "      #    continue\n",
        "\n",
        "    expected_features = 27  # oder dynamisch: head_data.shape[1] * 3\n",
        "\n",
        "    if X_win.shape[1:] != (window_size, expected_features):\n",
        "        print(f\"⚠️  Session {sess_dir} hat Format {X_win.shape[1:]}, wird übersprungen.\")\n",
        "        skipped_sessions.append(sess_dir)\n",
        "        continue\n",
        "\n",
        "    #7.4 Labels laden\n",
        "    total_frames = min(head_data.shape[0], wrist_data.shape[0], seat_data.shape[0])\n",
        "    frame_labels = parse_hot_labels(hot_path, total_frames)\n",
        "\n",
        "    # 7.5 ALLE gleich lang schneiden #sonst-Fehler, erstmal Sicherehitskürzung, später mit sync-datei arbeiten\n",
        "    min_len = min(len(head_data), len(wrist_data), len(seat_data))\n",
        "    head_data  = head_data[:min_len]\n",
        "    wrist_data = wrist_data[:min_len]\n",
        "    seat_data  = seat_data[:min_len]\n",
        "    frame_labels = frame_labels[:min_len]\n",
        "\n",
        "    # 7.5 Sicherheitskürzung (später optional mit synch.json ersetzen)\n",
        "    head_data  = head_data[:total_frames]\n",
        "    wrist_data = wrist_data[:total_frames]\n",
        "    seat_data  = seat_data[:total_frames]\n",
        "    frame_labels = frame_labels[:total_frames]\n",
        "\n",
        "    # 7.6 Fensterung & Label-Zuweisung\n",
        "    X_win, y_win = window_data_multiple_sensors(head_data, wrist_data, seat_data, frame_labels)\n",
        "\n",
        "    # 5. Gültigkeit prüfen\n",
        "    if len(X_win) == 0:\n",
        "        print(f\"⚠️  Session {sess_dir} übersprungen – keine gültigen Fenster.\")\n",
        "        skipped_sessions.append(sess_dir)\n",
        "        continue\n",
        "\n",
        "    if X_win.shape[1:] != (window_size, expected_features):\n",
        "        print(f\"⚠️  Session {sess_dir} hat Format {X_win.shape[1:]}, wird übersprungen.\")\n",
        "        skipped_sessions.append(sess_dir)\n",
        "        continue\n",
        "\n",
        "        # 6. Speichern\n",
        "    sessions_X.append(X_win)\n",
        "    sessions_y.append(y_win)\n",
        "    valid_sessions.append(sess_dir)\n",
        "    print(f\"✅ Session {sess_dir}: {len(X_win)} Fenster, {len(np.unique(y_win))} Klassen\")\n",
        "\n",
        "# --- Zusammenfassung ---\n",
        "print(\"\\n✅ Verwendete Sessions:\")\n",
        "for idx, sess in enumerate(valid_sessions):\n",
        "    print(f\"  {sess}: {sessions_X[idx].shape}\")\n",
        "\n",
        "if skipped_sessions:\n",
        "    print(\"\\n⛔️ Übersprungene Sessions:\")\n",
        "    for s in skipped_sessions:\n",
        "        print(f\"  {s}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hAmaAMFEKM_",
        "outputId": "5c093e8a-0977-4afa-9e9b-23a54909b9ad"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📂 Lade Session: Session_01\n",
            "📊 Head_D422CD00563B_20230713_082527.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Wrist_D422CD004550_20230713_082527.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Seat_D422CD00456D_20230713_082527.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Sensorlängen: Head=(60077, 9), Wrist=(60078, 9), Seat=(60075, 9)\n",
            "✅ Session Session_01: 1997 Fenster, 3 Klassen\n",
            "\n",
            "📂 Lade Session: Session_02\n",
            "📊 Head_D422CD00563B_20230713_085629.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Wrist_D422CD004550_20230713_085629.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Seat_D422CD00456D_20230713_085629.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Sensorlängen: Head=(48792, 9), Wrist=(48792, 9), Seat=(48784, 9)\n",
            "✅ Session Session_02: 1621 Fenster, 3 Klassen\n",
            "\n",
            "📂 Lade Session: Session_03\n",
            "📊 Head_D422CD00563B_20230713_092642.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Wrist_D422CD004550_20230713_092642.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Seat_D422CD00456D_20230713_092642.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Sensorlängen: Head=(42308, 9), Wrist=(42305, 9), Seat=(42307, 9)\n",
            "✅ Session Session_03: 1407 Fenster, 3 Klassen\n",
            "\n",
            "📂 Lade Session: Session_04\n",
            "📊 Head_D422CD00563B_20230717_070932.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Wrist_D422CD004550_20230717_070932.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Seat_D422CD00456D_20230717_070932.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Sensorlängen: Head=(56013, 9), Wrist=(56019, 9), Seat=(56015, 9)\n",
            "✅ Session Session_04: 1864 Fenster, 3 Klassen\n",
            "\n",
            "📂 Lade Session: Session_05\n",
            "📊 Head_D422CD00563B_20230717_070932.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Wrist_D422CD004550_20230717_070932.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Seat_D422CD00456D_20230717_070932.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Sensorlängen: Head=(56013, 9), Wrist=(56019, 9), Seat=(56015, 9)\n",
            "✅ Session Session_05: 1858 Fenster, 4 Klassen\n",
            "\n",
            "📂 Lade Session: Session_06\n",
            "📊 Head_D422CD00563B_20230720_074713.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Wrist_D422CD004550_20230720_074713.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Seat_D422CD00456D_20230720_074713.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Sensorlängen: Head=(64027, 9), Wrist=(64026, 9), Seat=(64025, 9)\n",
            "✅ Session Session_06: 2116 Fenster, 4 Klassen\n",
            "\n",
            "📂 Lade Session: Session_07\n",
            "📊 Head_D422CD00563B_20230720_082728.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Wrist_D422CD004550_20230720_082728.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Seat_D422CD00456D_20230720_082728.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Sensorlängen: Head=(59920, 9), Wrist=(59917, 9), Seat=(59921, 9)\n",
            "✅ Session Session_07: 1991 Fenster, 4 Klassen\n",
            "\n",
            "📂 Lade Session: Session_09\n",
            "📊 Head_D422CD00563B_20230724_072319.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Wrist_D422CD004550_20230724_072319.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Seat_D422CD00456D_20230724_072319.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Sensorlängen: Head=(59464, 9), Wrist=(59465, 9), Seat=(59468, 9)\n",
            "✅ Session Session_09: 1979 Fenster, 4 Klassen\n",
            "\n",
            "📂 Lade Session: Session_10\n",
            "📊 Head_D422CD004576_20230725_070718.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Wrist_D422CD004550_20230725_070718.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Seat_D422CD00456D_20230725_070718.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Sensorlängen: Head=(62167, 9), Wrist=(62163, 9), Seat=(62163, 9)\n",
            "✅ Session Session_10: 2061 Fenster, 4 Klassen\n",
            "\n",
            "📂 Lade Session: Session_11\n",
            "📊 Head_D422CD004576_20230727_073528.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-54-a79cdf4e430f>:25: DtypeWarning: Columns (5,6,7,8,9,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(path, sep=',', skiprows=1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Wrist_D422CD004550_20230727_073528.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-54-a79cdf4e430f>:25: DtypeWarning: Columns (5,6,7,8,9,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(path, sep=',', skiprows=1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Seat_D422CD00456D_20230727_073528.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-54-a79cdf4e430f>:41: DtypeWarning: Columns (5,6,7,8,9,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(path, sep=',', skiprows=1)\n",
            "<ipython-input-54-a79cdf4e430f>:41: DtypeWarning: Columns (5,6,7,8,9,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(path, sep=',', skiprows=1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Sensorlängen: Head=(65763, 9), Wrist=(65763, 9), Seat=(65763, 9)\n",
            "✅ Session Session_11: 2181 Fenster, 4 Klassen\n",
            "\n",
            "📂 Lade Session: Session_12\n",
            "📊 Head_D422CD004576_20230801_075834.csv: 12 Spalten\n",
            "   → Spaltennamen: ['0', '416010770', '-4.522172451019287', '48.04213333129883', '21.0351619720459', '0', '0.1', '0.2', '0.3', '0.4', '0.5', '']\n",
            "📊 Wrist_D422CD004550_20230801_075834.csv: 12 Spalten\n",
            "   → Spaltennamen: ['0', '532295258', '-42.42717361450195', '45.996009826660156', '-55.192440032958984', '0', '0.1', '0.2', '0.3', '0.4', '0.5', '']\n",
            "📊 Seat_D422CD00456D_20230801_075834.csv: 11 Spalten\n",
            "   → Spaltennamen: ['0', '409881162', '2202328491210930', '-6035955047607420', '-8357672119140620', '0.00000000000000', '0.00000000000000.1', '0.00000000000000.2', '0.00000000000000.3', '0.00000000000000.4', '0.00000000000000.5']\n",
            "📊 Sensorlängen: Head=(59522, 0), Wrist=(59523, 0), Seat=(59513, 0)\n",
            "⚠️  Session Session_12 hat Format (60, 0), wird übersprungen.\n",
            "\n",
            "📂 Lade Session: Session_13\n",
            "📊 Head_D422CD004576_20230802_080027.csv: 12 Spalten\n",
            "   → Spaltennamen: ['0', '209493532', '-7.16727876663208', '47.413570404052734', '-87.12100219726562', '0', '0.1', '0.2', '0.3', '0.4', '0.5', '']\n",
            "📊 Wrist_D422CD004550_20230802_080027.csv: 12 Spalten\n",
            "   → Spaltennamen: ['0', '358144070', '-41.73847198486328', '23.458871841430664', '-68.4642105102539', '0', '0.1', '0.2', '0.3', '0.4', '0.5', '']\n",
            "📊 Seat_D422CD00456D_20230802_080027.csv: 11 Spalten\n",
            "   → Spaltennamen: ['0', '435628135', '199753963947296', '-6415881347656250', '-16434582519531200', '0.00000000000000', '0.00000000000000.1', '0.00000000000000.2', '0.00000000000000.3', '0.00000000000000.4', '0.00000000000000.5']\n",
            "📊 Sensorlängen: Head=(65045, 0), Wrist=(66493, 0), Seat=(65036, 0)\n",
            "⚠️  Session Session_13 hat Format (60, 0), wird übersprungen.\n",
            "\n",
            "📂 Lade Session: Session_14\n",
            "📊 Head_D422CD004576_20230803_073423.csv: 12 Spalten\n",
            "   → Spaltennamen: ['0', '23311239', '5.965623378753662', '-45.560245513916016', '164.4220428466797', '0', '0.1', '0.2', '0.3', '0.4', '0.5', '']\n",
            "📊 Wrist_D422CD004550_20230803_073423.csv: 12 Spalten\n",
            "   → Spaltennamen: ['0', '177062498', '78.41714477539062', '7.847972869873047', '119.1408920288086', '0', '0.1', '0.2', '0.3', '0.4', '0.5', '']\n",
            "📊 Seat_D422CD00456D_20230803_073423.csv: 11 Spalten\n",
            "   → Spaltennamen: ['0', '310191965', '7921337127685540', '-2267286872863770', '-12943373107910100', '0.00000000000000', '0.00000000000000.1', '0.00000000000000.2', '0.00000000000000.3', '0.00000000000000.4', '0.00000000000000.5']\n",
            "📊 Sensorlängen: Head=(58096, 0), Wrist=(58095, 0), Seat=(58085, 0)\n",
            "⚠️  Session Session_14 hat Format (60, 0), wird übersprungen.\n",
            "\n",
            "✅ Verwendete Sessions:\n",
            "  Session_01: (1997, 60, 27)\n",
            "  Session_02: (1621, 60, 27)\n",
            "  Session_03: (1407, 60, 27)\n",
            "  Session_04: (1864, 60, 27)\n",
            "  Session_05: (1858, 60, 27)\n",
            "  Session_06: (2116, 60, 27)\n",
            "  Session_07: (1991, 60, 27)\n",
            "  Session_09: (1979, 60, 27)\n",
            "  Session_10: (2061, 60, 27)\n",
            "  Session_11: (2181, 60, 27)\n",
            "\n",
            "⛔️ Übersprungene Sessions:\n",
            "  Session_12\n",
            "  Session_13\n",
            "  Session_14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "🧠 Dann ist deine Fensterform:\n",
        "\n",
        "    3 Sensoren × 9 Spalten = 27 Features\n",
        "    → Fenster-Shape: (window_size, 27) = (60, 27)\n",
        "\n",
        "\n",
        "Euler_X, Euler_Y, Euler_Z\n",
        "\n",
        "\n",
        "Acc_X, Acc_Y, Acc_Z\n",
        "\n",
        "Gyr_X, Gyr_Y, Gyr_Z\n",
        "\n",
        "→ = 9 physikalisch sinnvolle Spalten pro Sensor"
      ],
      "metadata": {
        "id": "VEmZyAMMpyKX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Debug:shape der daten anzeigen\n",
        "\n",
        "print(\"\\n✅ Preprocessing abgeschlossen. Shape jeder Session:\")\n",
        "for idx, sess in enumerate(session_dirs):\n",
        "    print(f\"{sess}: {sessions_X[idx].shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "wNATwmB6JMDe",
        "outputId": "c5c95091-8e8f-4a79-8f36-9a5a466c27c3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Preprocessing abgeschlossen. Shape jeder Session:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "list index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-cae79fa8bc0b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n✅ Preprocessing abgeschlossen. Shape jeder Session:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession_dirs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{sess}: {sessions_X[idx].shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#8. Leave-one-session-out: Training and Evaluation"
      ],
      "metadata": {
        "id": "8szKmR2qE5RI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import os\n",
        "\n",
        "# Sicherstellen, dass der Ordner existiert\n",
        "checkpoint_dir = \"/content/drive/MyDrive/ML-MTB-Modell/ML-Modell_Checkpoints_saved\"\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "# Callback definieren\n",
        "checkpoint_cb = ModelCheckpoint(\n",
        "    filepath=os.path.join(checkpoint_dir, \"model_epoch_{epoch:02d}.h5\"),\n",
        "    save_best_only=False,  # oder True, wenn du nur das beste Modell behalten willst\n",
        "    save_weights_only=False,  # True, wenn du nur Gewichte speichern willst\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "all_accuracies = []\n",
        "accuracy_summary = {'Session': [], 'Accuracy': []}\n",
        "\n",
        "for test_idx in range(len(sessions_X)):\n",
        "    sess_name = session_dirs[test_idx]\n",
        "    print(f\"\\n📌 Teste auf Session (unbekannt): {sess_name} ({test_idx+1}/{len(sessions_X)})\")\n",
        "\n",
        "    # 8.1 Test-Daten definieren\n",
        "    X_test = sessions_X[test_idx]\n",
        "    y_test = sessions_y[test_idx]\n",
        "\n",
        "\n",
        "\n",
        "    # 8.2 Train-Daten: alle anderen Sessions zusammenschneiden\n",
        "    X_train = np.concatenate([x for i, x in enumerate(sessions_X) if i != test_idx])\n",
        "    y_train = np.concatenate([y for i, y in enumerate(sessions_y) if i != test_idx])\n",
        "\n",
        "    # 8.3 Label-Encoding (fit auf Trainingsdaten, transform auf beides)\n",
        "    le = LabelEncoder()\n",
        "    y_train_enc = le.fit_transform(y_train)\n",
        "    y_test_enc = le.transform(y_test)\n",
        "\n",
        "    # 8.4 Modell-Definition: CNN + LSTM\n",
        "    model = models.Sequential([\n",
        "        layers.Conv1D(64, 3, activation='relu', input_shape=X_train.shape[1:]),\n",
        "        layers.Conv1D(64, 3, activation='relu'),\n",
        "        layers.MaxPooling1D(pool_size=2),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.LSTM(64),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(100, activation='relu'),\n",
        "        layers.Dense(len(le.classes_), activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    # 8.5 Training (mit 10 % Validierungssplit aus Trainingsdaten)\n",
        "\n",
        "    # mit checkpoints zum speichern\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_val, y_val),\n",
        "        epochs=50,\n",
        "        batch_size=64,\n",
        "        callbacks=[checkpoint_cb]\n",
        "    )\n",
        "\n",
        "    # 8.6 Evaluation auf Test-Session\n",
        "    test_loss, test_acc = model.evaluate(X_test, y_test_enc, verbose=0)\n",
        "    print(f\"✅ Test-Accuracy für {sess_name}: {test_acc:.2f}\")\n",
        "    all_accuracies.append(test_acc)\n",
        "    accuracy_summary['Session'].append(sess_name)\n",
        "    accuracy_summary['Accuracy'].append(test_acc)\n",
        "\n",
        "    # 8.7 Klassifikationsbericht & Confusion Matrix\n",
        "    y_pred_probs = model.predict(X_test, verbose=0)\n",
        "    y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "    print(\"\\nKlassifikationsbericht:\")\n",
        "    print(classification_report(y_test_enc, y_pred_classes, target_names=le.classes_))\n",
        "\n",
        "    cm = confusion_matrix(y_test_enc, y_pred_classes)\n",
        "    disp = ConfusionMatrixDisplay(cm, display_labels=le.classes_)\n",
        "    disp.plot(xticks_rotation=45)\n",
        "    plt.title(f\"Confusion Matrix – {sess_name}\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "zlJAElwcE1L8",
        "outputId": "570ac0d4-8aa2-4d82-c74e-738f701bccc6"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📌 Teste auf Session (unbekannt): Session_01 (1/10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_val' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-5c29a82e8bc1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m     history = model.fit(\n\u001b[1;32m     64\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_val' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#💾 II. Modell speichern & später wieder laden (z. B. nach Training)\n",
        "\n",
        "##🔐 Speichern mit TensorFlow/**Keras**"
      ],
      "metadata": {
        "id": "rbaE9UFeMQ8r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Nach dem Training:\n",
        "#model.save(\"SenseCap_Eventdetection_Model.keras\")  # speichert nur in colab kurzzeitig\n",
        "model.save(\"/content/drive/MyDrive/ML-MTB-Modell/ML-Model_trained/SenseCap_Eventdetection_Model1.keras\")\n"
      ],
      "metadata": {
        "id": "9f0wu8rYM2P3"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##🔄 Laden\n",
        "\n",
        "Das speichert das gesamte Modell inkl. Architektur, Gewichten und Optimizer-Zustand –exakt da weitermachen, wo man aufgehört hast."
      ],
      "metadata": {
        "id": "Fe6SLk39NNOz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model(\"/content/drive/MyDrive/ML-MTB-Modell/ML-Model_trained/SenseCap_Eventdetection_Model1.keras\")\n"
      ],
      "metadata": {
        "id": "puTdBnHsNHsC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}