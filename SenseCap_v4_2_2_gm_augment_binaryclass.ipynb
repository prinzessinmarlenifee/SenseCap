{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prinzessinmarlenifee/SenseCap/blob/main/SenseCap_v4_2_2_gm_augment_binaryclass.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKNNiSrdDEqF"
      },
      "source": [
        "#Global Model with Binary Encoding & Data Augmentation\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qn46efPvFmfQ"
      },
      "source": [
        "##‚úÖ Ziel: Binary Classification\n",
        "\n",
        "    Action ‚Üí Positive Klasse (1)\n",
        "\n",
        "    Resting, Pushing, Pedaling ‚Üí Negative Klasse (0)\n",
        "\n",
        "    Damit erkennt das Modell gezielt nur ‚Äûechte Actions‚Äú, die sp√§ter f√ºr Highlights relevant sind."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kH_IAOvdE6R6"
      },
      "source": [
        "###Short Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cu32jcj0DpaS"
      },
      "source": [
        "Saving model and checkpoints for Zwischenspeicherung\n",
        "\n",
        "CSV-sensor data sheet\n",
        "1.   wrist\n",
        "2.   seat\n",
        "3.  head\n",
        "-> 3 Sensoren, 9 Spalten\n",
        "-> checkt erste und zweite Zeile f√ºr header (da unterschiedlich)\n",
        "\n",
        "*   hot encoding for labeling\n",
        " Action, Pedaling, Resting, Pushing\n",
        "\n",
        " Summary at end with\n",
        "\n",
        "\n",
        "*   test accuracy\n",
        "*   confusion matrix\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "all data is stored in Drive\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXQYTbV4RFPd"
      },
      "source": [
        "##Model Choice\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9xflzJBFK5z"
      },
      "source": [
        "‚úÖ Teil 2: Ist CNN + LSTM eine gute Architektur f√ºr IMU-Zeitreihendaten?\n",
        "\n",
        "Ja, das ist eine bew√§hrte Kombination ‚Äì besonders bei IMU-Daten (z.‚ÄØB. Accelerometer/Gyroscope), weil:\n",
        "üîé Warum CNN?\n",
        "\n",
        "    Erkennt lokale Muster in kurzen Zeitfenstern (z.‚ÄØB. Bewegungsphasen)\n",
        "\n",
        "    Spart Rechenzeit, da es weniger Parameter hat als ein reines LSTM\n",
        "\n",
        "üîÅ Warum LSTM?\n",
        "\n",
        "    Erkennt zeitliche Abh√§ngigkeiten (z.‚ÄØB. Bewegungsabfolgen)\n",
        "\n",
        "    Ideal f√ºr sequentielle Daten, wie du sie hast\n",
        "\n",
        "‚úÖ Alternativen oder Erweiterungen\n",
        "\n",
        "Falls du sp√§ter mehr Leistung brauchst:\n",
        "\n",
        "    Bidirectional LSTM ‚Üí besser f√ºr symmetrische Bewegungsabfolgen\n",
        "\n",
        "    Residual CNN Blocks ‚Üí f√ºr tiefere Netzwerke\n",
        "\n",
        "    Transformer ‚Üí wenn du sehr viele Daten und lange Sequenzen hast"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-84PMXWFN6N"
      },
      "source": [
        "##Setup and Prep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "id": "Hk6qFLbhDJlr",
        "outputId": "d81e6d9b-25db-44cc-fd26-d90b93038eb2"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Mountpoint must not already contain files",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-c8841ca53dd3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# mount drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    197\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mountpoint must not be a symlink'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mountpoint must not already contain files'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mountpoint must either be a directory or not exist'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Mountpoint must not already contain files"
          ]
        }
      ],
      "source": [
        "# mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OtTD-qyzDXoH"
      },
      "outputs": [],
      "source": [
        "#import packages\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "layers = tf.keras.layers\n",
        "models = tf.keras.models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8d9oN1zpDqKo"
      },
      "outputs": [],
      "source": [
        "# --- PARAMETER ---\n",
        "sampling_rate = 60       # 60 Hz nach SDI-Algorithmus\n",
        "window_size = 60         # 1 Sekunde = 60 Frames\n",
        "step_size = 30           # 50% √úberlappung\n",
        "\n",
        "# Basisverzeichnis (sollte die 18 Session-Ordner enthalten)\n",
        "base_dir = '/content/drive/MyDrive/ML-MTB-Modell/IMU-Sessions/'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcvlHHFOD36z"
      },
      "source": [
        "#Sessions einlesen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqMHmK7wD2YX",
        "outputId": "0f37a749-4eff-4fd2-dafe-a237469f15b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gefundene Sessions: 12 -> ['Session_01', 'Session_02', 'Session_04', 'Session_05', 'Session_06', 'Session_07', 'Session_09', 'Session_10', 'Session_11', 'Session_12', 'Session_13', 'Session_14']\n"
          ]
        }
      ],
      "source": [
        "session_dirs = sorted([\n",
        "    d for d in os.listdir(base_dir)\n",
        "    if os.path.isdir(os.path.join(base_dir, d))\n",
        "])\n",
        "print(f\"Gefundene Sessions: {len(session_dirs)} -> {session_dirs}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8puFV7gaEAMI"
      },
      "source": [
        "Fuktionen zum LAbel-Parsing und Datei finden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lo3wDSUeD-TT"
      },
      "outputs": [],
      "source": [
        "# 5.1 parse_hot_labels: Liest die _hot.json-Datei ein, erstellt f√ºr jeden Frame ein Label\n",
        "def parse_hot_labels(json_path, total_frames):\n",
        "    with open(json_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "    entries = data['button_presses'].strip().split(';')\n",
        "\n",
        "    label_changes = []\n",
        "    for entry in entries:\n",
        "        if ':' in entry:\n",
        "            label, frame = entry.strip().split(':')\n",
        "            label = label.strip()\n",
        "            # Korrigiere evtl. \"Peadling\" ‚Üí \"Pedaling\"\n",
        "            if label.lower() == 'peadling':\n",
        "                label = 'Pedaling'\n",
        "            label_changes.append((int(frame.strip()), label))\n",
        "\n",
        "    frame_labels = ['Unknown'] * total_frames\n",
        "    for i, (start_frame, label) in enumerate(label_changes):\n",
        "        end_frame = label_changes[i + 1][0] if i + 1 < len(label_changes) else total_frames\n",
        "        for f in range(start_frame, min(end_frame, total_frames)):\n",
        "            frame_labels[f] = label\n",
        "    return frame_labels\n",
        "\n",
        "# 5.2 find_sensor_file: Findet CSV-Datei, deren Name mit dem Prefix beginnt (Head_, Wrist_, Seat_)\n",
        "def find_sensor_file(folder, prefix):\n",
        "    for f in os.listdir(folder):\n",
        "        if f.lower().startswith(prefix.lower()):\n",
        "            return os.path.join(folder, f)\n",
        "    raise FileNotFoundError(f\"‚ùå Keine Datei mit Prefix '{prefix}' in {folder} gefunden.\")\n",
        "\n",
        "# 5.3 find_hot_file: Findet JSON-Datei, deren Name auf \"_hot.json\" endet\n",
        "def find_hot_file(folder):\n",
        "    for f in os.listdir(folder):\n",
        "        if f.lower().endswith('_hot.json'):\n",
        "            return os.path.join(folder, f)\n",
        "    raise FileNotFoundError(f\"‚ùå Keine Datei mit Suffix '_hot.json' in {folder} gefunden.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYZhfgCTESe4"
      },
      "source": [
        "# 6. Fensterung f√ºr drei Sensoren kombinieren"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_RKQP4OGEKi5"
      },
      "outputs": [],
      "source": [
        "def window_data_multiple_sensors(head_data, wrist_data, seat_data, frame_labels):\n",
        "    X_windows, y_windows = [], []\n",
        "    total_frames = len(frame_labels)\n",
        "\n",
        "    # Annahme: head_data, wrist_data, seat_data haben alle dieselbe Anzahl Zeilen = total_frames\n",
        "    for start in range(0, total_frames - window_size + 1, step_size):\n",
        "        end = start + window_size\n",
        "\n",
        "        win_h = head_data[start:end]    # (window_size, 6)\n",
        "        win_w = wrist_data[start:end]\n",
        "        win_s = seat_data[start:end]\n",
        "        window = np.concatenate([win_h, win_w, win_s], axis=1)  # ‚Üí (window_size, 18)\n",
        "\n",
        "        label_window = frame_labels[start:end]\n",
        "        dominant_label = Counter(label_window).most_common(1)[0][0]\n",
        "        if dominant_label == 'Unknown':\n",
        "            continue\n",
        "\n",
        "        X_windows.append(window)\n",
        "        y_windows.append(dominant_label)\n",
        "\n",
        "    return np.array(X_windows), np.array(y_windows)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjBHXCZBEaWp"
      },
      "source": [
        "#7. Daten einlesen und Fenster / Labels erzeugen\n",
        "‚Üí Nach Ausf√ºhrung siehst du f√ºr jede Session etwa: ‚Äú‚Üí 153 Fenster, 3 Klassen‚Äù etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hAmaAMFEKM_",
        "outputId": "3c2271bc-520c-4fc6-a533-0e51f249291d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìÇ Lade Session: Session_01\n",
            "üìä Head_D422CD00563B_20230713_082527.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "üìä Wrist_D422CD004550_20230713_082527.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "üìä Seat_D422CD00456D_20230713_082527.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "üìä Sensorl√§ngen: Head=(60077, 9), Wrist=(60078, 9), Seat=(60075, 9)\n",
            "‚úÖ Session Session_01: 1997 Fenster, 3 Klassen\n",
            "\n",
            "üìÇ Lade Session: Session_02\n",
            "üìä Head_D422CD00563B_20230713_085629.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "üìä Wrist_D422CD004550_20230713_085629.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "üìä Seat_D422CD00456D_20230713_085629.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "üìä Sensorl√§ngen: Head=(48792, 9), Wrist=(48792, 9), Seat=(48784, 9)\n",
            "‚úÖ Session Session_02: 1621 Fenster, 3 Klassen\n",
            "\n",
            "üìÇ Lade Session: Session_04\n",
            "üìä Head_D422CD00563B_20230717_070932.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "üìä Wrist_D422CD004550_20230717_070932.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "üìä Seat_D422CD00456D_20230717_070932.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "üìä Sensorl√§ngen: Head=(56013, 9), Wrist=(56019, 9), Seat=(56015, 9)\n",
            "‚úÖ Session Session_04: 1864 Fenster, 3 Klassen\n",
            "\n",
            "üìÇ Lade Session: Session_05\n",
            "üìä Head_D422CD00563B_20230717_070932.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "üìä Wrist_D422CD004550_20230717_070932.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "üìä Seat_D422CD00456D_20230717_070932.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "üìä Sensorl√§ngen: Head=(56013, 9), Wrist=(56019, 9), Seat=(56015, 9)\n",
            "‚úÖ Session Session_05: 1858 Fenster, 4 Klassen\n",
            "\n",
            "üìÇ Lade Session: Session_06\n",
            "üìä Head_D422CD00563B_20230720_074713.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "üìä Wrist_D422CD004550_20230720_074713.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "üìä Seat_D422CD00456D_20230720_074713.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "üìä Sensorl√§ngen: Head=(64027, 9), Wrist=(64026, 9), Seat=(64025, 9)\n",
            "‚úÖ Session Session_06: 2116 Fenster, 4 Klassen\n",
            "\n",
            "üìÇ Lade Session: Session_07\n",
            "üìä Head_D422CD00563B_20230720_082728.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "üìä Wrist_D422CD004550_20230720_082728.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "üìä Seat_D422CD00456D_20230720_082728.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "üìä Sensorl√§ngen: Head=(59920, 9), Wrist=(59917, 9), Seat=(59921, 9)\n",
            "‚úÖ Session Session_07: 1991 Fenster, 4 Klassen\n",
            "\n",
            "üìÇ Lade Session: Session_09\n",
            "üìä Head_D422CD00563B_20230724_072319.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "üìä Wrist_D422CD004550_20230724_072319.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "üìä Seat_D422CD00456D_20230724_072319.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "üìä Sensorl√§ngen: Head=(59464, 9), Wrist=(59465, 9), Seat=(59468, 9)\n",
            "‚úÖ Session Session_09: 1979 Fenster, 4 Klassen\n",
            "\n",
            "üìÇ Lade Session: Session_10\n",
            "üìä Head_D422CD004576_20230725_070718.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "üìä Wrist_D422CD004550_20230725_070718.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "üìä Seat_D422CD00456D_20230725_070718.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "üìä Sensorl√§ngen: Head=(62167, 9), Wrist=(62163, 9), Seat=(62163, 9)\n",
            "‚úÖ Session Session_10: 2061 Fenster, 4 Klassen\n",
            "\n",
            "üìÇ Lade Session: Session_11\n",
            "üìä Head_D422CD004576_20230727_073528.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-2c88c15e2b07>:25: DtypeWarning: Columns (5,6,7,8,9,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(path, sep=',', skiprows=1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Wrist_D422CD004550_20230727_073528.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-2c88c15e2b07>:25: DtypeWarning: Columns (5,6,7,8,9,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(path, sep=',', skiprows=1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Seat_D422CD00456D_20230727_073528.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-2c88c15e2b07>:50: DtypeWarning: Columns (5,6,7,8,9,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(path, sep=',', skiprows=skip)\n",
            "<ipython-input-7-2c88c15e2b07>:50: DtypeWarning: Columns (5,6,7,8,9,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(path, sep=',', skiprows=skip)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Sensorl√§ngen: Head=(65763, 9), Wrist=(65763, 9), Seat=(65763, 9)\n",
            "‚úÖ Session Session_11: 2181 Fenster, 4 Klassen\n",
            "\n",
            "üìÇ Lade Session: Session_12\n",
            "üìä Head_D422CD004576_20230801_075834.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['0', '416010770', '-4.522172451019287', '48.04213333129883', '21.0351619720459', '0', '0.1', '0.2', '0.3', '0.4', '0.5', '']\n",
            "üìä Wrist_D422CD004550_20230801_075834.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['0', '532295258', '-42.42717361450195', '45.996009826660156', '-55.192440032958984', '0', '0.1', '0.2', '0.3', '0.4', '0.5', '']\n",
            "üìä Seat_D422CD00456D_20230801_075834.csv: 11 Spalten\n",
            "   ‚Üí Spaltennamen: ['0', '409881162', '2202328491210930', '-6035955047607420', '-8357672119140620', '0.00000000000000', '0.00000000000000.1', '0.00000000000000.2', '0.00000000000000.3', '0.00000000000000.4', '0.00000000000000.5']\n",
            "üìä Sensorl√§ngen: Head=(59523, 9), Wrist=(59524, 9), Seat=(59514, 9)\n",
            "‚úÖ Session Session_12: 1967 Fenster, 4 Klassen\n",
            "\n",
            "üìÇ Lade Session: Session_13\n",
            "üìä Head_D422CD004576_20230802_080027.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['0', '209493532', '-7.16727876663208', '47.413570404052734', '-87.12100219726562', '0', '0.1', '0.2', '0.3', '0.4', '0.5', '']\n",
            "üìä Wrist_D422CD004550_20230802_080027.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['0', '358144070', '-41.73847198486328', '23.458871841430664', '-68.4642105102539', '0', '0.1', '0.2', '0.3', '0.4', '0.5', '']\n",
            "üìä Seat_D422CD00456D_20230802_080027.csv: 11 Spalten\n",
            "   ‚Üí Spaltennamen: ['0', '435628135', '199753963947296', '-6415881347656250', '-16434582519531200', '0.00000000000000', '0.00000000000000.1', '0.00000000000000.2', '0.00000000000000.3', '0.00000000000000.4', '0.00000000000000.5']\n",
            "üìä Sensorl√§ngen: Head=(65046, 9), Wrist=(66494, 9), Seat=(65037, 9)\n",
            "‚úÖ Session Session_13: 2161 Fenster, 4 Klassen\n",
            "\n",
            "üìÇ Lade Session: Session_14\n",
            "üìä Head_D422CD004576_20230803_073423.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['0', '23311239', '5.965623378753662', '-45.560245513916016', '164.4220428466797', '0', '0.1', '0.2', '0.3', '0.4', '0.5', '']\n",
            "üìä Wrist_D422CD004550_20230803_073423.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['0', '177062498', '78.41714477539062', '7.847972869873047', '119.1408920288086', '0', '0.1', '0.2', '0.3', '0.4', '0.5', '']\n",
            "üìä Seat_D422CD00456D_20230803_073423.csv: 11 Spalten\n",
            "   ‚Üí Spaltennamen: ['0', '310191965', '7921337127685540', '-2267286872863770', '-12943373107910100', '0.00000000000000', '0.00000000000000.1', '0.00000000000000.2', '0.00000000000000.3', '0.00000000000000.4', '0.00000000000000.5']\n",
            "üìä Sensorl√§ngen: Head=(58097, 9), Wrist=(58096, 9), Seat=(58086, 9)\n",
            "‚úÖ Session Session_14: 1869 Fenster, 4 Klassen\n",
            "\n",
            "‚úÖ Verwendete Sessions:\n",
            "  Session_01: (1997, 60, 27)\n",
            "  Session_02: (1621, 60, 27)\n",
            "  Session_04: (1864, 60, 27)\n",
            "  Session_05: (1858, 60, 27)\n",
            "  Session_06: (2116, 60, 27)\n",
            "  Session_07: (1991, 60, 27)\n",
            "  Session_09: (1979, 60, 27)\n",
            "  Session_10: (2061, 60, 27)\n",
            "  Session_11: (2181, 60, 27)\n",
            "  Session_12: (1967, 60, 27)\n",
            "  Session_13: (2161, 60, 27)\n",
            "  Session_14: (1869, 60, 27)\n"
          ]
        }
      ],
      "source": [
        "#Vorbereitung\n",
        "sessions_X = []\n",
        "sessions_y = []\n",
        "valid_sessions = []  # <- neue Liste! mit nur valid sessions\n",
        "skipped_sessions = []\n",
        "\n",
        "#features definieren:\n",
        "features = ['Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z']\n",
        "\n",
        "#Funktionen f√ºr Daten einlesen\n",
        "def smart_feature_filter(df):\n",
        "    # alles lowercase und leerzeichenfrei vergleichen\n",
        "    keep = [col for col in df.columns if any(kw in col.lower() for kw in ['euler', 'acc', 'gyr'])]\n",
        "    return df[keep]\n",
        "\n",
        "def print_csv_headers(path, label):\n",
        "    with open(path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "    print(f\"\\nüìã {label} ‚Üí Datei: {os.path.basename(path)}\")\n",
        "    print(\"   Zeile 0:\", lines[0].strip())\n",
        "    print(\"   Zeile 1:\", lines[1].strip())\n",
        "\n",
        "\n",
        "def inspect_sensor_csv(path):\n",
        "    df = pd.read_csv(path, sep=',', skiprows=1)\n",
        "    df.columns = df.columns.str.strip()\n",
        "    print(f\"üìä {os.path.basename(path)}: {df.shape[1]} Spalten\")\n",
        "    print(\"   ‚Üí Spaltennamen:\", df.columns.tolist())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def load_sensor_csv(path):\n",
        "  import csv\n",
        "\n",
        "  # Erste zwei Zeilen lesen\n",
        "  with open(path, 'r') as f:\n",
        "      reader = csv.reader(f)\n",
        "      first_line = next(reader)\n",
        "      second_line = next(reader)\n",
        "\n",
        "  # Pr√ºfen ob erste Zeile ein Header ist (z.‚ÄØB. mit bekannten Schl√ºsselw√∂rtern)\n",
        "  first_line_str = \",\".join(first_line).lower()\n",
        "  if any(kw in first_line_str for kw in ['euler', 'acc', 'gyr']):\n",
        "      skip = 0\n",
        "  else:\n",
        "      skip = 1\n",
        "\n",
        "  # Einlesen\n",
        "  df = pd.read_csv(path, sep=',', skiprows=skip)\n",
        "  df.columns = df.columns.str.strip()\n",
        "\n",
        "  # Features filtern\n",
        "  df = smart_feature_filter(df)\n",
        "\n",
        "  # Numerisch umwandeln und NaN behandeln\n",
        "  df = df.apply(pd.to_numeric, errors='coerce').fillna(0).astype(np.float32)\n",
        "\n",
        "  return df.values\n",
        "\n",
        "  print(f\"üîç {os.path.basename(path)}: Header {'erste Zeile' if skip==0 else 'zweite Zeile'}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# --- Hauptschleife ---\n",
        "for sess_dir in session_dirs:\n",
        "    print(f\"\\nüìÇ Lade Session: {sess_dir}\")\n",
        "    session_path = os.path.join(base_dir, sess_dir)\n",
        "\n",
        "\n",
        "    # 7.1 Sensor-Dateien finden\n",
        "    head_path  = find_sensor_file(session_path, 'Head_')\n",
        "    wrist_path = find_sensor_file(session_path, 'Wrist_')\n",
        "    seat_path  = find_sensor_file(session_path, 'Seat_')\n",
        "\n",
        "    # 7.2 Hot-JSON-Datei finden\n",
        "    hot_path = find_hot_file(session_path)\n",
        "\n",
        "    inspect_sensor_csv(head_path)\n",
        "    inspect_sensor_csv(wrist_path)\n",
        "    inspect_sensor_csv(seat_path)\n",
        "\n",
        "\n",
        "    #print csv-heads for debugging & checking (oben definierte function print_csv_headers)\n",
        "    #print_csv_headers(head_path, 'Head')\n",
        "    #print_csv_headers(wrist_path, 'Wrist')\n",
        "    #print_csv_headers(seat_path, 'Seat')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # 7.3 IMU-Daten laden\n",
        "    #funktion um imu laden\n",
        "    #aktuelles Problem: header in der zweiten Zeile, seperator ',' , erkennt nur zwei spalten beim einlesen\n",
        "\n",
        "\n",
        "\n",
        "    head_data  = load_sensor_csv(head_path)\n",
        "    wrist_data = load_sensor_csv(wrist_path)\n",
        "    seat_data  = load_sensor_csv(seat_path)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    print(f\"üìä Sensorl√§ngen: Head={head_data.shape}, Wrist={wrist_data.shape}, Seat={seat_data.shape}\")\n",
        "\n",
        "    #expected_features = 27  # 3 Sensoren √ó 9 Features (oben definiert)\n",
        "   # if X_win.shape[1:] != (window_size, expected_features):\n",
        "    #      print(f\"‚ö†Ô∏è Session {sess_dir} hat Format {X_win.shape[1:]}, wird √ºbersprungen.\")\n",
        "     #     skipped_sessions.append(sess_dir)\n",
        "      #    continue\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    #7.4 Labels laden\n",
        "    total_frames = min(head_data.shape[0], wrist_data.shape[0], seat_data.shape[0])\n",
        "    frame_labels = parse_hot_labels(hot_path, total_frames)\n",
        "\n",
        "    # Re-Labeln: Nur \"Action\" als positiv (1), alles andere negativ (0)\n",
        "    def relabel_binary(y_labels):\n",
        "        return np.array([1 if label == \"Action\" else 0 for label in y_labels])\n",
        "\n",
        "    # Beispiel-Anwendung f√ºr alle Sessions:\n",
        "    sessions_y = [relabel_binary(y) for y in sessions_y]\n",
        "\n",
        "\n",
        "    # 7.5 Sicherheitsk√ºrzung (sp√§ter optional mit synch.json ersetzen)\n",
        "    head_data  = head_data[:total_frames]\n",
        "    wrist_data = wrist_data[:total_frames]\n",
        "    seat_data  = seat_data[:total_frames]\n",
        "    frame_labels = frame_labels[:total_frames]\n",
        "\n",
        "\n",
        "    # 7.6 Fensterung & Label-Zuweisung\n",
        "    X_win, y_win = window_data_multiple_sensors(head_data, wrist_data, seat_data, frame_labels)\n",
        "\n",
        "    # 5. G√ºltigkeit pr√ºfen\n",
        "    if len(X_win) == 0:\n",
        "        print(f\"‚ö†Ô∏è  Session {sess_dir} √ºbersprungen ‚Äì keine g√ºltigen Fenster.\")\n",
        "        skipped_sessions.append(sess_dir)\n",
        "        continue\n",
        "\n",
        "    expected_features = 27  # oder dynamisch aus den Daten\n",
        "\n",
        "    if X_win.shape[1:] != (window_size, expected_features):\n",
        "        print(f\"‚ö†Ô∏è  Session {sess_dir} hat Format {X_win.shape[1:]}, wird √ºbersprungen.\")\n",
        "        skipped_sessions.append(sess_dir)\n",
        "        continue\n",
        "\n",
        "\n",
        "        # 6. Speichern\n",
        "    sessions_X.append(X_win)\n",
        "    sessions_y.append(y_win)\n",
        "    valid_sessions.append(sess_dir)\n",
        "    print(f\"‚úÖ Session {sess_dir}: {len(X_win)} Fenster, {len(np.unique(y_win))} Klassen\")\n",
        "\n",
        "# --- Zusammenfassung ---\n",
        "print(\"\\n‚úÖ Verwendete Sessions:\")\n",
        "for idx, sess in enumerate(valid_sessions):\n",
        "    print(f\"  {sess}: {sessions_X[idx].shape}\")\n",
        "\n",
        "if skipped_sessions:\n",
        "    print(\"\\n‚õîÔ∏è √úbersprungene Sessions:\")\n",
        "    for s in skipped_sessions:\n",
        "        print(f\"  {s}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEmZyAMMpyKX"
      },
      "source": [
        "üß† Dann ist deine Fensterform:\n",
        "\n",
        "    3 Sensoren √ó 9 Spalten = 27 Features\n",
        "    ‚Üí Fenster-Shape: (window_size, 27) = (60, 27)\n",
        "\n",
        "\n",
        "Euler_X, Euler_Y, Euler_Z\n",
        "\n",
        "\n",
        "Acc_X, Acc_Y, Acc_Z\n",
        "\n",
        "Gyr_X, Gyr_Y, Gyr_Z\n",
        "\n",
        "‚Üí = 9 physikalisch sinnvolle Spalten pro Sensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8szKmR2qE5RI"
      },
      "source": [
        "#8. Global Model: Training and Evaluation\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GXVBVo7GgPw"
      },
      "source": [
        "##Binary Labeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XglPVCpRGnyr"
      },
      "source": [
        "üìù Was passiert jetzt genau?\n",
        "\n",
        "    Du trainierst ein Modell, das nur zwei Klassen unterscheidet:\n",
        "    ‚Üí ‚ÄûHighlight-w√ºrdig (Action)‚Äú vs. ‚ÄûNicht interessant‚Äú\n",
        "\n",
        "    Der Fokus liegt auf Recall & Precision f√ºr Action (1):\n",
        "\n",
        "        Recall (Sensitivit√§t) = Wie viele tats√§chliche Actions werden erkannt?\n",
        "\n",
        "        Precision = Wie viele erkannte Actions sind wirklich Action?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luvQquTrGtxS"
      },
      "source": [
        "##Model training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EK4PkEMQL3ac"
      },
      "source": [
        "Schritt-f√ºr-Schritt Erkl√§rung\n",
        "\n",
        "  **1. Daten zusammenf√ºhren**\n",
        "\n",
        "    Alle Sessions werden zu einem gro√üen Datensatz verbunden, damit das Modell aus allen Beispielen lernt.\n",
        "\n",
        " **2. Label-Encoding**\n",
        "\n",
        "\n",
        "    Die Labels (z.B. verschiedene Aktivit√§ten) werden in numerische Werte umgewandelt, da das Modell nur mit Zahlen arbeitet.\n",
        "\n",
        " **3. Trainings- und Validierungs-Split**\n",
        "\n",
        "    Der Datensatz wird in Training (90%) und Validation (10%) aufgeteilt. Validation wird genutzt, um das Modell w√§hrend des Trainings zu √ºberpr√ºfen.\n",
        "\n",
        "  **4. Modell erstellen**\n",
        "\n",
        "    Das Modell kombiniert Convolutional Layers (um lokale Muster in den Zeitreihen zu erkennen) mit LSTM (um zeitliche Abh√§ngigkeiten zu lernen). Dropout wird eingesetzt, um √úberanpassung zu vermeiden.\n",
        "\n",
        "  **5. Checkpoint Callback**\n",
        "\n",
        "    W√§hrend des Trainings werden Modelle nach jeder Epoche gespeichert (nur die besten, basierend auf Validierungsleistung).\n",
        "\n",
        "  **6. Training**\n",
        "  \n",
        "    Das Modell lernt √ºber 50 Epochen, wobei Trainings- und Validierungsdaten genutzt werden.\n",
        "\n",
        "  **7. Finales Modell speichern**\n",
        "\n",
        "    Das finale Modell wird nach dem Training gespeichert,\n",
        "    um es sp√§ter laden und nutzen zu k√∂nnen.\n",
        "\n",
        "  **8. Evaluation auf Validierungsdaten**\n",
        "\n",
        "    Das Modell wird auf den Validation-Daten getestet,\n",
        "    um die Genauigkeit zu ermitteln.\n",
        "\n",
        "  **9.  Vorhersagen erzeugen**\n",
        "\n",
        "    Die Wahrscheinlichkeiten f√ºr jede Klasse werden ermittelt und in Klassen umgewandelt (h√∂chste Wahrscheinlichkeit = Vorhersage).\n",
        "\n",
        "  **10.  Labels pr√ºfen**\n",
        "\n",
        "    Nur die tats√§chlich in den Validierungsdaten vorhandenen Klassen werden f√ºr den Bericht verwendet.\n",
        "\n",
        " **11.  Classification Report**\n",
        "\n",
        "    Pr√§zision, Recall, F1-Score und Support f√ºr jede Klasse werden ausgegeben ‚Äî wichtige Kennzahlen f√ºr die Modellg√ºte.\n",
        "\n",
        "  **12.  Confusion Matrix**\n",
        "\n",
        "    Visualisiert die Fehler des Modells,\n",
        "    zeigt welche Klassen oft verwechselt werden.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRxeqKmSL5-0"
      },
      "source": [
        "##ML-Model Train Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "id": "8T-j67ejTEy9",
        "outputId": "661713e1-8989-45a3-cda0-d7d3f8669c9b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'sessions_X' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-45c5c77d37bb>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;31m# 1. Daten vorbereiten: alle Sessions zusammenf√ºhren\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m \u001b[0mX_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msessions_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0my_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msessions_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'sessions_X' is not defined"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import time\n",
        "import random\n",
        "\n",
        "timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "# üíæ Speicherpfade anlegen\n",
        "checkpoint_dir = \"/content/drive/MyDrive/mtb_project/checkpoints_global\"\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "final_model_dir = \"/content/drive/MyDrive/mtb_project/final_models_global\"\n",
        "os.makedirs(final_model_dir, exist_ok=True)\n",
        "report_dir = \"/content/drive/MyDrive/mtb_project/reports_global\"\n",
        "os.makedirs(report_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "#Data Augmentation\n",
        "def augment_time_series_multiclass(X, y, augment_factor=2, jitter_std=0.01, scale_range=(0.9, 1.1),\n",
        "                                   permute_segments=3, apply_mixup=False, seed=42):\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "    N, T, F = X.shape\n",
        "    X_aug = []\n",
        "    y_aug = []\n",
        "\n",
        "    def jitter(x):\n",
        "        return x + np.random.normal(loc=0., scale=jitter_std, size=x.shape)\n",
        "\n",
        "    def scale(x):\n",
        "        factor = np.random.uniform(*scale_range)\n",
        "        return x * factor\n",
        "\n",
        "    def permute(x):\n",
        "        segs = np.array_split(x, permute_segments)\n",
        "        np.random.shuffle(segs)\n",
        "        return np.concatenate(segs, axis=0)\n",
        "\n",
        "    def hello_ruven():\n",
        "      print(\"Hallo Ruven, du kleiner Schlawiner!\")\n",
        "\n",
        "    def mixup(x1, x2, y1, y2):\n",
        "        alpha = np.random.beta(0.4, 0.4)\n",
        "        x_mix = alpha * x1 + (1 - alpha) * x2\n",
        "        return x_mix, y1 if np.random.rand() < 0.5 else y2\n",
        "\n",
        "    for i in range(N):\n",
        "        for _ in range(augment_factor):\n",
        "            x_aug = X[i]\n",
        "\n",
        "            if np.random.rand() < 0.5:\n",
        "                x_aug = jitter(x_aug)\n",
        "            if np.random.rand() < 0.5:\n",
        "                x_aug = scale(x_aug)\n",
        "            if np.random.rand() < 0.3:\n",
        "                x_aug = permute(x_aug)\n",
        "\n",
        "            if apply_mixup and np.random.rand() < 0.3:\n",
        "                idx2 = np.random.randint(0, N)\n",
        "                x_aug, y_mix = mixup(x_aug, X[idx2], y[i], y[idx2])\n",
        "                y_aug.append(y_mix)\n",
        "            else:\n",
        "                y_aug.append(y[i])\n",
        "\n",
        "            X_aug.append(x_aug)\n",
        "\n",
        "    X_aug = np.array(X_aug)\n",
        "    y_aug = np.array(y_aug)\n",
        "\n",
        "    X_combined = np.concatenate([X, X_aug])\n",
        "    y_combined = np.concatenate([y, y_aug])\n",
        "\n",
        "    return X_combined, y_combined\n",
        "\n",
        "\n",
        "# 1. Daten vorbereiten: alle Sessions zusammenf√ºhren\n",
        "X_all = np.concatenate(sessions_X)\n",
        "y_all = np.concatenate(sessions_y)\n",
        "\n",
        "# 2. Labels bin√§r umwandeln: \"Action\" = 1, alles andere = 0\n",
        "y_all_binary = np.array([1 if label == \"Action\" else 0 for label in y_all])\n",
        "\n",
        "# 3. Trainings- und Validierungsdaten splitten (z.B. 90% Training, 10% Validation)\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_all, y_all_binary, test_size=0.1, random_state=42, stratify=y_all_binary\n",
        ")\n",
        "\n",
        "\n",
        "# Augmentierung auf Trainingsdaten anwenden\n",
        "X_train, y_train = augment_time_series_multiclass(X_train, y_train, augment_factor=2, jitter_std=0.01, scale_range=(0.9, 1.1),\n",
        "                                   permute_segments=3, apply_mixup=False, seed=42)\n",
        "\n",
        "\n",
        "# 4. Modell definieren (CNN + LSTM Architektur) - Binary Output: 1 Neuron mit Sigmoid\n",
        "model = models.Sequential([\n",
        "    layers.Conv1D(64, 3, activation='relu', input_shape=X_train.shape[1:]),\n",
        "    layers.Conv1D(64, 3, activation='relu'),\n",
        "    layers.MaxPooling1D(pool_size=2),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.LSTM(64),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(100, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')  # Ein Output f√ºr Binary Classification\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# 5. Callback f√ºr Checkpoints w√§hrend Training\n",
        "checkpoint_cb = ModelCheckpoint(\n",
        "    filepath=os.path.join(checkpoint_dir, \"global_epoch_{epoch:02d}.keras\"),\n",
        "    save_best_only=True,\n",
        "    save_weights_only=False,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# 6. Training starten\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=50,\n",
        "    batch_size=64,\n",
        "    callbacks=[checkpoint_cb]\n",
        ")\n",
        "\n",
        "# 7. Finale Modell speichern\n",
        "model.save(os.path.join(final_model_dir, \"global_final_v4_binary_augment_f2.keras\"))\n",
        "\n",
        "# 8. Vorhersagen f√ºr Validierungsdaten (Wahrscheinlichkeiten)\n",
        "y_pred_probs = model.predict(X_val)\n",
        "\n",
        "# 9. Wahrscheinlichkeiten in Klassen (0 oder 1) umwandeln, Schwellenwert 0.5\n",
        "y_pred_binary = (y_pred_probs >= 0.5).astype(int).reshape(-1)\n",
        "\n",
        "# 10. Classification Report ausgeben\n",
        "print(\"\\nüìÑ Classification Report (Binary):\\n\")\n",
        "report = classification_report(y_val, y_pred_binary, target_names=['Not Action', 'Action'])\n",
        "print(report)\n",
        "\n",
        "# 11. Report als Textdatei speichern\n",
        "with open(os.path.join(report_dir, f\"classification_report_augmentf2_binary_{timestamp}.txt\"), \"w\") as f:\n",
        "    f.write(report)\n",
        "\n",
        "# 12. Confusion Matrix plotten und speichern\n",
        "cm = confusion_matrix(y_val, y_pred_binary)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Not Action', 'Action'])\n",
        "fig, ax = plt.subplots(figsize=(6, 4))\n",
        "disp.plot(ax=ax)\n",
        "plt.title(\"Confusion Matrix ‚Äì Binary Model Data Augmentation f2\")\n",
        "plt.savefig(os.path.join(report_dir, f\"conf_matrix_augment_f2_binary_{timestamp}.png\"))\n",
        "plt.show()\n",
        "\n",
        "# 13. Evaluation auf Validierungsdaten\n",
        "val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
        "print(f\"\\n‚úÖ Validation Accuracy: {val_acc:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpxJ7i_COef6"
      },
      "source": [
        "##Erkl√§rung classification report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVRLqvXsOkF8"
      },
      "source": [
        "* Precision: Precision ist das Verh√§ltnis der Anzahl von True Positives zur Gesamtzahl der positiven Vorhersagen. Wenn das Modell z. B. 100 B√§ume erkannt hat und 90 korrekt gewesen w√§ren, betr√§gt die Genauigkeit 90 Prozent.\n",
        "\n",
        "Precision = (True Positive)/(True Positive + False Positive)\n",
        "\n",
        "* Recall: Recall ist das Verh√§ltnis der Anzahl von True Positives zur Gesamtzahl der realen (relevanten) Objekte. Wenn das Modell z. B. 75 B√§ume auf einem Bild korrekt erkennt und es tats√§chlich 100 B√§ume auf dem Bild gibt, betr√§gt der Recall 75 Prozent.\n",
        "\n",
        "Recall = (True Positive)/(True Positive + False Negative)\n",
        "\n",
        "* F-Ma√ü: Das F-Ma√ü (auch \"F1-Score\") ist ein gewichteter Durchschnitt von Genauigkeit und Recall. Die Werte liegen zwischen 0 und 1, wobei 1 f√ºr die h√∂chste Genauigkeit steht.\n",
        "\n",
        "F-Ma√ü = (Precision √ó Recall)/[(Precision + Recall)/2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wv6yD7uMUvoz"
      },
      "source": [
        "##Csv export"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2NW1yW4CMJFn"
      },
      "outputs": [],
      "source": [
        "#evtl speichern als csv oder oben integrieren\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "\n",
        "# Ausgabe als Dictionary\n",
        "report_dict = classification_report(y_val, y_pred_binary, target_names=['Not Action', 'Action'], output_dict=True)\n",
        "\n",
        "# In DataFrame konvertieren\n",
        "report_df = pd.DataFrame(report_dict).transpose()\n",
        "\n",
        "# Speichern als CSV\n",
        "report_df.to_csv(os.path.join(report_dir, f\"classification_report_binary_{timestamp}.csv\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-yhvJmXzOjU"
      },
      "source": [
        "#üßæ Zusammenfassung Modeltraining\n",
        "##üìä 1. Durchschnittliche Accuracy √ºber alle Sessions:\n",
        "\n",
        "ist oben in code integriert, funktioniert irgendwie nicht danacht"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ZKwF6fOy75p"
      },
      "outputs": [],
      "source": [
        "#üìä 1. Durchschnittliche Accuracy √ºber alle Sessions:\n",
        "\n",
        "mean_acc = np.mean(all_accuracies)\n",
        "print(\"\\nüìà Zusammenfassung:\")\n",
        "for i, acc in enumerate(all_accuracies):\n",
        "    print(f\"  Session {i+1}: Accuracy = {acc:.2f}\")\n",
        "print(f\"\\n‚úÖ Durchschnittliche Test-Accuracy √ºber alle Sessions: {mean_acc:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Evqv6rIczcn0"
      },
      "source": [
        "##üìÅ 2. CSV speichern (falls nicht schon vorhanden):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1AxzlH2XzXA9"
      },
      "outputs": [],
      "source": [
        "#üìÅ 2. CSV speichern (falls nicht schon vorhanden):\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df_summary = pd.DataFrame(accuracy_summary)\n",
        "df_summary['Session'] = [f\"Session_{i+1}\" for i in range(len(all_accuracies))]\n",
        "df_summary.to_csv(\"/content/drive/MyDrive/mtb_project/session_accuracy_report.csv\", index=False)\n",
        "print(\"‚úÖ Bericht gespeichert unter: session_accuracy_report.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJz6n-8PZWui"
      },
      "outputs": [],
      "source": [
        "os.makedirs(\"/content/drive/MyDrive/mtb_project/reports\", exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WbIb7duxZKhi"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import io\n",
        "\n",
        "# Klassifikationsbericht als Text speichern\n",
        "report_text = classification_report(y_test_enc, y_pred_classes, target_names=le.classes_)\n",
        "with open(f\"/content/drive/MyDrive/mtb_project/reports/{sess_name}_classification_report.txt\", \"w\") as f:\n",
        "    f.write(report_text)\n",
        "\n",
        "\n",
        "\n",
        "#confusion matrix als bild speicheern\n",
        "fig, ax = plt.subplots(figsize=(8,6))\n",
        "disp = ConfusionMatrixDisplay(cm, display_labels=le.classes_)\n",
        "disp.plot(ax=ax, xticks_rotation=45)\n",
        "plt.title(f\"Confusion Matrix ‚Äì {sess_name}\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"/content/drive/MyDrive/mtb_project/reports/{sess_name}_confusion_matrix.png\")\n",
        "plt.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6M9hNEyTzn0"
      },
      "source": [
        "üßæ Zusammenfassung nach dem Training:\n",
        "\n",
        "Nach der Schleife kannst du am Ende folgendes hinzuf√ºgen, um einen Bericht zu erzeugen:\n",
        "\n",
        "üìä Bonus: CSV speichern (optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "g9eFJGGxTutz",
        "outputId": "7e0765df-5645-4ea0-ad23-c0b8026c998d"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'all_accuracies' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-bb964def7d64>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Durchschnittliche Accuracy √ºber alle Sessions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmean_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_accuracies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nüìà Zusammenfassung:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_accuracies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"  Session {i+1}: Accuracy = {acc:.2f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'all_accuracies' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "# Durchschnittliche Accuracy √ºber alle Sessions\n",
        "mean_acc = np.mean(all_accuracies)\n",
        "print(\"\\nüìà Zusammenfassung:\")\n",
        "for i, acc in enumerate(all_accuracies):\n",
        "    print(f\"  Session {i+1}: Accuracy = {acc:.2f}\")\n",
        "print(f\"\\n‚úÖ Durchschnittliche Test-Accuracy √ºber alle Sessions: {mean_acc:.2f}\")\n",
        "\n",
        "\n",
        "\n",
        "#üìä Bonus: CSV speichern (optional)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "summary = {'Session': [], 'Accuracy': []}\n",
        "for i, acc in enumerate(all_accuracies):\n",
        "    summary['Session'].append(f\"Session_{i+1}\")\n",
        "    summary['Accuracy'].append(acc)\n",
        "\n",
        "df_summary = pd.DataFrame(summary)\n",
        "df_summary.to_csv(\"session_accuracy_report.csv\", index=False)\n",
        "print(\"üìÅ Bericht gespeichert als session_accuracy_report.csv\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbaE9UFeMQ8r"
      },
      "source": [
        "#üíæ II. Modell speichern & sp√§ter wieder laden (z.‚ÄØB. nach Training)\n",
        "\n",
        "##üîê Speichern mit TensorFlow/**Keras**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9f0wu8rYM2P3"
      },
      "outputs": [],
      "source": [
        "# Nach dem Training:\n",
        "#speichert mit timestamp\n",
        "#model.save(\"SenseCap_Eventdetection_Model.keras\")  # speichert nur in colab kurzzeitig\n",
        "import time\n",
        "timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "model.save(f\"/content/drive/MyDrive/ML-MTB-Modell/ML-Model_trained/SenseCap_Model_binary{timestamp}.keras\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fe6SLk39NNOz"
      },
      "source": [
        "##üîÑ Laden\n",
        "\n",
        "Das speichert das gesamte Modell inkl. Architektur, Gewichten und Optimizer-Zustand ‚Äìexakt da weitermachen, wo man aufgeh√∂rt hast."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puTdBnHsNHsC",
        "outputId": "e01895fd-40b2-435b-a7f7-44950f5ebdf9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 24 variables whereas the saved optimizer has 2 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model(\"/content/drive/MyDrive/ML-MTB-Modell/ML-Model_trained/SenseCap_Eventdetection_Model1.keras\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "0FK9HYSaUOP0",
        "outputId": "0bb3586c-14d1-4009-e85c-573951307718"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'test_sessions_X' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-49eeb814a429>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mall_accuracies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sessions_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_sessions_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_sessions_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'test_sessions_X' is not defined"
          ]
        }
      ],
      "source": [
        "all_accuracies = []\n",
        "\n",
        "for i in range(len(test_sessions_X)):\n",
        "    X_test = test_sessions_X[i]\n",
        "    y_test = test_sessions_y[i]\n",
        "\n",
        "    _, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "    all_accuracies.append(acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "p3xuxyPOUOsO",
        "outputId": "599667da-0a6e-4934-f3dc-505a22c9d150"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'all_accuracies' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-bb964def7d64>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Durchschnittliche Accuracy √ºber alle Sessions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmean_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_accuracies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nüìà Zusammenfassung:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_accuracies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"  Session {i+1}: Accuracy = {acc:.2f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'all_accuracies' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "# Durchschnittliche Accuracy √ºber alle Sessions\n",
        "mean_acc = np.mean(all_accuracies)\n",
        "print(\"\\nüìà Zusammenfassung:\")\n",
        "for i, acc in enumerate(all_accuracies):\n",
        "    print(f\"  Session {i+1}: Accuracy = {acc:.2f}\")\n",
        "print(f\"\\n‚úÖ Durchschnittliche Test-Accuracy √ºber alle Sessions: {mean_acc:.2f}\")\n",
        "\n",
        "\n",
        "\n",
        "#üìä Bonus: CSV speichern (optional)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "summary = {'Session': [], 'Accuracy': []}\n",
        "for i, acc in enumerate(all_accuracies):\n",
        "    summary['Session'].append(f\"Session_{i+1}\")\n",
        "    summary['Accuracy'].append(acc)\n",
        "\n",
        "df_summary = pd.DataFrame(summary)\n",
        "df_summary.to_csv(\"session_accuracy_report.csv\", index=False)\n",
        "print(\"üìÅ Bericht gespeichert als session_accuracy_report.csv\")\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "kH_IAOvdE6R6",
        "cXQYTbV4RFPd",
        "luvQquTrGtxS"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyPvZvVz+5Zm/KpBzoif+GzR",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}