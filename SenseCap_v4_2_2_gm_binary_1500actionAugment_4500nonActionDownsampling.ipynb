{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKNNiSrdDEqF"
      },
      "source": [
        "#Global Model with Binary Encoding & Data Augmentation\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qn46efPvFmfQ"
      },
      "source": [
        "##✅ Ziel: Binary Classification\n",
        "\n",
        "    Action → Positive Klasse (1)\n",
        "\n",
        "    Resting, Pushing, Pedaling → Negative Klasse (0)\n",
        "\n",
        "    Damit erkennt das Modell gezielt nur „echte Actions“, die später für Highlights relevant sind."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kH_IAOvdE6R6"
      },
      "source": [
        "###Short Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cu32jcj0DpaS"
      },
      "source": [
        "Saving model and checkpoints for Zwischenspeicherung\n",
        "\n",
        "CSV-sensor data sheet\n",
        "1.   wrist\n",
        "2.   seat\n",
        "3.  head\n",
        "-> 3 Sensoren, 9 Spalten\n",
        "-> checkt erste und zweite Zeile für header (da unterschiedlich)\n",
        "\n",
        "*   hot encoding for labeling\n",
        " Action, Pedaling, Resting, Pushing\n",
        "\n",
        " Summary at end with\n",
        "\n",
        "\n",
        "*   test accuracy\n",
        "*   confusion matrix\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "all data is stored in Drive\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXQYTbV4RFPd"
      },
      "source": [
        "##Model Choice\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9xflzJBFK5z"
      },
      "source": [
        "✅ Teil 2: Ist CNN + LSTM eine gute Architektur für IMU-Zeitreihendaten?\n",
        "\n",
        "Ja, das ist eine bewährte Kombination – besonders bei IMU-Daten (z. B. Accelerometer/Gyroscope), weil:\n",
        "🔎 Warum CNN?\n",
        "\n",
        "    Erkennt lokale Muster in kurzen Zeitfenstern (z. B. Bewegungsphasen)\n",
        "\n",
        "    Spart Rechenzeit, da es weniger Parameter hat als ein reines LSTM\n",
        "\n",
        "🔁 Warum LSTM?\n",
        "\n",
        "    Erkennt zeitliche Abhängigkeiten (z. B. Bewegungsabfolgen)\n",
        "\n",
        "    Ideal für sequentielle Daten, wie du sie hast\n",
        "\n",
        "✅ Alternativen oder Erweiterungen\n",
        "\n",
        "Falls du später mehr Leistung brauchst:\n",
        "\n",
        "    Bidirectional LSTM → besser für symmetrische Bewegungsabfolgen\n",
        "\n",
        "    Residual CNN Blocks → für tiefere Netzwerke\n",
        "\n",
        "    Transformer → wenn du sehr viele Daten und lange Sequenzen hast"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-84PMXWFN6N"
      },
      "source": [
        "##Setup and Prep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hk6qFLbhDJlr",
        "outputId": "5c3baf32-0ab7-4dec-fa3b-92b394f0edba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OtTD-qyzDXoH"
      },
      "outputs": [],
      "source": [
        "#import packages\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "layers = tf.keras.layers\n",
        "models = tf.keras.models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8d9oN1zpDqKo"
      },
      "outputs": [],
      "source": [
        "# --- PARAMETER ---\n",
        "sampling_rate = 60       # 60 Hz nach SDI-Algorithmus\n",
        "window_size = 60         # 1 Sekunde = 60 Frames\n",
        "step_size = 30           # 50% Überlappung\n",
        "\n",
        "# Basisverzeichnis (sollte die 18 Session-Ordner enthalten)\n",
        "base_dir = '/content/drive/MyDrive/ML-MTB-Modell/IMU-Sessions/'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcvlHHFOD36z"
      },
      "source": [
        "#Sessions einlesen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqMHmK7wD2YX",
        "outputId": "426949c9-1cb0-46b6-f278-524e15348b43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gefundene Sessions: 12 -> ['Session_01', 'Session_02', 'Session_03', 'Session_05', 'Session_06', 'Session_07', 'Session_09', 'Session_10', 'Session_11', 'Session_12', 'Session_13', 'Session_14']\n"
          ]
        }
      ],
      "source": [
        "session_dirs = sorted([\n",
        "    d for d in os.listdir(base_dir)\n",
        "    if os.path.isdir(os.path.join(base_dir, d))\n",
        "])\n",
        "print(f\"Gefundene Sessions: {len(session_dirs)} -> {session_dirs}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8puFV7gaEAMI"
      },
      "source": [
        "Fuktionen zum LAbel-Parsing und Datei finden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lo3wDSUeD-TT"
      },
      "outputs": [],
      "source": [
        "# 5.1 parse_hot_labels: Liest die _hot.json-Datei ein, erstellt für jeden Frame ein Label\n",
        "def parse_hot_labels(json_path, total_frames):\n",
        "    with open(json_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "    entries = data['button_presses'].strip().split(';')\n",
        "\n",
        "    label_changes = []\n",
        "    for entry in entries:\n",
        "        if ':' in entry:\n",
        "            label, frame = entry.strip().split(':')\n",
        "            label = label.strip()\n",
        "            # Korrigiere evtl. \"Peadling\" → \"Pedaling\"\n",
        "            if label.lower() == 'peadling':\n",
        "                label = 'Pedaling'\n",
        "            label_changes.append((int(frame.strip()), label))\n",
        "\n",
        "    frame_labels = ['Unknown'] * total_frames\n",
        "    for i, (start_frame, label) in enumerate(label_changes):\n",
        "        end_frame = label_changes[i + 1][0] if i + 1 < len(label_changes) else total_frames\n",
        "        for f in range(start_frame, min(end_frame, total_frames)):\n",
        "            frame_labels[f] = label\n",
        "    return frame_labels\n",
        "\n",
        "# 5.2 find_sensor_file: Findet CSV-Datei, deren Name mit dem Prefix beginnt (Head_, Wrist_, Seat_)\n",
        "def find_sensor_file(folder, prefix):\n",
        "    for f in os.listdir(folder):\n",
        "        if f.lower().startswith(prefix.lower()):\n",
        "            return os.path.join(folder, f)\n",
        "    raise FileNotFoundError(f\"❌ Keine Datei mit Prefix '{prefix}' in {folder} gefunden.\")\n",
        "\n",
        "# 5.3 find_hot_file: Findet JSON-Datei, deren Name auf \"_hot.json\" endet\n",
        "def find_hot_file(folder):\n",
        "    for f in os.listdir(folder):\n",
        "        if f.lower().endswith('_hot.json'):\n",
        "            return os.path.join(folder, f)\n",
        "    raise FileNotFoundError(f\"❌ Keine Datei mit Suffix '_hot.json' in {folder} gefunden.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYZhfgCTESe4"
      },
      "source": [
        "# 6. Fensterung für drei Sensoren kombinieren"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_RKQP4OGEKi5"
      },
      "outputs": [],
      "source": [
        "def window_data_multiple_sensors(head_data, wrist_data, seat_data, frame_labels):\n",
        "    X_windows, y_windows = [], []\n",
        "    total_frames = len(frame_labels)\n",
        "\n",
        "    # Annahme: head_data, wrist_data, seat_data haben alle dieselbe Anzahl Zeilen = total_frames\n",
        "    for start in range(0, total_frames - window_size + 1, step_size):\n",
        "        end = start + window_size\n",
        "\n",
        "        win_h = head_data[start:end]    # (window_size, 6)\n",
        "        win_w = wrist_data[start:end]\n",
        "        win_s = seat_data[start:end]\n",
        "        window = np.concatenate([win_h, win_w, win_s], axis=1)  # → (window_size, 18)\n",
        "\n",
        "        label_window = frame_labels[start:end]\n",
        "        dominant_label = Counter(label_window).most_common(1)[0][0]\n",
        "        if dominant_label == 'Unknown':\n",
        "            continue\n",
        "\n",
        "        X_windows.append(window)\n",
        "        y_windows.append(dominant_label)\n",
        "\n",
        "    return np.array(X_windows), np.array(y_windows)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjBHXCZBEaWp"
      },
      "source": [
        "#7. Daten einlesen und Fenster / Labels erzeugen\n",
        "→ Nach Ausführung siehst du für jede Session etwa: “→ 153 Fenster, 3 Klassen” etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hAmaAMFEKM_",
        "outputId": "da0fa700-0de3-4ccd-9ec7-05123cebb6ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📂 Lade Session: Session_01\n",
            "📊 Head_D422CD00563B_20230713_082527.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Wrist_D422CD004550_20230713_082527.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Seat_D422CD00456D_20230713_082527.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Sensorlängen: Head=(60077, 9), Wrist=(60078, 9), Seat=(60075, 9)\n",
            "✅ Session Session_01: 1997 Fenster, 3 Klassen\n",
            "\n",
            "📂 Lade Session: Session_02\n",
            "📊 Head_D422CD00563B_20230713_085629.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Wrist_D422CD004550_20230713_085629.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Seat_D422CD00456D_20230713_085629.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Sensorlängen: Head=(48792, 9), Wrist=(48792, 9), Seat=(48784, 9)\n",
            "✅ Session Session_02: 1621 Fenster, 3 Klassen\n",
            "\n",
            "📂 Lade Session: Session_03\n",
            "📊 Head_D422CD00563B_20230713_092642.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Wrist_D422CD004550_20230713_092642.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Seat_D422CD00456D_20230713_092642.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Sensorlängen: Head=(42308, 9), Wrist=(42305, 9), Seat=(42307, 9)\n",
            "✅ Session Session_03: 1407 Fenster, 3 Klassen\n",
            "\n",
            "📂 Lade Session: Session_05\n",
            "📊 Head_D422CD00563B_20230717_070932.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Wrist_D422CD004550_20230717_070932.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Seat_D422CD00456D_20230717_070932.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Sensorlängen: Head=(56013, 9), Wrist=(56019, 9), Seat=(56015, 9)\n",
            "✅ Session Session_05: 1858 Fenster, 4 Klassen\n",
            "\n",
            "📂 Lade Session: Session_06\n",
            "📊 Head_D422CD00563B_20230720_074713.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Wrist_D422CD004550_20230720_074713.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Seat_D422CD00456D_20230720_074713.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Sensorlängen: Head=(64027, 9), Wrist=(64026, 9), Seat=(64025, 9)\n",
            "✅ Session Session_06: 2116 Fenster, 4 Klassen\n",
            "\n",
            "📂 Lade Session: Session_07\n",
            "📊 Head_D422CD00563B_20230720_082728.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Wrist_D422CD004550_20230720_082728.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Seat_D422CD00456D_20230720_082728.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Sensorlängen: Head=(59920, 9), Wrist=(59917, 9), Seat=(59921, 9)\n",
            "✅ Session Session_07: 1991 Fenster, 4 Klassen\n",
            "\n",
            "📂 Lade Session: Session_09\n",
            "📊 Head_D422CD00563B_20230724_072319.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Wrist_D422CD004550_20230724_072319.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Seat_D422CD00456D_20230724_072319.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Sensorlängen: Head=(59464, 9), Wrist=(59465, 9), Seat=(59468, 9)\n",
            "✅ Session Session_09: 1979 Fenster, 4 Klassen\n",
            "\n",
            "📂 Lade Session: Session_10\n",
            "📊 Head_D422CD004576_20230725_070718.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Wrist_D422CD004550_20230725_070718.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Seat_D422CD00456D_20230725_070718.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Sensorlängen: Head=(62167, 9), Wrist=(62163, 9), Seat=(62163, 9)\n",
            "✅ Session Session_10: 2061 Fenster, 4 Klassen\n",
            "\n",
            "📂 Lade Session: Session_11\n",
            "📊 Head_D422CD004576_20230727_073528.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-7-155854597.py:25: DtypeWarning: Columns (5,6,7,8,9,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(path, sep=',', skiprows=1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Wrist_D422CD004550_20230727_073528.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-7-155854597.py:25: DtypeWarning: Columns (5,6,7,8,9,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(path, sep=',', skiprows=1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Seat_D422CD00456D_20230727_073528.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-7-155854597.py:50: DtypeWarning: Columns (5,6,7,8,9,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(path, sep=',', skiprows=skip)\n",
            "/tmp/ipython-input-7-155854597.py:50: DtypeWarning: Columns (5,6,7,8,9,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(path, sep=',', skiprows=skip)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Sensorlängen: Head=(65763, 9), Wrist=(65763, 9), Seat=(65763, 9)\n",
            "✅ Session Session_11: 2181 Fenster, 4 Klassen\n",
            "\n",
            "📂 Lade Session: Session_12\n",
            "📊 Head_D422CD004576_20230801_075834.csv: 12 Spalten\n",
            "   → Spaltennamen: ['0', '416010770', '-4.522172451019287', '48.04213333129883', '21.0351619720459', '0', '0.1', '0.2', '0.3', '0.4', '0.5', '']\n",
            "📊 Wrist_D422CD004550_20230801_075834.csv: 12 Spalten\n",
            "   → Spaltennamen: ['0', '532295258', '-42.42717361450195', '45.996009826660156', '-55.192440032958984', '0', '0.1', '0.2', '0.3', '0.4', '0.5', '']\n",
            "📊 Seat_D422CD00456D_20230801_075834.csv: 11 Spalten\n",
            "   → Spaltennamen: ['0', '409881162', '2202328491210930', '-6035955047607420', '-8357672119140620', '0.00000000000000', '0.00000000000000.1', '0.00000000000000.2', '0.00000000000000.3', '0.00000000000000.4', '0.00000000000000.5']\n",
            "📊 Sensorlängen: Head=(59523, 9), Wrist=(59524, 9), Seat=(59514, 9)\n",
            "✅ Session Session_12: 1967 Fenster, 4 Klassen\n",
            "\n",
            "📂 Lade Session: Session_13\n",
            "📊 Head_D422CD004576_20230802_080027.csv: 12 Spalten\n",
            "   → Spaltennamen: ['0', '209493532', '-7.16727876663208', '47.413570404052734', '-87.12100219726562', '0', '0.1', '0.2', '0.3', '0.4', '0.5', '']\n",
            "📊 Wrist_D422CD004550_20230802_080027.csv: 12 Spalten\n",
            "   → Spaltennamen: ['0', '358144070', '-41.73847198486328', '23.458871841430664', '-68.4642105102539', '0', '0.1', '0.2', '0.3', '0.4', '0.5', '']\n",
            "📊 Seat_D422CD00456D_20230802_080027.csv: 11 Spalten\n",
            "   → Spaltennamen: ['0', '435628135', '199753963947296', '-6415881347656250', '-16434582519531200', '0.00000000000000', '0.00000000000000.1', '0.00000000000000.2', '0.00000000000000.3', '0.00000000000000.4', '0.00000000000000.5']\n",
            "📊 Sensorlängen: Head=(65046, 9), Wrist=(66494, 9), Seat=(65037, 9)\n",
            "✅ Session Session_13: 2161 Fenster, 4 Klassen\n",
            "\n",
            "📂 Lade Session: Session_14\n",
            "📊 Head_D422CD004576_20230803_073423.csv: 12 Spalten\n",
            "   → Spaltennamen: ['0', '23311239', '5.965623378753662', '-45.560245513916016', '164.4220428466797', '0', '0.1', '0.2', '0.3', '0.4', '0.5', '']\n",
            "📊 Wrist_D422CD004550_20230803_073423.csv: 12 Spalten\n",
            "   → Spaltennamen: ['0', '177062498', '78.41714477539062', '7.847972869873047', '119.1408920288086', '0', '0.1', '0.2', '0.3', '0.4', '0.5', '']\n",
            "📊 Seat_D422CD00456D_20230803_073423.csv: 11 Spalten\n",
            "   → Spaltennamen: ['0', '310191965', '7921337127685540', '-2267286872863770', '-12943373107910100', '0.00000000000000', '0.00000000000000.1', '0.00000000000000.2', '0.00000000000000.3', '0.00000000000000.4', '0.00000000000000.5']\n",
            "📊 Sensorlängen: Head=(58097, 9), Wrist=(58096, 9), Seat=(58086, 9)\n",
            "✅ Session Session_14: 1869 Fenster, 4 Klassen\n",
            "\n",
            "✅ Verwendete Sessions:\n",
            "  Session_01: (1997, 60, 27)\n",
            "  Session_02: (1621, 60, 27)\n",
            "  Session_03: (1407, 60, 27)\n",
            "  Session_05: (1858, 60, 27)\n",
            "  Session_06: (2116, 60, 27)\n",
            "  Session_07: (1991, 60, 27)\n",
            "  Session_09: (1979, 60, 27)\n",
            "  Session_10: (2061, 60, 27)\n",
            "  Session_11: (2181, 60, 27)\n",
            "  Session_12: (1967, 60, 27)\n",
            "  Session_13: (2161, 60, 27)\n",
            "  Session_14: (1869, 60, 27)\n"
          ]
        }
      ],
      "source": [
        "#Vorbereitung\n",
        "sessions_X = []\n",
        "sessions_y = []\n",
        "valid_sessions = []  # <- neue Liste! mit nur valid sessions\n",
        "skipped_sessions = []\n",
        "\n",
        "#features definieren:\n",
        "features = ['Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z']\n",
        "\n",
        "#Funktionen für Daten einlesen\n",
        "def smart_feature_filter(df):\n",
        "    # alles lowercase und leerzeichenfrei vergleichen\n",
        "    keep = [col for col in df.columns if any(kw in col.lower() for kw in ['euler', 'acc', 'gyr'])]\n",
        "    return df[keep]\n",
        "\n",
        "def print_csv_headers(path, label):\n",
        "    with open(path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "    print(f\"\\n📋 {label} → Datei: {os.path.basename(path)}\")\n",
        "    print(\"   Zeile 0:\", lines[0].strip())\n",
        "    print(\"   Zeile 1:\", lines[1].strip())\n",
        "\n",
        "\n",
        "def inspect_sensor_csv(path):\n",
        "    df = pd.read_csv(path, sep=',', skiprows=1)\n",
        "    df.columns = df.columns.str.strip()\n",
        "    print(f\"📊 {os.path.basename(path)}: {df.shape[1]} Spalten\")\n",
        "    print(\"   → Spaltennamen:\", df.columns.tolist())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def load_sensor_csv(path):\n",
        "  import csv\n",
        "\n",
        "  # Erste zwei Zeilen lesen\n",
        "  with open(path, 'r') as f:\n",
        "      reader = csv.reader(f)\n",
        "      first_line = next(reader)\n",
        "      second_line = next(reader)\n",
        "\n",
        "  # Prüfen ob erste Zeile ein Header ist (z. B. mit bekannten Schlüsselwörtern)\n",
        "  first_line_str = \",\".join(first_line).lower()\n",
        "  if any(kw in first_line_str for kw in ['euler', 'acc', 'gyr']):\n",
        "      skip = 0\n",
        "  else:\n",
        "      skip = 1\n",
        "\n",
        "  # Einlesen\n",
        "  df = pd.read_csv(path, sep=',', skiprows=skip)\n",
        "  df.columns = df.columns.str.strip()\n",
        "\n",
        "  # Features filtern\n",
        "  df = smart_feature_filter(df)\n",
        "\n",
        "  # Numerisch umwandeln und NaN behandeln\n",
        "  df = df.apply(pd.to_numeric, errors='coerce').fillna(0).astype(np.float32)\n",
        "\n",
        "  return df.values\n",
        "\n",
        "  print(f\"🔍 {os.path.basename(path)}: Header {'erste Zeile' if skip==0 else 'zweite Zeile'}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# --- Hauptschleife ---\n",
        "for sess_dir in session_dirs:\n",
        "    print(f\"\\n📂 Lade Session: {sess_dir}\")\n",
        "    session_path = os.path.join(base_dir, sess_dir)\n",
        "\n",
        "\n",
        "    # 7.1 Sensor-Dateien finden\n",
        "    head_path  = find_sensor_file(session_path, 'Head_')\n",
        "    wrist_path = find_sensor_file(session_path, 'Wrist_')\n",
        "    seat_path  = find_sensor_file(session_path, 'Seat_')\n",
        "\n",
        "    # 7.2 Hot-JSON-Datei finden\n",
        "    hot_path = find_hot_file(session_path)\n",
        "\n",
        "    inspect_sensor_csv(head_path)\n",
        "    inspect_sensor_csv(wrist_path)\n",
        "    inspect_sensor_csv(seat_path)\n",
        "\n",
        "\n",
        "    #print csv-heads for debugging & checking (oben definierte function print_csv_headers)\n",
        "    #print_csv_headers(head_path, 'Head')\n",
        "    #print_csv_headers(wrist_path, 'Wrist')\n",
        "    #print_csv_headers(seat_path, 'Seat')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # 7.3 IMU-Daten laden\n",
        "    #funktion um imu laden\n",
        "    #aktuelles Problem: header in der zweiten Zeile, seperator ',' , erkennt nur zwei spalten beim einlesen\n",
        "\n",
        "\n",
        "\n",
        "    head_data  = load_sensor_csv(head_path)\n",
        "    wrist_data = load_sensor_csv(wrist_path)\n",
        "    seat_data  = load_sensor_csv(seat_path)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    print(f\"📊 Sensorlängen: Head={head_data.shape}, Wrist={wrist_data.shape}, Seat={seat_data.shape}\")\n",
        "\n",
        "    #expected_features = 27  # 3 Sensoren × 9 Features (oben definiert)\n",
        "   # if X_win.shape[1:] != (window_size, expected_features):\n",
        "    #      print(f\"⚠️ Session {sess_dir} hat Format {X_win.shape[1:]}, wird übersprungen.\")\n",
        "     #     skipped_sessions.append(sess_dir)\n",
        "      #    continue\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    #7.4 Labels laden\n",
        "    total_frames = min(head_data.shape[0], wrist_data.shape[0], seat_data.shape[0])\n",
        "    frame_labels = parse_hot_labels(hot_path, total_frames)\n",
        "\n",
        "    # Re-Labeln: Nur \"Action\" als positiv (1), alles andere negativ (0)\n",
        "    def relabel_binary(y_labels):\n",
        "        return np.array([1 if label == \"Action\" else 0 for label in y_labels])\n",
        "\n",
        "    # Beispiel-Anwendung für alle Sessions:\n",
        "    sessions_y = [relabel_binary(y) for y in sessions_y]\n",
        "\n",
        "\n",
        "    # 7.5 Sicherheitskürzung (später optional mit synch.json ersetzen)\n",
        "    head_data  = head_data[:total_frames]\n",
        "    wrist_data = wrist_data[:total_frames]\n",
        "    seat_data  = seat_data[:total_frames]\n",
        "    frame_labels = frame_labels[:total_frames]\n",
        "\n",
        "\n",
        "    # 7.6 Fensterung & Label-Zuweisung\n",
        "    X_win, y_win = window_data_multiple_sensors(head_data, wrist_data, seat_data, frame_labels)\n",
        "\n",
        "    # 5. Gültigkeit prüfen\n",
        "    if len(X_win) == 0:\n",
        "        print(f\"⚠️  Session {sess_dir} übersprungen – keine gültigen Fenster.\")\n",
        "        skipped_sessions.append(sess_dir)\n",
        "        continue\n",
        "\n",
        "    expected_features = 27  # oder dynamisch aus den Daten\n",
        "\n",
        "    if X_win.shape[1:] != (window_size, expected_features):\n",
        "        print(f\"⚠️  Session {sess_dir} hat Format {X_win.shape[1:]}, wird übersprungen.\")\n",
        "        skipped_sessions.append(sess_dir)\n",
        "        continue\n",
        "\n",
        "\n",
        "        # 6. Speichern\n",
        "    sessions_X.append(X_win)\n",
        "    sessions_y.append(y_win)\n",
        "    valid_sessions.append(sess_dir)\n",
        "    print(f\"✅ Session {sess_dir}: {len(X_win)} Fenster, {len(np.unique(y_win))} Klassen\")\n",
        "\n",
        "# --- Zusammenfassung ---\n",
        "print(\"\\n✅ Verwendete Sessions:\")\n",
        "for idx, sess in enumerate(valid_sessions):\n",
        "    print(f\"  {sess}: {sessions_X[idx].shape}\")\n",
        "\n",
        "if skipped_sessions:\n",
        "    print(\"\\n⛔️ Übersprungene Sessions:\")\n",
        "    for s in skipped_sessions:\n",
        "        print(f\"  {s}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEmZyAMMpyKX"
      },
      "source": [
        "🧠 Dann ist deine Fensterform:\n",
        "\n",
        "    3 Sensoren × 9 Spalten = 27 Features\n",
        "    → Fenster-Shape: (window_size, 27) = (60, 27)\n",
        "\n",
        "\n",
        "Euler_X, Euler_Y, Euler_Z\n",
        "\n",
        "\n",
        "Acc_X, Acc_Y, Acc_Z\n",
        "\n",
        "Gyr_X, Gyr_Y, Gyr_Z\n",
        "\n",
        "→ = 9 physikalisch sinnvolle Spalten pro Sensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8szKmR2qE5RI"
      },
      "source": [
        "#8. Global Model: Training and Evaluation\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GXVBVo7GgPw"
      },
      "source": [
        "##Binary Labeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XglPVCpRGnyr"
      },
      "source": [
        "📝 Was passiert jetzt genau?\n",
        "\n",
        "    Du trainierst ein Modell, das nur zwei Klassen unterscheidet:\n",
        "    → „Highlight-würdig (Action)“ vs. „Nicht interessant“\n",
        "\n",
        "    Der Fokus liegt auf Recall & Precision für Action (1):\n",
        "\n",
        "        Recall (Sensitivität) = Wie viele tatsächliche Actions werden erkannt?\n",
        "\n",
        "        Precision = Wie viele erkannte Actions sind wirklich Action?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: use data augmentation to generate more action labels. so that we have 1500 action labels and cut the non Action labels to 4500\n",
        "\n",
        "# --- Binary Relabeling ---\n",
        "def relabel_binary(y_labels):\n",
        "    # Convert labels to binary: 'Action' -> 1, everything else -> 0\n",
        "    return np.array([1 if label == \"Action\" else 0 for label in y_labels])\n",
        "\n",
        "# Apply binary relabeling to collected labels\n",
        "sessions_y_binary = [relabel_binary(y) for y in sessions_y]\n",
        "\n",
        "\n",
        "# --- Data Augmentation and Balancing ---\n",
        "\n",
        "# Flatten the lists of arrays\n",
        "all_X = np.concatenate(sessions_X, axis=0)\n",
        "all_y = np.concatenate(sessions_y_binary, axis=0) # Use the binary labels\n",
        "\n",
        "print(f\"\\nInitial data shape: X={all_X.shape}, y={all_y.shape}\")\n",
        "\n",
        "# Count the initial labels\n",
        "label_counts = Counter(all_y)\n",
        "print(f\"Initial label distribution: {label_counts}\")\n",
        "\n",
        "action_indices = np.where(all_y == 1)[0]\n",
        "non_action_indices = np.where(all_y == 0)[0]\n",
        "\n",
        "num_action = len(action_indices)\n",
        "num_non_action = len(non_action_indices)\n",
        "\n",
        "target_action = 1500\n",
        "target_non_action = 4500\n",
        "\n",
        "# Augment Action class\n",
        "if num_action < target_action:\n",
        "    print(f\"\\nAugmenting Action class from {num_action} to {target_action}\")\n",
        "    # Simple augmentation: Duplicate samples with a small amount of noise\n",
        "    augmentation_factor = (target_action // num_action) + 1 # Ensure we get enough\n",
        "    augmented_X_action = []\n",
        "    augmented_y_action = []\n",
        "\n",
        "    noise_level = 0.01 # Small noise to avoid perfect duplicates\n",
        "\n",
        "    for idx in action_indices:\n",
        "        original_sample = all_X[idx]\n",
        "        for _ in range(augmentation_factor):\n",
        "            noisy_sample = original_sample + np.random.normal(0, noise_level, original_sample.shape).astype(np.float32)\n",
        "            augmented_X_action.append(noisy_sample)\n",
        "            augmented_y_action.append(1) # Label is still 1\n",
        "\n",
        "    # Only take the required number of augmented samples\n",
        "    augmented_X_action = augmented_X_action[:target_action - num_action]\n",
        "    augmented_y_action = augmented_y_action[:target_action - num_action]\n",
        "\n",
        "    # Combine original Action data with augmented data\n",
        "    X_action_balanced = np.concatenate([all_X[action_indices], augmented_X_action], axis=0)\n",
        "    y_action_balanced = np.concatenate([all_y[action_indices], augmented_y_action], axis=0)\n",
        "\n",
        "else:\n",
        "    # If we already have more than the target, randomly sample\n",
        "    print(f\"\\nDownsampling Action class from {num_action} to {target_action}\")\n",
        "    sampled_indices = np.random.choice(action_indices, size=target_action, replace=False)\n",
        "    X_action_balanced = all_X[sampled_indices]\n",
        "    y_action_balanced = all_y[sampled_indices]\n",
        "\n",
        "\n",
        "# Downsample Non-Action class\n",
        "if num_non_action > target_non_action:\n",
        "    print(f\"Downsampling Non-Action class from {num_non_action} to {target_non_action}\")\n",
        "    sampled_indices = np.random.choice(non_action_indices, size=target_non_action, replace=False)\n",
        "    X_non_action_balanced = all_X[sampled_indices]\n",
        "    y_non_action_balanced = all_y[sampled_indices]\n",
        "else:\n",
        "     # If we have less than or equal to the target, use all non-action data\n",
        "     print(f\"Using all {num_non_action} Non-Action samples (target is {target_non_action})\")\n",
        "     X_non_action_balanced = all_X[non_action_indices]\n",
        "     y_non_action_balanced = all_y[non_action_indices]\n",
        "\n",
        "\n",
        "# Combine the balanced datasets\n",
        "X_balanced = np.concatenate([X_action_balanced, X_non_action_balanced], axis=0)\n",
        "y_balanced = np.concatenate([y_action_balanced, y_non_action_balanced], axis=0)\n",
        "\n",
        "# Shuffle the combined data\n",
        "shuffle_indices = np.random.permutation(len(X_balanced))\n",
        "X_balanced = X_balanced[shuffle_indices]\n",
        "y_balanced = y_balanced[shuffle_indices]\n",
        "\n",
        "print(f\"\\nBalanced data shape: X={X_balanced.shape}, y={y_balanced.shape}\")\n",
        "print(f\"Balanced label distribution: {Counter(y_balanced)}\")\n",
        "\n",
        "# You can now use X_balanced and y_balanced for training\n"
      ],
      "metadata": {
        "id": "iaHtk0wyMT7m",
        "outputId": "245b636e-c0ec-48b0-a3f1-c07f80f9af33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Initial data shape: X=(23208, 60, 27), y=(23208,)\n",
            "Initial label distribution: Counter({np.int64(0): 22641, np.int64(1): 567})\n",
            "\n",
            "Augmenting Action class from 567 to 1500\n",
            "Downsampling Non-Action class from 22641 to 4500\n",
            "\n",
            "Balanced data shape: X=(6000, 60, 27), y=(6000,)\n",
            "Balanced label distribution: Counter({np.int64(0): 4500, np.int64(1): 1500})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: adapt the following code so it will use the balanced datasets to train the model: import os\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# import matplotlib.pyplot as plt\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "# from tensorflow.keras import layers, models\n",
        "# from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "# import time\n",
        "# import random\n",
        "# timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "# # 💾 Speicherpfade anlegen\n",
        "# checkpoint_dir = \"/content/drive/MyDrive/mtb_project/checkpoints_global\"\n",
        "# os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "# final_model_dir = \"/content/drive/MyDrive/mtb_project/final_models_global\"\n",
        "# os.makedirs(final_model_dir, exist_ok=True)\n",
        "# report_dir = \"/content/drive/MyDrive/mtb_project/reports_global\"\n",
        "# os.makedirs(report_dir, exist_ok=True)\n",
        "# #Data Augmentation\n",
        "# def augment_time_series_multiclass(X, y, augment_factor=2, jitter_std=0.01, scale_range=(0.9, 1.1),\n",
        "#                                    permute_segments=3, apply_mixup=False, seed=42):\n",
        "#     np.random.seed(seed)\n",
        "#     random.seed(seed)\n",
        "#     N, T, F = X.shape\n",
        "#     X_aug = []\n",
        "#     y_aug = []\n",
        "#     def jitter(x):\n",
        "#         return x + np.random.normal(loc=0., scale=jitter_std, size=x.shape)\n",
        "#     def scale(x):\n",
        "#         factor = np.random.uniform(*scale_range)\n",
        "#         return x * factor\n",
        "#     def permute(x):\n",
        "#         segs = np.array_split(x, permute_segments)\n",
        "#         np.random.shuffle(segs)\n",
        "#         return np.concatenate(segs, axis=0)\n",
        "#     def hello_ruven():\n",
        "#       print(\"Hallo Ruven, du kleiner Schlawiner!\")\n",
        "#     def mixup(x1, x2, y1, y2):\n",
        "#         alpha = np.random.beta(0.4, 0.4)\n",
        "#         x_mix = alpha * x1 + (1 - alpha) * x2\n",
        "#         return x_mix, y1 if np.random.rand() < 0.5 else y2\n",
        "#     for i in range(N):\n",
        "#         for _ in range(augment_factor):\n",
        "#             x_aug = X[i]\n",
        "#             if np.random.rand() < 0.5:\n",
        "#                 x_aug = jitter(x_aug)\n",
        "#             if np.random.rand() < 0.5:\n",
        "#                 x_aug = scale(x_aug)\n",
        "#             if np\n",
        "\n",
        "# Split balanced data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_balanced, y_balanced, test_size=0.2, random_state=42, stratify=y_balanced\n",
        ")\n",
        "\n",
        "print(f\"\\nTrain data shape: X={X_train.shape}, y={y_train.shape}\")\n",
        "print(f\"Test data shape: X={X_test.shape}, y={y_test.shape}\")\n",
        "print(f\"Train label distribution: {Counter(y_train)}\")\n",
        "print(f\"Test label distribution: {Counter(y_test)}\")\n",
        "\n",
        "# --- Model Definition (CNN + LSTM) ---\n",
        "def build_cnn_lstm_model(input_shape):\n",
        "    model = models.Sequential()\n",
        "\n",
        "    # CNN layers\n",
        "    model.add(layers.Conv1D(filters=64, kernel_size=5, activation='relu', input_shape=input_shape))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.MaxPooling1D(pool_size=2))\n",
        "    model.add(layers.Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.MaxPooling1D(pool_size=2))\n",
        "    model.add(layers.Conv1D(filters=256, kernel_size=5, activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.MaxPooling1D(pool_size=2))\n",
        "\n",
        "    # Flatten output for LSTM\n",
        "    model.add(layers.Flatten())\n",
        "\n",
        "    # Reshape for LSTM (add time step dimension, even if it's 1)\n",
        "    # The Flatten output shape is (batch_size, num_features)\n",
        "    # We need (batch_size, timesteps, features), where timesteps=1\n",
        "    # Get the shape after Flatten and create the new shape\n",
        "    flattened_shape = model.output_shape[1]\n",
        "    model.add(layers.Reshape((1, flattened_shape)))\n",
        "\n",
        "\n",
        "    # LSTM layer\n",
        "    model.add(layers.LSTM(128, return_sequences=False, activation='relu')) # return_sequences=False for classification\n",
        "\n",
        "    # Dense layers\n",
        "    model.add(layers.Dense(64, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5)) # Add dropout\n",
        "    model.add(layers.Dense(1, activation='sigmoid')) # Binary classification output\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) # Binary classification loss\n",
        "\n",
        "    return model\n",
        "\n",
        "# Build the model\n",
        "input_shape = (X_train.shape[1], X_train.shape[2])\n",
        "model = build_cnn_lstm_model(input_shape)\n",
        "\n",
        "# Print model summary\n",
        "model.summary()\n",
        "\n",
        "\n",
        "# --- Training the Model ---\n",
        "# Define checkpoint callback\n",
        "checkpoint_filepath = os.path.join(checkpoint_dir, f'best_model_{timestamp}.h5')\n",
        "model_checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    monitor='val_loss', # Monitor validation loss\n",
        "    save_best_only=True, # Save only the best model\n",
        "    mode='min', # Minimize validation loss\n",
        "    verbose=1 # Print messages\n",
        ")\n",
        "\n",
        "# Train the model using the balanced data\n",
        "epochs = 50 # You might need to tune this\n",
        "batch_size = 64 # You might need to tune this\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=epochs,\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0.2, # Use a validation split from the training data\n",
        "    callbacks=[model_checkpoint_callback]\n",
        ")\n",
        "\n",
        "# --- Evaluation ---\n",
        "\n",
        "# Load the best model saved during training\n",
        "try:\n",
        "    best_model = models.load_model(checkpoint_filepath)\n",
        "    print(f\"\\nLoaded best model from {checkpoint_filepath}\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nError loading best model, using the last trained model: {e}\")\n",
        "    best_model = model # Use the last trained model if loading fails\n",
        "\n",
        "\n",
        "# Evaluate the best model on the test data\n",
        "loss, accuracy = best_model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"\\nTest Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Generate classification report\n",
        "y_pred_prob = best_model.predict(X_test)\n",
        "y_pred = (y_pred_prob > 0.5).astype(int) # Convert probabilities to binary predictions\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=['Non-Action (0)', 'Action (1)']))\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Non-Action (0)', 'Action (1)'])\n",
        "disp.plot()\n",
        "plt.title('Confusion Matrix (Binary)')\n",
        "\n",
        "# Save the plot\n",
        "cm_plot_path = os.path.join(report_dir, f'confusion_matrix_binary_{timestamp}.png')\n",
        "plt.savefig(cm_plot_path)\n",
        "print(f\"Confusion matrix plot saved to {cm_plot_path}\")\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# --- Save Final Model ---\n",
        "final_model_filepath = os.path.join(final_model_dir, f'final_binary_model_{timestamp}.h5')\n",
        "best_model.save(final_model_filepath)\n",
        "print(f\"\\nFinal binary model saved to {final_model_filepath}\")\n",
        "\n",
        "# --- Save Report ---\n",
        "report_filepath = os.path.join(report_dir, f'report_binary_{timestamp}.txt')\n",
        "with open(report_filepath, 'w') as f:\n",
        "    f.write(f\"Training Report - {timestamp}\\n\")\n",
        "    f.write(\"-\" * 30 + \"\\n\")\n",
        "    f.write(f\"Balanced Data Shape: X={X_balanced.shape}, y={y_balanced.shape}\\n\")\n",
        "    f.write(f\"Balanced Label Distribution: {Counter(y_balanced)}\\n\")\n",
        "    f.write(f\"Train Data Shape: X={X_train.shape}, y={y_train.shape}\\n\")\n",
        "    f.write(f\"Test Data Shape: X={X_test.shape}, y={y_test.shape}\\n\")\n",
        "    f.write(f\"Train Label Distribution: {Counter(y_train)}\\n\")\n",
        "    f.write(f\"Test Label Distribution: {Counter(y_test)}\\n\")\n",
        "    f.write(\"-\" * 30 + \"\\n\")\n",
        "    f.write(f\"Model: CNN+LSTM\\n\")\n",
        "    f.write(f\"Epochs: {epochs}, Batch Size: {batch_size}\\n\")\n",
        "    f.write(\"-\" * 30 + \"\\n\")\n",
        "    f.write(f\"Test Loss: {loss:.4f}\\n\")\n",
        "    f.write(f\"Test Accuracy: {accuracy:.4f}\\n\")\n",
        "    f.write(\"-\" * 30 + \"\\n\")\n",
        "    f.write(\"Classification Report:\\n\")\n",
        "    f.write(classification_report(y_test, y_pred, target_names=['Non-Action (0)', 'Action (1)']))\n",
        "    f.write(\"-\" * 30 + \"\\n\")\n",
        "    f.write(\"Confusion Matrix:\\n\")\n",
        "    f.write(np.array2string(cm) + \"\\n\")\n",
        "    f.write(\"-\" * 30 + \"\\n\")\n",
        "    f.write(f\"Checkpoint saved to: {checkpoint_filepath}\\n\")\n",
        "    f.write(f\"Final model saved to: {final_model_filepath}\\n\")\n",
        "    f.write(f\"Confusion matrix plot saved to: {cm_plot_path}\\n\")\n",
        "\n",
        "print(f\"Training report saved to {report_filepath}\")"
      ],
      "metadata": {
        "id": "x_Omf93GbOoL",
        "outputId": "caa86c63-4ebb-47cf-b127-fcdcbdb373e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train data shape: X=(4800, 60, 27), y=(4800,)\n",
            "Test data shape: X=(1200, 60, 27), y=(1200,)\n",
            "Train label distribution: Counter({np.int64(0): 3600, np.int64(1): 1200})\n",
            "Test label distribution: Counter({np.int64(0): 900, np.int64(1): 300})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_6 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │         \u001b[38;5;34m8,704\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_3 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_7 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m41,088\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_4 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_8 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │       \u001b[38;5;34m164,096\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_5 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ reshape (\u001b[38;5;33mReshape\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1024\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m590,336\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,704</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">41,088</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">164,096</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,336</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m814,337\u001b[0m (3.11 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">814,337</span> (3.11 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m813,441\u001b[0m (3.10 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">813,441</span> (3.10 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m896\u001b[0m (3.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> (3.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.8188 - loss: 0.3593\n",
            "Epoch 1: val_loss improved from inf to 0.39731, saving model to /content/drive/MyDrive/mtb_project/checkpoints_global/best_model_20250629-193848.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 81ms/step - accuracy: 0.8192 - loss: 0.3582 - val_accuracy: 0.8073 - val_loss: 0.3973\n",
            "Epoch 2/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.8674 - loss: 0.2645\n",
            "Epoch 2: val_loss improved from 0.39731 to 0.30264, saving model to /content/drive/MyDrive/mtb_project/checkpoints_global/best_model_20250629-193848.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 103ms/step - accuracy: 0.8673 - loss: 0.2646 - val_accuracy: 0.8229 - val_loss: 0.3026\n",
            "Epoch 3/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.8674 - loss: 0.2414\n",
            "Epoch 3: val_loss improved from 0.30264 to 0.25985, saving model to /content/drive/MyDrive/mtb_project/checkpoints_global/best_model_20250629-193848.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 0.8673 - loss: 0.2415 - val_accuracy: 0.8625 - val_loss: 0.2599\n",
            "Epoch 4/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.8772 - loss: 0.2541\n",
            "Epoch 4: val_loss improved from 0.25985 to 0.25092, saving model to /content/drive/MyDrive/mtb_project/checkpoints_global/best_model_20250629-193848.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 83ms/step - accuracy: 0.8773 - loss: 0.2540 - val_accuracy: 0.8656 - val_loss: 0.2509\n",
            "Epoch 5/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.8796 - loss: 0.2393\n",
            "Epoch 5: val_loss did not improve from 0.25092\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - accuracy: 0.8796 - loss: 0.2393 - val_accuracy: 0.8510 - val_loss: 0.3110\n",
            "Epoch 6/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.8850 - loss: 0.2341\n",
            "Epoch 6: val_loss did not improve from 0.25092\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 0.8849 - loss: 0.2342 - val_accuracy: 0.8479 - val_loss: 0.2578\n",
            "Epoch 7/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.8889 - loss: 0.2376\n",
            "Epoch 7: val_loss improved from 0.25092 to 0.25019, saving model to /content/drive/MyDrive/mtb_project/checkpoints_global/best_model_20250629-193848.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 91ms/step - accuracy: 0.8889 - loss: 0.2376 - val_accuracy: 0.8771 - val_loss: 0.2502\n",
            "Epoch 8/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.8950 - loss: 0.2136\n",
            "Epoch 8: val_loss improved from 0.25019 to 0.23804, saving model to /content/drive/MyDrive/mtb_project/checkpoints_global/best_model_20250629-193848.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 73ms/step - accuracy: 0.8949 - loss: 0.2137 - val_accuracy: 0.8729 - val_loss: 0.2380\n",
            "Epoch 9/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.8852 - loss: 0.2234\n",
            "Epoch 9: val_loss improved from 0.23804 to 0.23628, saving model to /content/drive/MyDrive/mtb_project/checkpoints_global/best_model_20250629-193848.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 107ms/step - accuracy: 0.8852 - loss: 0.2234 - val_accuracy: 0.8750 - val_loss: 0.2363\n",
            "Epoch 10/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.8870 - loss: 0.2144\n",
            "Epoch 10: val_loss did not improve from 0.23628\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 76ms/step - accuracy: 0.8870 - loss: 0.2144 - val_accuracy: 0.8687 - val_loss: 0.2473\n",
            "Epoch 11/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.8974 - loss: 0.2060\n",
            "Epoch 11: val_loss improved from 0.23628 to 0.21438, saving model to /content/drive/MyDrive/mtb_project/checkpoints_global/best_model_20250629-193848.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 116ms/step - accuracy: 0.8974 - loss: 0.2060 - val_accuracy: 0.8865 - val_loss: 0.2144\n",
            "Epoch 12/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.8917 - loss: 0.2076\n",
            "Epoch 12: val_loss did not improve from 0.21438\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 0.8918 - loss: 0.2077 - val_accuracy: 0.8792 - val_loss: 0.2440\n",
            "Epoch 13/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.8921 - loss: 0.1979\n",
            "Epoch 13: val_loss did not improve from 0.21438\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 0.8921 - loss: 0.1980 - val_accuracy: 0.8854 - val_loss: 0.2322\n",
            "Epoch 14/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.8936 - loss: 0.2008\n",
            "Epoch 14: val_loss did not improve from 0.21438\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 96ms/step - accuracy: 0.8938 - loss: 0.2007 - val_accuracy: 0.8938 - val_loss: 0.2411\n",
            "Epoch 15/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.8987 - loss: 0.1856\n",
            "Epoch 15: val_loss did not improve from 0.21438\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 0.8989 - loss: 0.1855 - val_accuracy: 0.8885 - val_loss: 0.2319\n",
            "Epoch 16/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9147 - loss: 0.1710\n",
            "Epoch 16: val_loss did not improve from 0.21438\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.9147 - loss: 0.1710 - val_accuracy: 0.8917 - val_loss: 0.2283\n",
            "Epoch 17/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.9296 - loss: 0.1532\n",
            "Epoch 17: val_loss did not improve from 0.21438\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - accuracy: 0.9295 - loss: 0.1534 - val_accuracy: 0.8865 - val_loss: 0.2519\n",
            "Epoch 18/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9200 - loss: 0.1675\n",
            "Epoch 18: val_loss did not improve from 0.21438\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - accuracy: 0.9201 - loss: 0.1674 - val_accuracy: 0.8948 - val_loss: 0.2310\n",
            "Epoch 19/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.9455 - loss: 0.1309\n",
            "Epoch 19: val_loss did not improve from 0.21438\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - accuracy: 0.9455 - loss: 0.1308 - val_accuracy: 0.9042 - val_loss: 0.2301\n",
            "Epoch 20/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9506 - loss: 0.1147\n",
            "Epoch 20: val_loss did not improve from 0.21438\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 69ms/step - accuracy: 0.9504 - loss: 0.1150 - val_accuracy: 0.9167 - val_loss: 0.2280\n",
            "Epoch 21/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.9514 - loss: 0.1102\n",
            "Epoch 21: val_loss did not improve from 0.21438\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 97ms/step - accuracy: 0.9514 - loss: 0.1102 - val_accuracy: 0.9073 - val_loss: 0.2556\n",
            "Epoch 22/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9575 - loss: 0.0962\n",
            "Epoch 22: val_loss did not improve from 0.21438\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 71ms/step - accuracy: 0.9574 - loss: 0.0964 - val_accuracy: 0.8885 - val_loss: 0.3034\n",
            "Epoch 23/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.9387 - loss: 0.1304\n",
            "Epoch 23: val_loss did not improve from 0.21438\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 101ms/step - accuracy: 0.9389 - loss: 0.1300 - val_accuracy: 0.9062 - val_loss: 0.2303\n",
            "Epoch 24/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9717 - loss: 0.0744\n",
            "Epoch 24: val_loss did not improve from 0.21438\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 72ms/step - accuracy: 0.9716 - loss: 0.0745 - val_accuracy: 0.9021 - val_loss: 0.2575\n",
            "Epoch 25/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.9747 - loss: 0.0680\n",
            "Epoch 25: val_loss did not improve from 0.21438\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 100ms/step - accuracy: 0.9746 - loss: 0.0681 - val_accuracy: 0.9094 - val_loss: 0.2673\n",
            "Epoch 26/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9714 - loss: 0.0667\n",
            "Epoch 26: val_loss did not improve from 0.21438\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 0.9715 - loss: 0.0666 - val_accuracy: 0.9083 - val_loss: 0.2938\n",
            "Epoch 27/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9731 - loss: 0.0581\n",
            "Epoch 27: val_loss did not improve from 0.21438\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 0.9731 - loss: 0.0583 - val_accuracy: 0.9146 - val_loss: 0.2746\n",
            "Epoch 28/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.9645 - loss: 0.0860\n",
            "Epoch 28: val_loss did not improve from 0.21438\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 101ms/step - accuracy: 0.9645 - loss: 0.0860 - val_accuracy: 0.9292 - val_loss: 0.2541\n",
            "Epoch 29/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9793 - loss: 0.0545\n",
            "Epoch 29: val_loss did not improve from 0.21438\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 0.9793 - loss: 0.0544 - val_accuracy: 0.9281 - val_loss: 0.2652\n",
            "Epoch 30/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9899 - loss: 0.0279\n",
            "Epoch 30: val_loss did not improve from 0.21438\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 0.9898 - loss: 0.0280 - val_accuracy: 0.9240 - val_loss: 0.3144\n",
            "Epoch 31/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.9857 - loss: 0.0437\n",
            "Epoch 31: val_loss did not improve from 0.21438\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 103ms/step - accuracy: 0.9856 - loss: 0.0438 - val_accuracy: 0.9208 - val_loss: 0.3545\n",
            "Epoch 32/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9833 - loss: 0.0452\n",
            "Epoch 32: val_loss did not improve from 0.21438\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 71ms/step - accuracy: 0.9833 - loss: 0.0453 - val_accuracy: 0.9167 - val_loss: 0.3298\n",
            "Epoch 33/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9870 - loss: 0.0398\n",
            "Epoch 33: val_loss did not improve from 0.21438\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 95ms/step - accuracy: 0.9870 - loss: 0.0398 - val_accuracy: 0.9292 - val_loss: 0.2849\n",
            "Epoch 34/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9904 - loss: 0.0310\n",
            "Epoch 34: val_loss did not improve from 0.21438\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 75ms/step - accuracy: 0.9903 - loss: 0.0311 - val_accuracy: 0.9062 - val_loss: 0.4387\n",
            "Epoch 35/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.9800 - loss: 0.0577\n",
            "Epoch 35: val_loss did not improve from 0.21438\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - accuracy: 0.9800 - loss: 0.0577 - val_accuracy: 0.9115 - val_loss: 0.2996\n",
            "Epoch 36/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.9872 - loss: 0.0341\n",
            "Epoch 36: val_loss did not improve from 0.21438\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 84ms/step - accuracy: 0.9872 - loss: 0.0341 - val_accuracy: 0.9292 - val_loss: 0.2981\n",
            "Epoch 37/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.9941 - loss: 0.0225\n",
            "Epoch 37: val_loss did not improve from 0.21438\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - accuracy: 0.9940 - loss: 0.0225 - val_accuracy: 0.9198 - val_loss: 0.3042\n",
            "Epoch 38/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9913 - loss: 0.0289\n",
            "Epoch 38: val_loss did not improve from 0.21438\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 91ms/step - accuracy: 0.9913 - loss: 0.0289 - val_accuracy: 0.9094 - val_loss: 0.3943\n",
            "Epoch 39/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9946 - loss: 0.0163\n",
            "Epoch 39: val_loss did not improve from 0.21438\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 70ms/step - accuracy: 0.9946 - loss: 0.0163 - val_accuracy: 0.9250 - val_loss: 0.3567\n",
            "Epoch 40/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.9973 - loss: 0.0111\n",
            "Epoch 40: val_loss did not improve from 0.21438\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 98ms/step - accuracy: 0.9973 - loss: 0.0111 - val_accuracy: 0.9208 - val_loss: 0.4074\n",
            "Epoch 41/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9909 - loss: 0.0257\n",
            "Epoch 41: val_loss did not improve from 0.21438\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 0.9908 - loss: 0.0257 - val_accuracy: 0.9146 - val_loss: 0.4408\n",
            "Epoch 42/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9915 - loss: 0.0263\n",
            "Epoch 42: val_loss did not improve from 0.21438\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 70ms/step - accuracy: 0.9915 - loss: 0.0263 - val_accuracy: 0.9167 - val_loss: 0.4267\n",
            "Epoch 43/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.9928 - loss: 0.0192\n",
            "Epoch 43: val_loss did not improve from 0.21438\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 102ms/step - accuracy: 0.9927 - loss: 0.0193 - val_accuracy: 0.9104 - val_loss: 0.5368\n",
            "Epoch 44/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9887 - loss: 0.0305\n",
            "Epoch 44: val_loss did not improve from 0.21438\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 0.9887 - loss: 0.0306 - val_accuracy: 0.9250 - val_loss: 0.3473\n",
            "Epoch 45/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9901 - loss: 0.0254\n",
            "Epoch 45: val_loss did not improve from 0.21438\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 0.9901 - loss: 0.0255 - val_accuracy: 0.9146 - val_loss: 0.3493\n",
            "Epoch 46/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9959 - loss: 0.0144\n",
            "Epoch 46: val_loss did not improve from 0.21438\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 95ms/step - accuracy: 0.9959 - loss: 0.0145 - val_accuracy: 0.9187 - val_loss: 0.3844\n",
            "Epoch 47/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9979 - loss: 0.0103\n",
            "Epoch 47: val_loss did not improve from 0.21438\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 0.9979 - loss: 0.0103 - val_accuracy: 0.9271 - val_loss: 0.4388\n",
            "Epoch 48/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9960 - loss: 0.0114\n",
            "Epoch 48: val_loss did not improve from 0.21438\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 77ms/step - accuracy: 0.9959 - loss: 0.0115 - val_accuracy: 0.9187 - val_loss: 0.4127\n",
            "Epoch 49/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.9972 - loss: 0.0068\n",
            "Epoch 49: val_loss did not improve from 0.21438\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 88ms/step - accuracy: 0.9972 - loss: 0.0068 - val_accuracy: 0.9135 - val_loss: 0.4744\n",
            "Epoch 50/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.9951 - loss: 0.0109\n",
            "Epoch 50: val_loss did not improve from 0.21438\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 86ms/step - accuracy: 0.9951 - loss: 0.0109 - val_accuracy: 0.9177 - val_loss: 0.5102\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loaded best model from /content/drive/MyDrive/mtb_project/checkpoints_global/best_model_20250629-193848.h5\n",
            "\n",
            "Test Loss: 0.2012\n",
            "Test Accuracy: 0.9050\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n",
            "\n",
            "Classification Report:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Non-Action (0)       0.98      0.89      0.93       900\n",
            "    Action (1)       0.74      0.96      0.83       300\n",
            "\n",
            "      accuracy                           0.91      1200\n",
            "     macro avg       0.86      0.92      0.88      1200\n",
            "  weighted avg       0.92      0.91      0.91      1200\n",
            "\n",
            "Confusion matrix plot saved to /content/drive/MyDrive/mtb_project/reports_global/confusion_matrix_binary_20250629-193848.png\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final binary model saved to /content/drive/MyDrive/mtb_project/final_models_global/final_binary_model_20250629-193848.h5\n",
            "Training report saved to /content/drive/MyDrive/mtb_project/reports_global/report_binary_20250629-193848.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luvQquTrGtxS"
      },
      "source": [
        "##Model training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EK4PkEMQL3ac"
      },
      "source": [
        "Schritt-für-Schritt Erklärung\n",
        "\n",
        "  **1. Daten zusammenführen**\n",
        "\n",
        "    Alle Sessions werden zu einem großen Datensatz verbunden, damit das Modell aus allen Beispielen lernt.\n",
        "\n",
        " **2. Label-Encoding**\n",
        "\n",
        "\n",
        "    Die Labels (z.B. verschiedene Aktivitäten) werden in numerische Werte umgewandelt, da das Modell nur mit Zahlen arbeitet.\n",
        "\n",
        " **3. Trainings- und Validierungs-Split**\n",
        "\n",
        "    Der Datensatz wird in Training (90%) und Validation (10%) aufgeteilt. Validation wird genutzt, um das Modell während des Trainings zu überprüfen.\n",
        "\n",
        "  **4. Modell erstellen**\n",
        "\n",
        "    Das Modell kombiniert Convolutional Layers (um lokale Muster in den Zeitreihen zu erkennen) mit LSTM (um zeitliche Abhängigkeiten zu lernen). Dropout wird eingesetzt, um Überanpassung zu vermeiden.\n",
        "\n",
        "  **5. Checkpoint Callback**\n",
        "\n",
        "    Während des Trainings werden Modelle nach jeder Epoche gespeichert (nur die besten, basierend auf Validierungsleistung).\n",
        "\n",
        "  **6. Training**\n",
        "  \n",
        "    Das Modell lernt über 50 Epochen, wobei Trainings- und Validierungsdaten genutzt werden.\n",
        "\n",
        "  **7. Finales Modell speichern**\n",
        "\n",
        "    Das finale Modell wird nach dem Training gespeichert,\n",
        "    um es später laden und nutzen zu können.\n",
        "\n",
        "  **8. Evaluation auf Validierungsdaten**\n",
        "\n",
        "    Das Modell wird auf den Validation-Daten getestet,\n",
        "    um die Genauigkeit zu ermitteln.\n",
        "\n",
        "  **9.  Vorhersagen erzeugen**\n",
        "\n",
        "    Die Wahrscheinlichkeiten für jede Klasse werden ermittelt und in Klassen umgewandelt (höchste Wahrscheinlichkeit = Vorhersage).\n",
        "\n",
        "  **10.  Labels prüfen**\n",
        "\n",
        "    Nur die tatsächlich in den Validierungsdaten vorhandenen Klassen werden für den Bericht verwendet.\n",
        "\n",
        " **11.  Classification Report**\n",
        "\n",
        "    Präzision, Recall, F1-Score und Support für jede Klasse werden ausgegeben — wichtige Kennzahlen für die Modellgüte.\n",
        "\n",
        "  **12.  Confusion Matrix**\n",
        "\n",
        "    Visualisiert die Fehler des Modells,\n",
        "    zeigt welche Klassen oft verwechselt werden.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRxeqKmSL5-0"
      },
      "source": [
        "##ML-Model Train Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8T-j67ejTEy9",
        "outputId": "74290dd3-59d3-42d5-b44b-a12107bb0177"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m979/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9666 - loss: 0.1407\n",
            "Epoch 1: val_loss improved from inf to 0.11582, saving model to /content/drive/MyDrive/mtb_project/checkpoints_global/global_epoch_01.keras\n",
            "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 44ms/step - accuracy: 0.9666 - loss: 0.1407 - val_accuracy: 0.9754 - val_loss: 0.1158\n",
            "Epoch 2/50\n",
            "\u001b[1m979/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9758 - loss: 0.1158\n",
            "Epoch 2: val_loss did not improve from 0.11582\n",
            "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 42ms/step - accuracy: 0.9758 - loss: 0.1158 - val_accuracy: 0.9754 - val_loss: 0.1172\n",
            "Epoch 3/50\n",
            "\u001b[1m979/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9756 - loss: 0.1163\n",
            "Epoch 3: val_loss did not improve from 0.11582\n",
            "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 40ms/step - accuracy: 0.9756 - loss: 0.1163 - val_accuracy: 0.9754 - val_loss: 0.1164\n",
            "Epoch 4/50\n",
            "\u001b[1m978/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9745 - loss: 0.1204\n",
            "Epoch 4: val_loss improved from 0.11582 to 0.11554, saving model to /content/drive/MyDrive/mtb_project/checkpoints_global/global_epoch_04.keras\n",
            "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 43ms/step - accuracy: 0.9745 - loss: 0.1204 - val_accuracy: 0.9754 - val_loss: 0.1155\n",
            "Epoch 5/50\n",
            "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9750 - loss: 0.1189\n",
            "Epoch 5: val_loss did not improve from 0.11554\n",
            "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 42ms/step - accuracy: 0.9750 - loss: 0.1189 - val_accuracy: 0.9754 - val_loss: 0.1170\n",
            "Epoch 6/50\n",
            "\u001b[1m978/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9755 - loss: 0.1162\n",
            "Epoch 6: val_loss improved from 0.11554 to 0.11552, saving model to /content/drive/MyDrive/mtb_project/checkpoints_global/global_epoch_06.keras\n",
            "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 44ms/step - accuracy: 0.9755 - loss: 0.1162 - val_accuracy: 0.9754 - val_loss: 0.1155\n",
            "Epoch 7/50\n",
            "\u001b[1m978/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9771 - loss: 0.1113\n",
            "Epoch 7: val_loss did not improve from 0.11552\n",
            "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 42ms/step - accuracy: 0.9771 - loss: 0.1113 - val_accuracy: 0.9754 - val_loss: 0.1158\n",
            "Epoch 8/50\n",
            "\u001b[1m978/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9753 - loss: 0.1169\n",
            "Epoch 8: val_loss did not improve from 0.11552\n",
            "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 42ms/step - accuracy: 0.9753 - loss: 0.1169 - val_accuracy: 0.9754 - val_loss: 0.1163\n",
            "Epoch 9/50\n",
            "\u001b[1m978/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9753 - loss: 0.1169\n",
            "Epoch 9: val_loss did not improve from 0.11552\n",
            "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 42ms/step - accuracy: 0.9753 - loss: 0.1169 - val_accuracy: 0.9754 - val_loss: 0.1170\n",
            "Epoch 10/50\n",
            "\u001b[1m979/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9750 - loss: 0.1182\n",
            "Epoch 10: val_loss did not improve from 0.11552\n",
            "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 42ms/step - accuracy: 0.9750 - loss: 0.1181 - val_accuracy: 0.9754 - val_loss: 0.1197\n",
            "Epoch 11/50\n",
            "\u001b[1m979/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9750 - loss: 0.1184\n",
            "Epoch 11: val_loss did not improve from 0.11552\n",
            "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 43ms/step - accuracy: 0.9750 - loss: 0.1184 - val_accuracy: 0.9754 - val_loss: 0.1163\n",
            "Epoch 12/50\n",
            "\u001b[1m979/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9756 - loss: 0.1153\n",
            "Epoch 12: val_loss did not improve from 0.11552\n",
            "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 43ms/step - accuracy: 0.9756 - loss: 0.1153 - val_accuracy: 0.9754 - val_loss: 0.1174\n",
            "Epoch 13/50\n",
            "\u001b[1m979/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9755 - loss: 0.1165\n",
            "Epoch 13: val_loss did not improve from 0.11552\n",
            "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 42ms/step - accuracy: 0.9755 - loss: 0.1165 - val_accuracy: 0.9754 - val_loss: 0.1155\n",
            "Epoch 14/50\n",
            "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9765 - loss: 0.1130\n",
            "Epoch 14: val_loss improved from 0.11552 to 0.11528, saving model to /content/drive/MyDrive/mtb_project/checkpoints_global/global_epoch_14.keras\n",
            "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 43ms/step - accuracy: 0.9765 - loss: 0.1130 - val_accuracy: 0.9754 - val_loss: 0.1153\n",
            "Epoch 15/50\n",
            "\u001b[1m979/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9766 - loss: 0.1118\n",
            "Epoch 15: val_loss did not improve from 0.11528\n",
            "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 42ms/step - accuracy: 0.9766 - loss: 0.1118 - val_accuracy: 0.9754 - val_loss: 0.1156\n",
            "Epoch 16/50\n",
            "\u001b[1m979/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9763 - loss: 0.1130\n",
            "Epoch 16: val_loss did not improve from 0.11528\n",
            "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 42ms/step - accuracy: 0.9763 - loss: 0.1130 - val_accuracy: 0.9754 - val_loss: 0.1154\n",
            "Epoch 17/50\n",
            "\u001b[1m979/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9761 - loss: 0.1139\n",
            "Epoch 17: val_loss did not improve from 0.11528\n",
            "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 42ms/step - accuracy: 0.9761 - loss: 0.1139 - val_accuracy: 0.9754 - val_loss: 0.1153\n",
            "Epoch 18/50\n",
            "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9746 - loss: 0.1199\n",
            "Epoch 18: val_loss did not improve from 0.11528\n",
            "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 41ms/step - accuracy: 0.9746 - loss: 0.1199 - val_accuracy: 0.9754 - val_loss: 0.1165\n",
            "Epoch 19/50\n",
            "\u001b[1m978/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9753 - loss: 0.1174\n",
            "Epoch 19: val_loss did not improve from 0.11528\n",
            "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 42ms/step - accuracy: 0.9753 - loss: 0.1174 - val_accuracy: 0.9754 - val_loss: 0.1155\n",
            "Epoch 20/50\n",
            "\u001b[1m978/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9758 - loss: 0.1153\n",
            "Epoch 20: val_loss did not improve from 0.11528\n",
            "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 42ms/step - accuracy: 0.9758 - loss: 0.1153 - val_accuracy: 0.9754 - val_loss: 0.1169\n",
            "Epoch 21/50\n",
            "\u001b[1m979/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9759 - loss: 0.1144\n",
            "Epoch 21: val_loss did not improve from 0.11528\n",
            "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 43ms/step - accuracy: 0.9759 - loss: 0.1144 - val_accuracy: 0.9754 - val_loss: 0.1179\n",
            "Epoch 22/50\n",
            "\u001b[1m979/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9760 - loss: 0.1141\n",
            "Epoch 22: val_loss did not improve from 0.11528\n",
            "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 43ms/step - accuracy: 0.9760 - loss: 0.1141 - val_accuracy: 0.9754 - val_loss: 0.1153\n",
            "Epoch 23/50\n",
            "\u001b[1m978/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9759 - loss: 0.1146\n",
            "Epoch 23: val_loss did not improve from 0.11528\n",
            "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 43ms/step - accuracy: 0.9759 - loss: 0.1146 - val_accuracy: 0.9754 - val_loss: 0.1186\n",
            "Epoch 24/50\n",
            "\u001b[1m979/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9761 - loss: 0.1143\n",
            "Epoch 24: val_loss did not improve from 0.11528\n",
            "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 43ms/step - accuracy: 0.9761 - loss: 0.1143 - val_accuracy: 0.9754 - val_loss: 0.1163\n",
            "Epoch 25/50\n",
            "\u001b[1m979/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9757 - loss: 0.1152\n",
            "Epoch 25: val_loss did not improve from 0.11528\n",
            "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 44ms/step - accuracy: 0.9757 - loss: 0.1152 - val_accuracy: 0.9754 - val_loss: 0.1170\n",
            "Epoch 26/50\n",
            "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9744 - loss: 0.1203\n",
            "Epoch 26: val_loss did not improve from 0.11528\n",
            "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 43ms/step - accuracy: 0.9744 - loss: 0.1203 - val_accuracy: 0.9754 - val_loss: 0.1155\n",
            "Epoch 27/50\n",
            "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9762 - loss: 0.1136\n",
            "Epoch 27: val_loss did not improve from 0.11528\n",
            "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 43ms/step - accuracy: 0.9762 - loss: 0.1136 - val_accuracy: 0.9754 - val_loss: 0.1153\n",
            "Epoch 28/50\n",
            "\u001b[1m979/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9759 - loss: 0.1144\n",
            "Epoch 28: val_loss did not improve from 0.11528\n",
            "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 43ms/step - accuracy: 0.9759 - loss: 0.1144 - val_accuracy: 0.9754 - val_loss: 0.1157\n",
            "Epoch 29/50\n",
            "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9753 - loss: 0.1165\n",
            "Epoch 29: val_loss did not improve from 0.11528\n",
            "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 43ms/step - accuracy: 0.9753 - loss: 0.1165 - val_accuracy: 0.9754 - val_loss: 0.1153\n",
            "Epoch 30/50\n",
            "\u001b[1m979/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9770 - loss: 0.1103\n",
            "Epoch 30: val_loss did not improve from 0.11528\n",
            "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 43ms/step - accuracy: 0.9770 - loss: 0.1103 - val_accuracy: 0.9754 - val_loss: 0.1153\n",
            "Epoch 31/50\n",
            "\u001b[1m978/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9763 - loss: 0.1127\n",
            "Epoch 31: val_loss did not improve from 0.11528\n",
            "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 42ms/step - accuracy: 0.9763 - loss: 0.1127 - val_accuracy: 0.9754 - val_loss: 0.1154\n",
            "Epoch 32/50\n",
            "\u001b[1m979/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9753 - loss: 0.1169\n",
            "Epoch 32: val_loss did not improve from 0.11528\n",
            "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 43ms/step - accuracy: 0.9753 - loss: 0.1169 - val_accuracy: 0.9754 - val_loss: 0.1161\n",
            "Epoch 33/50\n",
            "\u001b[1m978/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9753 - loss: 0.1166\n",
            "Epoch 33: val_loss did not improve from 0.11528\n",
            "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 43ms/step - accuracy: 0.9753 - loss: 0.1166 - val_accuracy: 0.9754 - val_loss: 0.1154\n",
            "Epoch 34/50\n",
            "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9751 - loss: 0.1174\n",
            "Epoch 34: val_loss did not improve from 0.11528\n",
            "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 43ms/step - accuracy: 0.9751 - loss: 0.1174 - val_accuracy: 0.9754 - val_loss: 0.1167\n",
            "Epoch 35/50\n",
            "\u001b[1m979/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9758 - loss: 0.1149\n",
            "Epoch 35: val_loss did not improve from 0.11528\n",
            "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 43ms/step - accuracy: 0.9758 - loss: 0.1149 - val_accuracy: 0.9754 - val_loss: 0.1156\n",
            "Epoch 36/50\n",
            "\u001b[1m979/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9748 - loss: 0.1183\n",
            "Epoch 36: val_loss did not improve from 0.11528\n",
            "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 43ms/step - accuracy: 0.9748 - loss: 0.1183 - val_accuracy: 0.9754 - val_loss: 0.1153\n",
            "Epoch 37/50\n",
            "\u001b[1m979/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9753 - loss: 0.1164\n",
            "Epoch 37: val_loss did not improve from 0.11528\n",
            "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 43ms/step - accuracy: 0.9753 - loss: 0.1164 - val_accuracy: 0.9754 - val_loss: 0.1153\n",
            "Epoch 38/50\n",
            "\u001b[1m979/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9747 - loss: 0.1187\n",
            "Epoch 38: val_loss did not improve from 0.11528\n",
            "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 43ms/step - accuracy: 0.9747 - loss: 0.1187 - val_accuracy: 0.9754 - val_loss: 0.1159\n",
            "Epoch 39/50\n",
            "\u001b[1m979/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9751 - loss: 0.1175\n",
            "Epoch 39: val_loss did not improve from 0.11528\n",
            "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 43ms/step - accuracy: 0.9751 - loss: 0.1175 - val_accuracy: 0.9754 - val_loss: 0.1153\n",
            "Epoch 40/50\n",
            "\u001b[1m979/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9752 - loss: 0.1170\n",
            "Epoch 40: val_loss did not improve from 0.11528\n",
            "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 42ms/step - accuracy: 0.9752 - loss: 0.1170 - val_accuracy: 0.9754 - val_loss: 0.1165\n",
            "Epoch 41/50\n",
            "\u001b[1m979/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9752 - loss: 0.1172\n",
            "Epoch 41: val_loss did not improve from 0.11528\n",
            "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 42ms/step - accuracy: 0.9752 - loss: 0.1172 - val_accuracy: 0.9754 - val_loss: 0.1154\n",
            "Epoch 42/50\n",
            "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9752 - loss: 0.1170\n",
            "Epoch 42: val_loss did not improve from 0.11528\n",
            "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 43ms/step - accuracy: 0.9752 - loss: 0.1170 - val_accuracy: 0.9754 - val_loss: 0.1153\n",
            "Epoch 43/50\n",
            "\u001b[1m979/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9752 - loss: 0.1169\n",
            "Epoch 43: val_loss did not improve from 0.11528\n",
            "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 43ms/step - accuracy: 0.9752 - loss: 0.1169 - val_accuracy: 0.9754 - val_loss: 0.1153\n",
            "Epoch 44/50\n",
            "\u001b[1m979/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9756 - loss: 0.1153\n",
            "Epoch 44: val_loss did not improve from 0.11528\n",
            "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 41ms/step - accuracy: 0.9756 - loss: 0.1153 - val_accuracy: 0.9754 - val_loss: 0.1157\n",
            "Epoch 45/50\n",
            "\u001b[1m978/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9757 - loss: 0.1151\n",
            "Epoch 45: val_loss did not improve from 0.11528\n",
            "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 41ms/step - accuracy: 0.9757 - loss: 0.1151 - val_accuracy: 0.9754 - val_loss: 0.1153\n",
            "Epoch 46/50\n",
            "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9753 - loss: 0.1166\n",
            "Epoch 46: val_loss did not improve from 0.11528\n",
            "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 42ms/step - accuracy: 0.9753 - loss: 0.1166 - val_accuracy: 0.9754 - val_loss: 0.1153\n",
            "Epoch 47/50\n",
            "\u001b[1m979/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9761 - loss: 0.1136\n",
            "Epoch 47: val_loss did not improve from 0.11528\n",
            "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 42ms/step - accuracy: 0.9761 - loss: 0.1136 - val_accuracy: 0.9754 - val_loss: 0.1153\n",
            "Epoch 48/50\n",
            "\u001b[1m979/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9758 - loss: 0.1148\n",
            "Epoch 48: val_loss did not improve from 0.11528\n",
            "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 41ms/step - accuracy: 0.9758 - loss: 0.1148 - val_accuracy: 0.9754 - val_loss: 0.1153\n",
            "Epoch 49/50\n",
            "\u001b[1m979/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9758 - loss: 0.1151\n",
            "Epoch 49: val_loss did not improve from 0.11528\n",
            "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 42ms/step - accuracy: 0.9758 - loss: 0.1151 - val_accuracy: 0.9754 - val_loss: 0.1164\n",
            "Epoch 50/50\n",
            "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9750 - loss: 0.1180\n",
            "Epoch 50: val_loss did not improve from 0.11528\n",
            "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 41ms/step - accuracy: 0.9750 - loss: 0.1180 - val_accuracy: 0.9754 - val_loss: 0.1157\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step\n",
            "\n",
            "📄 Classification Report (Binary):\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Not Action       0.98      1.00      0.99      2264\n",
            "      Action       0.00      0.00      0.00        57\n",
            "\n",
            "    accuracy                           0.98      2321\n",
            "   macro avg       0.49      0.50      0.49      2321\n",
            "weighted avg       0.95      0.98      0.96      2321\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Validation Accuracy: 0.98\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import time\n",
        "import random\n",
        "\n",
        "timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "# 💾 Speicherpfade anlegen\n",
        "checkpoint_dir = \"/content/drive/MyDrive/mtb_project/checkpoints_global\"\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "final_model_dir = \"/content/drive/MyDrive/mtb_project/final_models_global\"\n",
        "os.makedirs(final_model_dir, exist_ok=True)\n",
        "report_dir = \"/content/drive/MyDrive/mtb_project/reports_global\"\n",
        "os.makedirs(report_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "#Data Augmentation\n",
        "def augment_time_series_multiclass(X, y, augment_factor=2, jitter_std=0.01, scale_range=(0.9, 1.1),\n",
        "                                   permute_segments=3, apply_mixup=False, seed=42):\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "    N, T, F = X.shape\n",
        "    X_aug = []\n",
        "    y_aug = []\n",
        "\n",
        "    def jitter(x):\n",
        "        return x + np.random.normal(loc=0., scale=jitter_std, size=x.shape)\n",
        "\n",
        "    def scale(x):\n",
        "        factor = np.random.uniform(*scale_range)\n",
        "        return x * factor\n",
        "\n",
        "    def permute(x):\n",
        "        segs = np.array_split(x, permute_segments)\n",
        "        np.random.shuffle(segs)\n",
        "        return np.concatenate(segs, axis=0)\n",
        "\n",
        "    def hello_ruven():\n",
        "      print(\"Hallo Ruven, du kleiner Schlawiner!\")\n",
        "\n",
        "    def mixup(x1, x2, y1, y2):\n",
        "        alpha = np.random.beta(0.4, 0.4)\n",
        "        x_mix = alpha * x1 + (1 - alpha) * x2\n",
        "        return x_mix, y1 if np.random.rand() < 0.5 else y2\n",
        "\n",
        "    for i in range(N):\n",
        "        for _ in range(augment_factor):\n",
        "            x_aug = X[i]\n",
        "\n",
        "            if np.random.rand() < 0.5:\n",
        "                x_aug = jitter(x_aug)\n",
        "            if np.random.rand() < 0.5:\n",
        "                x_aug = scale(x_aug)\n",
        "            if np.random.rand() < 0.3:\n",
        "                x_aug = permute(x_aug)\n",
        "\n",
        "            if apply_mixup and np.random.rand() < 0.3:\n",
        "                idx2 = np.random.randint(0, N)\n",
        "                x_aug, y_mix = mixup(x_aug, X[idx2], y[i], y[idx2])\n",
        "                y_aug.append(y_mix)\n",
        "            else:\n",
        "                y_aug.append(y[i])\n",
        "\n",
        "            X_aug.append(x_aug)\n",
        "\n",
        "    X_aug = np.array(X_aug)\n",
        "    y_aug = np.array(y_aug)\n",
        "\n",
        "    X_combined = np.concatenate([X, X_aug])\n",
        "    y_combined = np.concatenate([y, y_aug])\n",
        "\n",
        "    return X_combined, y_combined\n",
        "\n",
        "\n",
        "# 1. Daten vorbereiten: alle Sessions zusammenführen\n",
        "X_all = np.concatenate(sessions_X)\n",
        "y_all = np.concatenate(sessions_y)\n",
        "\n",
        "# 2. Labels binär umwandeln: \"Action\" = 1, alles andere = 0\n",
        "y_all_binary = np.array([1 if label == \"Action\" else 0 for label in y_all])\n",
        "\n",
        "# 3. Trainings- und Validierungsdaten splitten (z.B. 90% Training, 10% Validation)\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_all, y_all_binary, test_size=0.1, random_state=42, stratify=y_all_binary\n",
        ")\n",
        "\n",
        "\n",
        "# Augmentierung auf Trainingsdaten anwenden\n",
        "X_train, y_train = augment_time_series_multiclass(X_train, y_train, augment_factor=2, jitter_std=0.01, scale_range=(0.9, 1.1),\n",
        "                                   permute_segments=3, apply_mixup=False, seed=42)\n",
        "\n",
        "\n",
        "# 4. Modell definieren (CNN + LSTM Architektur) - Binary Output: 1 Neuron mit Sigmoid\n",
        "model = models.Sequential([\n",
        "    layers.Conv1D(64, 3, activation='relu', input_shape=X_train.shape[1:]),\n",
        "    layers.Conv1D(64, 3, activation='relu'),\n",
        "    layers.MaxPooling1D(pool_size=2),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.LSTM(64),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(100, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')  # Ein Output für Binary Classification\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# 5. Callback für Checkpoints während Training\n",
        "checkpoint_cb = ModelCheckpoint(\n",
        "    filepath=os.path.join(checkpoint_dir, \"global_epoch_{epoch:02d}.keras\"),\n",
        "    save_best_only=True,\n",
        "    save_weights_only=False,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# 6. Training starten\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=50,\n",
        "    batch_size=64,\n",
        "    callbacks=[checkpoint_cb]\n",
        ")\n",
        "\n",
        "# 7. Finale Modell speichern\n",
        "model.save(os.path.join(final_model_dir, \"global_final_v4_binary_augment_f2.keras\"))\n",
        "\n",
        "# 8. Vorhersagen für Validierungsdaten (Wahrscheinlichkeiten)\n",
        "y_pred_probs = model.predict(X_val)\n",
        "\n",
        "# 9. Wahrscheinlichkeiten in Klassen (0 oder 1) umwandeln, Schwellenwert 0.5\n",
        "y_pred_binary = (y_pred_probs >= 0.5).astype(int).reshape(-1)\n",
        "\n",
        "# 10. Classification Report ausgeben\n",
        "print(\"\\n📄 Classification Report (Binary):\\n\")\n",
        "report = classification_report(y_val, y_pred_binary, target_names=['Not Action', 'Action'])\n",
        "print(report)\n",
        "\n",
        "# 11. Report als Textdatei speichern\n",
        "with open(os.path.join(report_dir, f\"classification_report_augmentf2_binary_{timestamp}.txt\"), \"w\") as f:\n",
        "    f.write(report)\n",
        "\n",
        "# 12. Confusion Matrix plotten und speichern\n",
        "cm = confusion_matrix(y_val, y_pred_binary)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Not Action', 'Action'])\n",
        "fig, ax = plt.subplots(figsize=(6, 4))\n",
        "disp.plot(ax=ax)\n",
        "plt.title(\"Confusion Matrix – Binary Model Data Augmentation f2\")\n",
        "plt.savefig(os.path.join(report_dir, f\"conf_matrix_augment_f2_binary_{timestamp}.png\"))\n",
        "plt.show()\n",
        "\n",
        "# 13. Evaluation auf Validierungsdaten\n",
        "val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
        "print(f\"\\n✅ Validation Accuracy: {val_acc:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpxJ7i_COef6"
      },
      "source": [
        "##Erklärung classification report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVRLqvXsOkF8"
      },
      "source": [
        "* Precision: Precision ist das Verhältnis der Anzahl von True Positives zur Gesamtzahl der positiven Vorhersagen. Wenn das Modell z. B. 100 Bäume erkannt hat und 90 korrekt gewesen wären, beträgt die Genauigkeit 90 Prozent.\n",
        "\n",
        "Precision = (True Positive)/(True Positive + False Positive)\n",
        "\n",
        "* Recall: Recall ist das Verhältnis der Anzahl von True Positives zur Gesamtzahl der realen (relevanten) Objekte. Wenn das Modell z. B. 75 Bäume auf einem Bild korrekt erkennt und es tatsächlich 100 Bäume auf dem Bild gibt, beträgt der Recall 75 Prozent.\n",
        "\n",
        "Recall = (True Positive)/(True Positive + False Negative)\n",
        "\n",
        "* F-Maß: Das F-Maß (auch \"F1-Score\") ist ein gewichteter Durchschnitt von Genauigkeit und Recall. Die Werte liegen zwischen 0 und 1, wobei 1 für die höchste Genauigkeit steht.\n",
        "\n",
        "F-Maß = (Precision × Recall)/[(Precision + Recall)/2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wv6yD7uMUvoz"
      },
      "source": [
        "##Csv export"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2NW1yW4CMJFn"
      },
      "outputs": [],
      "source": [
        "#evtl speichern als csv oder oben integrieren\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "\n",
        "# Ausgabe als Dictionary\n",
        "report_dict = classification_report(y_val, y_pred_binary, target_names=['Not Action', 'Action'], output_dict=True)\n",
        "\n",
        "# In DataFrame konvertieren\n",
        "report_df = pd.DataFrame(report_dict).transpose()\n",
        "\n",
        "# Speichern als CSV\n",
        "report_df.to_csv(os.path.join(report_dir, f\"classification_report_binary_{timestamp}.csv\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-yhvJmXzOjU"
      },
      "source": [
        "#🧾 Zusammenfassung Modeltraining\n",
        "##📊 1. Durchschnittliche Accuracy über alle Sessions:\n",
        "\n",
        "ist oben in code integriert, funktioniert irgendwie nicht danacht"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ZKwF6fOy75p"
      },
      "outputs": [],
      "source": [
        "#📊 1. Durchschnittliche Accuracy über alle Sessions:\n",
        "\n",
        "mean_acc = np.mean(all_accuracies)\n",
        "print(\"\\n📈 Zusammenfassung:\")\n",
        "for i, acc in enumerate(all_accuracies):\n",
        "    print(f\"  Session {i+1}: Accuracy = {acc:.2f}\")\n",
        "print(f\"\\n✅ Durchschnittliche Test-Accuracy über alle Sessions: {mean_acc:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Evqv6rIczcn0"
      },
      "source": [
        "##📁 2. CSV speichern (falls nicht schon vorhanden):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1AxzlH2XzXA9"
      },
      "outputs": [],
      "source": [
        "#📁 2. CSV speichern (falls nicht schon vorhanden):\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df_summary = pd.DataFrame(accuracy_summary)\n",
        "df_summary['Session'] = [f\"Session_{i+1}\" for i in range(len(all_accuracies))]\n",
        "df_summary.to_csv(\"/content/drive/MyDrive/mtb_project/session_accuracy_report.csv\", index=False)\n",
        "print(\"✅ Bericht gespeichert unter: session_accuracy_report.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJz6n-8PZWui"
      },
      "outputs": [],
      "source": [
        "os.makedirs(\"/content/drive/MyDrive/mtb_project/reports\", exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WbIb7duxZKhi"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import io\n",
        "\n",
        "# Klassifikationsbericht als Text speichern\n",
        "report_text = classification_report(y_test_enc, y_pred_classes, target_names=le.classes_)\n",
        "with open(f\"/content/drive/MyDrive/mtb_project/reports/{sess_name}_classification_report.txt\", \"w\") as f:\n",
        "    f.write(report_text)\n",
        "\n",
        "\n",
        "\n",
        "#confusion matrix als bild speicheern\n",
        "fig, ax = plt.subplots(figsize=(8,6))\n",
        "disp = ConfusionMatrixDisplay(cm, display_labels=le.classes_)\n",
        "disp.plot(ax=ax, xticks_rotation=45)\n",
        "plt.title(f\"Confusion Matrix – {sess_name}\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"/content/drive/MyDrive/mtb_project/reports/{sess_name}_confusion_matrix.png\")\n",
        "plt.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6M9hNEyTzn0"
      },
      "source": [
        "🧾 Zusammenfassung nach dem Training:\n",
        "\n",
        "Nach der Schleife kannst du am Ende folgendes hinzufügen, um einen Bericht zu erzeugen:\n",
        "\n",
        "📊 Bonus: CSV speichern (optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "g9eFJGGxTutz",
        "outputId": "7e0765df-5645-4ea0-ad23-c0b8026c998d"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'all_accuracies' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-bb964def7d64>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Durchschnittliche Accuracy über alle Sessions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmean_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_accuracies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n📈 Zusammenfassung:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_accuracies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"  Session {i+1}: Accuracy = {acc:.2f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'all_accuracies' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "# Durchschnittliche Accuracy über alle Sessions\n",
        "mean_acc = np.mean(all_accuracies)\n",
        "print(\"\\n📈 Zusammenfassung:\")\n",
        "for i, acc in enumerate(all_accuracies):\n",
        "    print(f\"  Session {i+1}: Accuracy = {acc:.2f}\")\n",
        "print(f\"\\n✅ Durchschnittliche Test-Accuracy über alle Sessions: {mean_acc:.2f}\")\n",
        "\n",
        "\n",
        "\n",
        "#📊 Bonus: CSV speichern (optional)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "summary = {'Session': [], 'Accuracy': []}\n",
        "for i, acc in enumerate(all_accuracies):\n",
        "    summary['Session'].append(f\"Session_{i+1}\")\n",
        "    summary['Accuracy'].append(acc)\n",
        "\n",
        "df_summary = pd.DataFrame(summary)\n",
        "df_summary.to_csv(\"session_accuracy_report.csv\", index=False)\n",
        "print(\"📁 Bericht gespeichert als session_accuracy_report.csv\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbaE9UFeMQ8r"
      },
      "source": [
        "#💾 II. Modell speichern & später wieder laden (z. B. nach Training)\n",
        "\n",
        "##🔐 Speichern mit TensorFlow/**Keras**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9f0wu8rYM2P3"
      },
      "outputs": [],
      "source": [
        "# Nach dem Training:\n",
        "#speichert mit timestamp\n",
        "#model.save(\"SenseCap_Eventdetection_Model.keras\")  # speichert nur in colab kurzzeitig\n",
        "import time\n",
        "timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "model.save(f\"/content/drive/MyDrive/ML-MTB-Modell/ML-Model_trained/SenseCap_Model_binary{timestamp}.keras\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fe6SLk39NNOz"
      },
      "source": [
        "##🔄 Laden\n",
        "\n",
        "Das speichert das gesamte Modell inkl. Architektur, Gewichten und Optimizer-Zustand –exakt da weitermachen, wo man aufgehört hast."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puTdBnHsNHsC",
        "outputId": "e01895fd-40b2-435b-a7f7-44950f5ebdf9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 24 variables whereas the saved optimizer has 2 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model(\"/content/drive/MyDrive/ML-MTB-Modell/ML-Model_trained/SenseCap_Eventdetection_Model1.keras\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "0FK9HYSaUOP0",
        "outputId": "0bb3586c-14d1-4009-e85c-573951307718"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'test_sessions_X' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-49eeb814a429>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mall_accuracies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sessions_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_sessions_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_sessions_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'test_sessions_X' is not defined"
          ]
        }
      ],
      "source": [
        "all_accuracies = []\n",
        "\n",
        "for i in range(len(test_sessions_X)):\n",
        "    X_test = test_sessions_X[i]\n",
        "    y_test = test_sessions_y[i]\n",
        "\n",
        "    _, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "    all_accuracies.append(acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "p3xuxyPOUOsO",
        "outputId": "599667da-0a6e-4934-f3dc-505a22c9d150"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'all_accuracies' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-bb964def7d64>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Durchschnittliche Accuracy über alle Sessions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmean_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_accuracies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n📈 Zusammenfassung:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_accuracies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"  Session {i+1}: Accuracy = {acc:.2f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'all_accuracies' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "# Durchschnittliche Accuracy über alle Sessions\n",
        "mean_acc = np.mean(all_accuracies)\n",
        "print(\"\\n📈 Zusammenfassung:\")\n",
        "for i, acc in enumerate(all_accuracies):\n",
        "    print(f\"  Session {i+1}: Accuracy = {acc:.2f}\")\n",
        "print(f\"\\n✅ Durchschnittliche Test-Accuracy über alle Sessions: {mean_acc:.2f}\")\n",
        "\n",
        "\n",
        "\n",
        "#📊 Bonus: CSV speichern (optional)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "summary = {'Session': [], 'Accuracy': []}\n",
        "for i, acc in enumerate(all_accuracies):\n",
        "    summary['Session'].append(f\"Session_{i+1}\")\n",
        "    summary['Accuracy'].append(acc)\n",
        "\n",
        "df_summary = pd.DataFrame(summary)\n",
        "df_summary.to_csv(\"session_accuracy_report.csv\", index=False)\n",
        "print(\"📁 Bericht gespeichert als session_accuracy_report.csv\")\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "kH_IAOvdE6R6",
        "cXQYTbV4RFPd",
        "luvQquTrGtxS"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}