{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPxUjE63hJdPcP0elsoPF+O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prinzessinmarlenifee/SenseCap/blob/main/SenseCap_v4_dataaugment_global_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Versuch 3: Single sheets ohne sync - Global Model\n",
        "\n",
        "\n",
        "\n",
        "Saveing model and checkpoints for Zwischenspeicherung\n",
        "\n",
        "CSV-sensor data sheet\n",
        "1.   wrist\n",
        "2.   seat\n",
        "3.  head\n",
        "-> 3 Sensoren, 9 Spalten\n",
        "-> checkt erste und zweite Zeile f√ºr header (da unterschiedlich)\n",
        "\n",
        "*   hot encoding for labeling\n",
        " Action, Pedaling, Resting, Pushing\n",
        "\n",
        " Summary at end with\n",
        "\n",
        "\n",
        "*   test accuracy\n",
        "*   confusion matrix\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "all data is stored in Drive\n",
        "\n"
      ],
      "metadata": {
        "id": "hKNNiSrdDEqF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model Choice\n",
        "‚úÖ Teil 2: Ist CNN + LSTM eine gute Architektur f√ºr IMU-Zeitreihendaten?\n",
        "\n",
        "Ja, das ist eine bew√§hrte Kombination ‚Äì besonders bei IMU-Daten (z.‚ÄØB. Accelerometer/Gyroscope), weil:\n",
        "üîé Warum CNN?\n",
        "\n",
        "    Erkennt lokale Muster in kurzen Zeitfenstern (z.‚ÄØB. Bewegungsphasen)\n",
        "\n",
        "    Spart Rechenzeit, da es weniger Parameter hat als ein reines LSTM\n",
        "\n",
        "üîÅ Warum LSTM?\n",
        "\n",
        "    Erkennt zeitliche Abh√§ngigkeiten (z.‚ÄØB. Bewegungsabfolgen)\n",
        "\n",
        "    Ideal f√ºr sequentielle Daten, wie du sie hast\n",
        "\n",
        "‚úÖ Alternativen oder Erweiterungen\n",
        "\n",
        "Falls du sp√§ter mehr Leistung brauchst:\n",
        "\n",
        "    Bidirectional LSTM ‚Üí besser f√ºr symmetrische Bewegungsabfolgen\n",
        "\n",
        "    Residual CNN Blocks ‚Üí f√ºr tiefere Netzwerke\n",
        "\n",
        "    Transformer ‚Üí wenn du sehr viele Daten und lange Sequenzen hast"
      ],
      "metadata": {
        "id": "cXQYTbV4RFPd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "Hk6qFLbhDJlr",
        "outputId": "276e23f2-4ad8-4cd2-b05e-3829c18a806e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Mountpoint must not already contain files",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-c8841ca53dd3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# mount drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    197\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mountpoint must not be a symlink'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mountpoint must not already contain files'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mountpoint must either be a directory or not exist'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Mountpoint must not already contain files"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import packages\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "layers = tf.keras.layers\n",
        "models = tf.keras.models\n"
      ],
      "metadata": {
        "id": "OtTD-qyzDXoH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- PARAMETER ---\n",
        "sampling_rate = 60       # 60 Hz nach SDI-Algorithmus\n",
        "window_size = 60         # 1 Sekunde = 60 Frames\n",
        "step_size = 30           # 50% √úberlappung\n",
        "\n",
        "# Basisverzeichnis (sollte die 18 Session-Ordner enthalten)\n",
        "base_dir = '/content/drive/MyDrive/ML-MTB-Modell/IMU-Sessions/'\n"
      ],
      "metadata": {
        "id": "8d9oN1zpDqKo"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sessions einlesen"
      ],
      "metadata": {
        "id": "bcvlHHFOD36z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "session_dirs = sorted([\n",
        "    d for d in os.listdir(base_dir)\n",
        "    if os.path.isdir(os.path.join(base_dir, d))\n",
        "])\n",
        "print(f\"Gefundene Sessions: {len(session_dirs)} -> {session_dirs}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "sqMHmK7wD2YX",
        "outputId": "bcd65438-28a0-43bd-a0ec-826b303b4579"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/ML-MTB-Modell/IMU-Sessions/'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-3bc1a431e7bf>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m session_dirs = sorted([\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0md\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m ])\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Gefundene Sessions: {len(session_dirs)} -> {session_dirs}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/ML-MTB-Modell/IMU-Sessions/'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fuktionen zum LAbel-Parsing und Datei finden"
      ],
      "metadata": {
        "id": "8puFV7gaEAMI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5.1 parse_hot_labels: Liest die _hot.json-Datei ein, erstellt f√ºr jeden Frame ein Label\n",
        "def parse_hot_labels(json_path, total_frames):\n",
        "    with open(json_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "    entries = data['button_presses'].strip().split(';')\n",
        "\n",
        "    label_changes = []\n",
        "    for entry in entries:\n",
        "        if ':' in entry:\n",
        "            label, frame = entry.strip().split(':')\n",
        "            label = label.strip()\n",
        "            # Korrigiere evtl. \"Peadling\" ‚Üí \"Pedaling\"\n",
        "            if label.lower() == 'peadling':\n",
        "                label = 'Pedaling'\n",
        "            label_changes.append((int(frame.strip()), label))\n",
        "\n",
        "    frame_labels = ['Unknown'] * total_frames\n",
        "    for i, (start_frame, label) in enumerate(label_changes):\n",
        "        end_frame = label_changes[i + 1][0] if i + 1 < len(label_changes) else total_frames\n",
        "        for f in range(start_frame, min(end_frame, total_frames)):\n",
        "            frame_labels[f] = label\n",
        "    return frame_labels\n",
        "\n",
        "# 5.2 find_sensor_file: Findet CSV-Datei, deren Name mit dem Prefix beginnt (Head_, Wrist_, Seat_)\n",
        "def find_sensor_file(folder, prefix):\n",
        "    for f in os.listdir(folder):\n",
        "        if f.lower().startswith(prefix.lower()):\n",
        "            return os.path.join(folder, f)\n",
        "    raise FileNotFoundError(f\"‚ùå Keine Datei mit Prefix '{prefix}' in {folder} gefunden.\")\n",
        "\n",
        "# 5.3 find_hot_file: Findet JSON-Datei, deren Name auf \"_hot.json\" endet\n",
        "def find_hot_file(folder):\n",
        "    for f in os.listdir(folder):\n",
        "        if f.lower().endswith('_hot.json'):\n",
        "            return os.path.join(folder, f)\n",
        "    raise FileNotFoundError(f\"‚ùå Keine Datei mit Suffix '_hot.json' in {folder} gefunden.\")\n"
      ],
      "metadata": {
        "id": "lo3wDSUeD-TT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Fensterung f√ºr drei Sensoren kombinieren"
      ],
      "metadata": {
        "id": "FYZhfgCTESe4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def window_data_multiple_sensors(head_data, wrist_data, seat_data, frame_labels):\n",
        "    X_windows, y_windows = [], []\n",
        "    total_frames = len(frame_labels)\n",
        "\n",
        "    # Annahme: head_data, wrist_data, seat_data haben alle dieselbe Anzahl Zeilen = total_frames\n",
        "    for start in range(0, total_frames - window_size + 1, step_size):\n",
        "        end = start + window_size\n",
        "\n",
        "        win_h = head_data[start:end]    # (window_size, 6)\n",
        "        win_w = wrist_data[start:end]\n",
        "        win_s = seat_data[start:end]\n",
        "        window = np.concatenate([win_h, win_w, win_s], axis=1)  # ‚Üí (window_size, 18)\n",
        "\n",
        "        label_window = frame_labels[start:end]\n",
        "        dominant_label = Counter(label_window).most_common(1)[0][0]\n",
        "        if dominant_label == 'Unknown':\n",
        "            continue\n",
        "\n",
        "        X_windows.append(window)\n",
        "        y_windows.append(dominant_label)\n",
        "\n",
        "    return np.array(X_windows), np.array(y_windows)\n"
      ],
      "metadata": {
        "id": "_RKQP4OGEKi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#7. Daten einlesen und Fenster / Labels erzeugen\n",
        "‚Üí Nach Ausf√ºhrung siehst du f√ºr jede Session etwa: ‚Äú‚Üí 153 Fenster, 3 Klassen‚Äù etc."
      ],
      "metadata": {
        "id": "yjBHXCZBEaWp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Vorbereitung\n",
        "sessions_X = []\n",
        "sessions_y = []\n",
        "valid_sessions = []  # <- neue Liste! mit nur valid sessions\n",
        "skipped_sessions = []\n",
        "\n",
        "#features definieren:\n",
        "features = ['Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z']\n",
        "\n",
        "#Funktionen f√ºr Daten einlesen\n",
        "def smart_feature_filter(df):\n",
        "    # alles lowercase und leerzeichenfrei vergleichen\n",
        "    keep = [col for col in df.columns if any(kw in col.lower() for kw in ['euler', 'acc', 'gyr'])]\n",
        "    return df[keep]\n",
        "\n",
        "def print_csv_headers(path, label):\n",
        "    with open(path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "    print(f\"\\nüìã {label} ‚Üí Datei: {os.path.basename(path)}\")\n",
        "    print(\"   Zeile 0:\", lines[0].strip())\n",
        "    print(\"   Zeile 1:\", lines[1].strip())\n",
        "\n",
        "\n",
        "def inspect_sensor_csv(path):\n",
        "    df = pd.read_csv(path, sep=',', skiprows=1)\n",
        "    df.columns = df.columns.str.strip()\n",
        "    print(f\"üìä {os.path.basename(path)}: {df.shape[1]} Spalten\")\n",
        "    print(\"   ‚Üí Spaltennamen:\", df.columns.tolist())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def load_sensor_csv(path):\n",
        "  import csv\n",
        "\n",
        "  # Erste zwei Zeilen lesen\n",
        "  with open(path, 'r') as f:\n",
        "      reader = csv.reader(f)\n",
        "      first_line = next(reader)\n",
        "      second_line = next(reader)\n",
        "\n",
        "  # Pr√ºfen ob erste Zeile ein Header ist (z.‚ÄØB. mit bekannten Schl√ºsselw√∂rtern)\n",
        "  first_line_str = \",\".join(first_line).lower()\n",
        "  if any(kw in first_line_str for kw in ['euler', 'acc', 'gyr']):\n",
        "      skip = 0\n",
        "  else:\n",
        "      skip = 1\n",
        "\n",
        "  # Einlesen\n",
        "  df = pd.read_csv(path, sep=',', skiprows=skip)\n",
        "  df.columns = df.columns.str.strip()\n",
        "\n",
        "  # Features filtern\n",
        "  df = smart_feature_filter(df)\n",
        "\n",
        "  # Numerisch umwandeln und NaN behandeln\n",
        "  df = df.apply(pd.to_numeric, errors='coerce').fillna(0).astype(np.float32)\n",
        "\n",
        "  return df.values\n",
        "\n",
        "  print(f\"üîç {os.path.basename(path)}: Header {'erste Zeile' if skip==0 else 'zweite Zeile'}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# --- Hauptschleife ---\n",
        "for sess_dir in session_dirs:\n",
        "    print(f\"\\nüìÇ Lade Session: {sess_dir}\")\n",
        "    session_path = os.path.join(base_dir, sess_dir)\n",
        "\n",
        "\n",
        "    # 7.1 Sensor-Dateien finden\n",
        "    head_path  = find_sensor_file(session_path, 'Head_')\n",
        "    wrist_path = find_sensor_file(session_path, 'Wrist_')\n",
        "    seat_path  = find_sensor_file(session_path, 'Seat_')\n",
        "\n",
        "    # 7.2 Hot-JSON-Datei finden\n",
        "    hot_path = find_hot_file(session_path)\n",
        "\n",
        "    inspect_sensor_csv(head_path)\n",
        "    inspect_sensor_csv(wrist_path)\n",
        "    inspect_sensor_csv(seat_path)\n",
        "\n",
        "\n",
        "    #print csv-heads for debugging & checking (oben definierte function print_csv_headers)\n",
        "    #print_csv_headers(head_path, 'Head')\n",
        "    #print_csv_headers(wrist_path, 'Wrist')\n",
        "    #print_csv_headers(seat_path, 'Seat')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # 7.3 IMU-Daten laden\n",
        "    #funktion um imu laden\n",
        "    #aktuelles Problem: header in der zweiten Zeile, seperator ',' , erkennt nur zwei spalten beim einlesen\n",
        "\n",
        "\n",
        "\n",
        "    head_data  = load_sensor_csv(head_path)\n",
        "    wrist_data = load_sensor_csv(wrist_path)\n",
        "    seat_data  = load_sensor_csv(seat_path)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    print(f\"üìä Sensorl√§ngen: Head={head_data.shape}, Wrist={wrist_data.shape}, Seat={seat_data.shape}\")\n",
        "\n",
        "    #expected_features = 27  # 3 Sensoren √ó 9 Features (oben definiert)\n",
        "   # if X_win.shape[1:] != (window_size, expected_features):\n",
        "    #      print(f\"‚ö†Ô∏è Session {sess_dir} hat Format {X_win.shape[1:]}, wird √ºbersprungen.\")\n",
        "     #     skipped_sessions.append(sess_dir)\n",
        "      #    continue\n",
        "\n",
        "\n",
        "\n",
        "    #7.4 Labels laden\n",
        "    total_frames = min(head_data.shape[0], wrist_data.shape[0], seat_data.shape[0])\n",
        "    frame_labels = parse_hot_labels(hot_path, total_frames)\n",
        "\n",
        "\n",
        "\n",
        "    # 7.5 Sicherheitsk√ºrzung (sp√§ter optional mit synch.json ersetzen)\n",
        "    head_data  = head_data[:total_frames]\n",
        "    wrist_data = wrist_data[:total_frames]\n",
        "    seat_data  = seat_data[:total_frames]\n",
        "    frame_labels = frame_labels[:total_frames]\n",
        "\n",
        "\n",
        "    # 7.6 Fensterung & Label-Zuweisung\n",
        "    X_win, y_win = window_data_multiple_sensors(head_data, wrist_data, seat_data, frame_labels)\n",
        "\n",
        "    # 5. G√ºltigkeit pr√ºfen\n",
        "    if len(X_win) == 0:\n",
        "        print(f\"‚ö†Ô∏è  Session {sess_dir} √ºbersprungen ‚Äì keine g√ºltigen Fenster.\")\n",
        "        skipped_sessions.append(sess_dir)\n",
        "        continue\n",
        "\n",
        "    expected_features = 27  # oder dynamisch aus den Daten\n",
        "\n",
        "    if X_win.shape[1:] != (window_size, expected_features):\n",
        "        print(f\"‚ö†Ô∏è  Session {sess_dir} hat Format {X_win.shape[1:]}, wird √ºbersprungen.\")\n",
        "        skipped_sessions.append(sess_dir)\n",
        "        continue\n",
        "\n",
        "\n",
        "        # 6. Speichern\n",
        "    sessions_X.append(X_win)\n",
        "    sessions_y.append(y_win)\n",
        "    valid_sessions.append(sess_dir)\n",
        "    print(f\"‚úÖ Session {sess_dir}: {len(X_win)} Fenster, {len(np.unique(y_win))} Klassen\")\n",
        "\n",
        "# --- Zusammenfassung ---\n",
        "print(\"\\n‚úÖ Verwendete Sessions:\")\n",
        "for idx, sess in enumerate(valid_sessions):\n",
        "    print(f\"  {sess}: {sessions_X[idx].shape}\")\n",
        "\n",
        "if skipped_sessions:\n",
        "    print(\"\\n‚õîÔ∏è √úbersprungene Sessions:\")\n",
        "    for s in skipped_sessions:\n",
        "        print(f\"  {s}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hAmaAMFEKM_",
        "outputId": "92ce23df-8b28-4280-ef5d-ff021219bfb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìÇ Lade Session: Session_01\n",
            "üìä Head_D422CD00563B_20230713_082527.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "üìä Wrist_D422CD004550_20230713_082527.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "üìä Seat_D422CD00456D_20230713_082527.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "üìä Sensorl√§ngen: Head=(60077, 9), Wrist=(60078, 9), Seat=(60075, 9)\n",
            "‚úÖ Session Session_01: 1997 Fenster, 3 Klassen\n",
            "\n",
            "üìÇ Lade Session: Session_02\n",
            "üìä Head_D422CD00563B_20230713_085629.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "üìä Wrist_D422CD004550_20230713_085629.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "üìä Seat_D422CD00456D_20230713_085629.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "üìä Sensorl√§ngen: Head=(48792, 9), Wrist=(48792, 9), Seat=(48784, 9)\n",
            "‚úÖ Session Session_02: 1621 Fenster, 3 Klassen\n",
            "\n",
            "üìÇ Lade Session: Session_03\n",
            "üìä Head_D422CD00563B_20230713_092642.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "üìä Wrist_D422CD004550_20230713_092642.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "üìä Seat_D422CD00456D_20230713_092642.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "üìä Sensorl√§ngen: Head=(42308, 9), Wrist=(42305, 9), Seat=(42307, 9)\n",
            "‚úÖ Session Session_03: 1407 Fenster, 3 Klassen\n",
            "\n",
            "üìÇ Lade Session: Session_04\n",
            "üìä Head_D422CD00563B_20230717_070932.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "üìä Wrist_D422CD004550_20230717_070932.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "üìä Seat_D422CD00456D_20230717_070932.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "üìä Sensorl√§ngen: Head=(56013, 9), Wrist=(56019, 9), Seat=(56015, 9)\n",
            "‚úÖ Session Session_04: 1864 Fenster, 3 Klassen\n",
            "\n",
            "üìÇ Lade Session: Session_05\n",
            "üìä Head_D422CD00563B_20230717_070932.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "üìä Wrist_D422CD004550_20230717_070932.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "üìä Seat_D422CD00456D_20230717_070932.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "üìä Sensorl√§ngen: Head=(56013, 9), Wrist=(56019, 9), Seat=(56015, 9)\n",
            "‚úÖ Session Session_05: 1858 Fenster, 4 Klassen\n",
            "\n",
            "üìÇ Lade Session: Session_06\n",
            "üìä Head_D422CD00563B_20230720_074713.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "üìä Wrist_D422CD004550_20230720_074713.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "üìä Seat_D422CD00456D_20230720_074713.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "üìä Sensorl√§ngen: Head=(64027, 9), Wrist=(64026, 9), Seat=(64025, 9)\n",
            "‚úÖ Session Session_06: 2116 Fenster, 4 Klassen\n",
            "\n",
            "üìÇ Lade Session: Session_07\n",
            "üìä Head_D422CD00563B_20230720_082728.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "üìä Wrist_D422CD004550_20230720_082728.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "üìä Seat_D422CD00456D_20230720_082728.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "üìä Sensorl√§ngen: Head=(59920, 9), Wrist=(59917, 9), Seat=(59921, 9)\n",
            "‚úÖ Session Session_07: 1991 Fenster, 4 Klassen\n",
            "\n",
            "üìÇ Lade Session: Session_09\n",
            "üìä Head_D422CD00563B_20230724_072319.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "üìä Wrist_D422CD004550_20230724_072319.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "üìä Seat_D422CD00456D_20230724_072319.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "üìä Sensorl√§ngen: Head=(59464, 9), Wrist=(59465, 9), Seat=(59468, 9)\n",
            "‚úÖ Session Session_09: 1979 Fenster, 4 Klassen\n",
            "\n",
            "üìÇ Lade Session: Session_10\n",
            "üìä Head_D422CD004576_20230725_070718.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "üìä Wrist_D422CD004550_20230725_070718.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "üìä Seat_D422CD00456D_20230725_070718.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "üìä Sensorl√§ngen: Head=(62167, 9), Wrist=(62163, 9), Seat=(62163, 9)\n",
            "‚úÖ Session Session_10: 2061 Fenster, 4 Klassen\n",
            "\n",
            "üìÇ Lade Session: Session_11\n",
            "üìä Head_D422CD004576_20230727_073528.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-bde1625cbf8d>:25: DtypeWarning: Columns (5,6,7,8,9,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(path, sep=',', skiprows=1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Wrist_D422CD004550_20230727_073528.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-bde1625cbf8d>:25: DtypeWarning: Columns (5,6,7,8,9,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(path, sep=',', skiprows=1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Seat_D422CD00456D_20230727_073528.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-bde1625cbf8d>:50: DtypeWarning: Columns (5,6,7,8,9,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(path, sep=',', skiprows=skip)\n",
            "<ipython-input-7-bde1625cbf8d>:50: DtypeWarning: Columns (5,6,7,8,9,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(path, sep=',', skiprows=skip)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Sensorl√§ngen: Head=(65763, 9), Wrist=(65763, 9), Seat=(65763, 9)\n",
            "‚úÖ Session Session_11: 2181 Fenster, 4 Klassen\n",
            "\n",
            "üìÇ Lade Session: Session_12\n",
            "üìä Head_D422CD004576_20230801_075834.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['0', '416010770', '-4.522172451019287', '48.04213333129883', '21.0351619720459', '0', '0.1', '0.2', '0.3', '0.4', '0.5', '']\n",
            "üìä Wrist_D422CD004550_20230801_075834.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['0', '532295258', '-42.42717361450195', '45.996009826660156', '-55.192440032958984', '0', '0.1', '0.2', '0.3', '0.4', '0.5', '']\n",
            "üìä Seat_D422CD00456D_20230801_075834.csv: 11 Spalten\n",
            "   ‚Üí Spaltennamen: ['0', '409881162', '2202328491210930', '-6035955047607420', '-8357672119140620', '0.00000000000000', '0.00000000000000.1', '0.00000000000000.2', '0.00000000000000.3', '0.00000000000000.4', '0.00000000000000.5']\n",
            "üìä Sensorl√§ngen: Head=(59523, 9), Wrist=(59524, 9), Seat=(59514, 9)\n",
            "‚úÖ Session Session_12: 1967 Fenster, 4 Klassen\n",
            "\n",
            "üìÇ Lade Session: Session_13\n",
            "üìä Head_D422CD004576_20230802_080027.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['0', '209493532', '-7.16727876663208', '47.413570404052734', '-87.12100219726562', '0', '0.1', '0.2', '0.3', '0.4', '0.5', '']\n",
            "üìä Wrist_D422CD004550_20230802_080027.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['0', '358144070', '-41.73847198486328', '23.458871841430664', '-68.4642105102539', '0', '0.1', '0.2', '0.3', '0.4', '0.5', '']\n",
            "üìä Seat_D422CD00456D_20230802_080027.csv: 11 Spalten\n",
            "   ‚Üí Spaltennamen: ['0', '435628135', '199753963947296', '-6415881347656250', '-16434582519531200', '0.00000000000000', '0.00000000000000.1', '0.00000000000000.2', '0.00000000000000.3', '0.00000000000000.4', '0.00000000000000.5']\n",
            "üìä Sensorl√§ngen: Head=(65046, 9), Wrist=(66494, 9), Seat=(65037, 9)\n",
            "‚úÖ Session Session_13: 2161 Fenster, 4 Klassen\n",
            "\n",
            "üìÇ Lade Session: Session_14\n",
            "üìä Head_D422CD004576_20230803_073423.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['0', '23311239', '5.965623378753662', '-45.560245513916016', '164.4220428466797', '0', '0.1', '0.2', '0.3', '0.4', '0.5', '']\n",
            "üìä Wrist_D422CD004550_20230803_073423.csv: 12 Spalten\n",
            "   ‚Üí Spaltennamen: ['0', '177062498', '78.41714477539062', '7.847972869873047', '119.1408920288086', '0', '0.1', '0.2', '0.3', '0.4', '0.5', '']\n",
            "üìä Seat_D422CD00456D_20230803_073423.csv: 11 Spalten\n",
            "   ‚Üí Spaltennamen: ['0', '310191965', '7921337127685540', '-2267286872863770', '-12943373107910100', '0.00000000000000', '0.00000000000000.1', '0.00000000000000.2', '0.00000000000000.3', '0.00000000000000.4', '0.00000000000000.5']\n",
            "üìä Sensorl√§ngen: Head=(58097, 9), Wrist=(58096, 9), Seat=(58086, 9)\n",
            "‚úÖ Session Session_14: 1869 Fenster, 4 Klassen\n",
            "\n",
            "‚úÖ Verwendete Sessions:\n",
            "  Session_01: (1997, 60, 27)\n",
            "  Session_02: (1621, 60, 27)\n",
            "  Session_03: (1407, 60, 27)\n",
            "  Session_04: (1864, 60, 27)\n",
            "  Session_05: (1858, 60, 27)\n",
            "  Session_06: (2116, 60, 27)\n",
            "  Session_07: (1991, 60, 27)\n",
            "  Session_09: (1979, 60, 27)\n",
            "  Session_10: (2061, 60, 27)\n",
            "  Session_11: (2181, 60, 27)\n",
            "  Session_12: (1967, 60, 27)\n",
            "  Session_13: (2161, 60, 27)\n",
            "  Session_14: (1869, 60, 27)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üß† Dann ist deine Fensterform:\n",
        "\n",
        "    3 Sensoren √ó 9 Spalten = 27 Features\n",
        "    ‚Üí Fenster-Shape: (window_size, 27) = (60, 27)\n",
        "\n",
        "\n",
        "Euler_X, Euler_Y, Euler_Z\n",
        "\n",
        "\n",
        "Acc_X, Acc_Y, Acc_Z\n",
        "\n",
        "Gyr_X, Gyr_Y, Gyr_Z\n",
        "\n",
        "‚Üí = 9 physikalisch sinnvolle Spalten pro Sensor"
      ],
      "metadata": {
        "id": "VEmZyAMMpyKX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#8. Global Model: Training and Evaluation\n",
        "\n",
        "Schritt-f√ºr-Schritt Erkl√§rung\n",
        "\n",
        "  **1. Daten zusammenf√ºhren**\n",
        "\n",
        "    Alle Sessions werden zu einem gro√üen Datensatz verbunden, damit das Modell aus allen Beispielen lernt.\n",
        "\n",
        " **2. Label-Encoding**\n",
        "\n",
        "\n",
        "    Die Labels (z.B. verschiedene Aktivit√§ten) werden in numerische Werte umgewandelt, da das Modell nur mit Zahlen arbeitet.\n",
        "\n",
        " **3. Trainings- und Validierungs-Split**\n",
        "\n",
        "    Der Datensatz wird in Training (90%) und Validation (10%) aufgeteilt. Validation wird genutzt, um das Modell w√§hrend des Trainings zu √ºberpr√ºfen.\n",
        "\n",
        "  **4. Modell erstellen**\n",
        "\n",
        "    Das Modell kombiniert Convolutional Layers (um lokale Muster in den Zeitreihen zu erkennen) mit LSTM (um zeitliche Abh√§ngigkeiten zu lernen). Dropout wird eingesetzt, um √úberanpassung zu vermeiden.\n",
        "\n",
        "  **5. Checkpoint Callback**\n",
        "\n",
        "    W√§hrend des Trainings werden Modelle nach jeder Epoche gespeichert (nur die besten, basierend auf Validierungsleistung).\n",
        "\n",
        "  **6. Training**\n",
        "  \n",
        "    Das Modell lernt √ºber 50 Epochen, wobei Trainings- und Validierungsdaten genutzt werden.\n",
        "\n",
        "  **7. Finales Modell speichern**\n",
        "\n",
        "    Das finale Modell wird nach dem Training gespeichert,\n",
        "    um es sp√§ter laden und nutzen zu k√∂nnen.\n",
        "\n",
        "  **8. Evaluation auf Validierungsdaten**\n",
        "\n",
        "    Das Modell wird auf den Validation-Daten getestet,\n",
        "    um die Genauigkeit zu ermitteln.\n",
        "\n",
        "  **9.  Vorhersagen erzeugen**\n",
        "\n",
        "    Die Wahrscheinlichkeiten f√ºr jede Klasse werden ermittelt und in Klassen umgewandelt (h√∂chste Wahrscheinlichkeit = Vorhersage).\n",
        "\n",
        "  **10.  Labels pr√ºfen**\n",
        "\n",
        "    Nur die tats√§chlich in den Validierungsdaten vorhandenen Klassen werden f√ºr den Bericht verwendet.\n",
        "\n",
        " **11.  Classification Report**\n",
        "\n",
        "    Pr√§zision, Recall, F1-Score und Support f√ºr jede Klasse werden ausgegeben ‚Äî wichtige Kennzahlen f√ºr die Modellg√ºte.\n",
        "\n",
        "  **12.  Confusion Matrix**\n",
        "\n",
        "    Visualisiert die Fehler des Modells,\n",
        "    zeigt welche Klassen oft verwechselt werden.\n",
        "\n"
      ],
      "metadata": {
        "id": "8szKmR2qE5RI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "\n",
        "# üíæ Speicherpfade anlegen\n",
        "checkpoint_dir = \"/content/drive/MyDrive/mtb_project/checkpoints_global\"\n",
        "final_model_dir = \"/content/drive/MyDrive/mtb_project/final_models_global\"\n",
        "report_dir = \"/content/drive/MyDrive/mtb_project/reports_global\"\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "os.makedirs(final_model_dir, exist_ok=True)\n",
        "os.makedirs(report_dir, exist_ok=True)\n",
        "\n",
        "# üîÅ Augmentierungsfunktion\n",
        "def augment_data(X, y, noise_std=0.01, time_shift_max=5):\n",
        "    X_aug, y_aug = [], []\n",
        "    for xi, yi in zip(X, y):\n",
        "      # 1. Leichtes Rauschen hinzuf√ºgen\n",
        "        noisy = xi + np.random.normal(0, noise_std, xi.shape)\n",
        "      # 2. Zuf√§lliges Zeitverschieben\n",
        "        shift = np.random.randint(-time_shift_max, time_shift_max)\n",
        "        shifted = np.roll(noisy, shift, axis=0)\n",
        "        # Optional: Padding beim Rollen (statt wrap-around)\n",
        "        if shift > 0:\n",
        "            shifted[:shift, :] = 0\n",
        "        elif shift < 0:\n",
        "            shifted[shift:, :] = 0\n",
        "        X_aug.append(shifted)\n",
        "        y_aug.append(yi)\n",
        "    return np.array(X_aug), np.array(y_aug)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 1Ô∏è‚É£ Sessions zusammenf√ºhren (dieser Teil muss mit deinen Daten erg√§nzt werden!)\n",
        "# Beispiel:\n",
        "X_all = np.concatenate(sessions_X)\n",
        "y_all = np.concatenate(sessions_y)\n",
        "\n",
        "# 2Ô∏è‚É£ Labels encoden\n",
        "le = LabelEncoder()\n",
        "y_all_enc = le.fit_transform(y_all)\n",
        "\n",
        "# 3Ô∏è‚É£ Train/Val-Split\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_all, y_all_enc, test_size=0.1, random_state=42, stratify=y_all_enc\n",
        ")\n",
        "\n",
        "# 4Ô∏è‚É£ Augmentieren ‚Äì auf Original-Labels\n",
        "y_train_original = le.inverse_transform(y_train)\n",
        "X_aug, y_aug = augment_data(X_train, y_train_original)\n",
        "y_aug_enc = le.transform(y_aug)\n",
        "\n",
        "# üîÄ Kombinieren\n",
        "X_train_combined = np.concatenate([X_train, X_aug])\n",
        "y_train_combined = np.concatenate([y_train, y_aug_enc])\n",
        "\n",
        "# 5Ô∏è‚É£ Modell bauen\n",
        "model = models.Sequential([\n",
        "    layers.Conv1D(64, 3, activation='relu', input_shape=X_train.shape[1:]),\n",
        "    layers.Conv1D(64, 3, activation='relu'),\n",
        "    layers.MaxPooling1D(pool_size=2),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.LSTM(64),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(100, activation='relu'),\n",
        "    layers.Dense(len(le.classes_), activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 6Ô∏è‚É£ Callback f√ºr Checkpoints\n",
        "checkpoint_cb = ModelCheckpoint(\n",
        "    filepath=os.path.join(checkpoint_dir, \"global_epoch_{epoch:02d}.keras\"),\n",
        "    save_best_only=True, save_weights_only=False, verbose=1\n",
        ")\n",
        "\n",
        "# 7Ô∏è‚É£ Training\n",
        "history = model.fit(\n",
        "    X_train_combined, y_train_combined,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=50, batch_size=64,\n",
        "    callbacks=[checkpoint_cb]\n",
        ")\n",
        "\n",
        "# 8Ô∏è‚É£ Speichern des finalen Modells\n",
        "model.save(os.path.join(final_model_dir, \"global_final.keras\"))\n",
        "\n",
        "# 9Ô∏è‚É£ Evaluation\n",
        "val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
        "print(f\"\\n‚úÖ Validation Accuracy: {val_acc:.2f}\")\n",
        "\n",
        "# üîÆ Vorhersagen\n",
        "y_pred_probs = model.predict(X_val, verbose=0)\n",
        "y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "# üìä Report + Matrix\n",
        "labels_present = unique_labels(y_val, y_pred_classes)\n",
        "report_text = classification_report(\n",
        "    y_val, y_pred_classes,\n",
        "    labels=labels_present,\n",
        "    target_names=[le.classes_[i] for i in labels_present]\n",
        ")\n",
        "print(\"\\nüìÑ Classification Report:\\n\")\n",
        "print(report_text)\n",
        "\n",
        "# üíæ Speichern als Text\n",
        "with open(os.path.join(report_dir, \"global_model_classification_report.txt\"), \"w\") as f:\n",
        "    f.write(report_text)\n",
        "\n",
        "# üìà Confusion Matrix\n",
        "cm = confusion_matrix(y_val, y_pred_classes, labels=labels_present)\n",
        "disp = ConfusionMatrixDisplay(cm, display_labels=[le.classes_[i] for i in labels_present])\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "disp.plot(ax=ax, xticks_rotation=45)\n",
        "plt.title(\"Confusion Matrix ‚Äì Global Model Validation\")\n",
        "\n",
        "# üíæ Speichern als PNG\n",
        "plt.savefig(os.path.join(report_dir, \"global_model_confusion_matrix.png\"))\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "rxVuQEL74mVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "\n",
        "# üíæ Speicherpfade anlegen\n",
        "checkpoint_dir = \"/content/drive/MyDrive/mtb_project/checkpoints_global\"\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "final_model_dir = \"/content/drive/MyDrive/mtb_project/final_models_global\"\n",
        "os.makedirs(final_model_dir, exist_ok=True)\n",
        "\n",
        "def augment_data(X, y, noise_std=0.01, time_shift_max=5):\n",
        "    X_aug = []\n",
        "    y_aug = []\n",
        "\n",
        "    for xi, yi in zip(X, y):\n",
        "        # 1. Leichtes Rauschen hinzuf√ºgen\n",
        "        noisy = xi + np.random.normal(0, noise_std, xi.shape)\n",
        "\n",
        "        # 2. Zuf√§lliges Zeitverschieben\n",
        "        shift = np.random.randint(-time_shift_max, time_shift_max)\n",
        "        shifted = np.roll(noisy, shift, axis=0)\n",
        "\n",
        "        # Optional: Padding beim Rollen (statt wrap-around)\n",
        "        if shift > 0:\n",
        "            shifted[:shift, :] = 0\n",
        "        elif shift < 0:\n",
        "            shifted[shift:, :] = 0\n",
        "\n",
        "        X_aug.append(shifted)\n",
        "        y_aug.append(yi)\n",
        "\n",
        "    return np.array(X_aug), np.array(y_aug)\n",
        "\n",
        "t\n",
        "\n",
        "X_train_aug, y_train_aug = augment_timeseries(X_train, y_train, augment_factor=2)\n",
        "\n",
        "# Augmentieren\n",
        "X_aug, y_aug = augment_data(X_train, y_train)\n",
        "\n",
        "# Kombinieren mit Originaldaten\n",
        "X_train_combined = np.concatenate([X_train, X_aug])\n",
        "y_train_combined = np.concatenate([y_train, y_aug])\n",
        "\n",
        "# 1. Daten vorbereiten: alle Sessions zusammenf√ºhren\n",
        "\n",
        "\n",
        "# 2. Labels encoden (wichtig f√ºr Modell)\n",
        "le = LabelEncoder()\n",
        "y_all_enc = le.fit_transform(y_all)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 3. Trainings- und Validierungsdaten splitten (z.B. 90% Training, 10% Validation)\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_all, y_all_enc, test_size=0.1, random_state=42, stratify=y_all_enc\n",
        ")\n",
        "\n",
        "# Nachdem du X_train und y_train_enc oder y_train_binary hast\n",
        "\n",
        "X_train_aug, y_train_aug = augment_timeseries(X_train, y_train, augment_factor=2)\n",
        "\n",
        "# Augmentieren\n",
        "X_aug, y_aug = augment_data(X_train, y_train)\n",
        "\n",
        "# Kombinieren mit Originaldaten\n",
        "X_train_combined = np.concatenate([X_train, X_aug])\n",
        "y_train_combined = np.concatenate([y_train, y_aug])\n",
        "\n",
        "# 4. Modell definieren (CNN + LSTM Architektur)\n",
        "model = models.Sequential([\n",
        "    layers.Conv1D(64, 3, activation='relu', input_shape=X_train.shape[1:]),\n",
        "    layers.Conv1D(64, 3, activation='relu'),\n",
        "    layers.MaxPooling1D(pool_size=2),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.LSTM(64),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(100, activation='relu'),\n",
        "    layers.Dense(len(le.classes_), activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# 5. Callback f√ºr Checkpoints w√§hrend Training\n",
        "checkpoint_cb = ModelCheckpoint(\n",
        "    filepath=os.path.join(checkpoint_dir, \"global_epoch_{epoch:02d}.keras\"),\n",
        "    save_best_only=True,\n",
        "    save_weights_only=False,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# 6. Training starten\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=50,\n",
        "    batch_size=64,\n",
        "    callbacks=[checkpoint_cb]\n",
        ")\n",
        "\n",
        "# 7. Finale Modell speichern\n",
        "model.save(os.path.join(final_model_dir, \"global_final.keras\"))\n",
        "\n",
        "# 8. Evaluation auf Validierungsdaten\n",
        "val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
        "print(f\"\\n‚úÖ Validation Accuracy: {val_acc:.2f}\")\n",
        "\n",
        "# 9. Vorhersagen f√ºr Validierungsdaten erzeugen\n",
        "y_pred_probs = model.predict(X_val, verbose=0)\n",
        "y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "# 10. Berechne vorhandene Labels (f√ºr Report & Matrix)\n",
        "labels_present = unique_labels(y_val, y_pred_classes)\n",
        "\n",
        "# 11. Klassifikationsbericht ausgeben\n",
        "print(\"\\nClassification Report on Validation Set:\")\n",
        "print(classification_report(\n",
        "    y_val,\n",
        "    y_pred_classes,\n",
        "    labels=labels_present,\n",
        "    target_names=[le.classes_[i] for i in labels_present]\n",
        "))\n",
        "\n",
        "# 12. Confusion Matrix visualisieren\n",
        "cm = confusion_matrix(y_val, y_pred_classes, labels=labels_present)\n",
        "disp = ConfusionMatrixDisplay(cm, display_labels=[le.classes_[i] for i in labels_present])\n",
        "disp.plot(xticks_rotation=45)\n",
        "plt.title(\"Confusion Matrix ‚Äì Global Model Validation\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "Dpz8UigUO1eH",
        "outputId": "a8742864-0a9f-47fe-b6b2-7021200daf08"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'augment_timeseries' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-e33d3ac0f470>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# Nachdem du X_train und y_train_enc oder y_train_binary hast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mX_train_aug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_aug\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maugment_timeseries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugment_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;31m# Augmentieren\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'augment_timeseries' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üßæ Zusammenfassung Modeltraining\n",
        "##üìä 1. Durchschnittliche Accuracy √ºber alle Sessions:"
      ],
      "metadata": {
        "id": "q-yhvJmXzOjU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#üìä 1. Durchschnittliche Accuracy √ºber alle Sessions:\n",
        "\n",
        "mean_acc = np.mean(all_accuracies)\n",
        "print(\"\\nüìà Zusammenfassung:\")\n",
        "for i, acc in enumerate(all_accuracies):\n",
        "    print(f\"  Session {i+1}: Accuracy = {acc:.2f}\")\n",
        "print(f\"\\n‚úÖ Durchschnittliche Test-Accuracy √ºber alle Sessions: {mean_acc:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "5ZKwF6fOy75p",
        "outputId": "0ea2850d-5897-444f-bbea-611e688ec0d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'all_accuracies' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-ff1e0f4f9e92>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#üìä 1. Durchschnittliche Accuracy √ºber alle Sessions:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmean_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_accuracies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nüìà Zusammenfassung:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_accuracies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'all_accuracies' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##üìÅ 2. CSV speichern (falls nicht schon vorhanden):"
      ],
      "metadata": {
        "id": "Evqv6rIczcn0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#üìÅ 2. CSV speichern (falls nicht schon vorhanden):\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df_summary = pd.DataFrame(accuracy_summary)\n",
        "df_summary['Session'] = [f\"Session_{i+1}\" for i in range(len(all_accuracies))]\n",
        "df_summary.to_csv(\"/content/drive/MyDrive/mtb_project/session_accuracy_report.csv\", index=False)\n",
        "print(\"‚úÖ Bericht gespeichert unter: session_accuracy_report.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AxzlH2XzXA9",
        "outputId": "cc0684b5-4bd9-428b-b823-35d8283e50d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Bericht gespeichert unter: session_accuracy_report.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "all_accuracies = []\n",
        "accuracy_summary = {'Session': [], 'Accuracy': []}\n",
        "\n",
        "for test_idx in range(len(sessions_X)):\n",
        "    sess_name = session_dirs[test_idx]\n",
        "    print(f\"\\nüìå Teste auf Session (unbekannt): {sess_name} ({test_idx+1}/{len(sessions_X)})\")\n",
        "\n",
        "    # 8.1 Test-Daten definieren\n",
        "    X_test = sessions_X[test_idx]\n",
        "    y_test = sessions_y[test_idx]\n",
        "\n",
        "\n",
        "\n",
        "    # 8.2 Train-Daten: alle anderen Sessions zusammenschneiden\n",
        "    X_train = np.concatenate([x for i, x in enumerate(sessions_X) if i != test_idx])\n",
        "    y_train = np.concatenate([y for i, y in enumerate(sessions_y) if i != test_idx])\n",
        "\n",
        "    # 8.3 Label-Encoding (fit auf Trainingsdaten, transform auf beides)\n",
        "    le = LabelEncoder()\n",
        "    y_train_enc = le.fit_transform(y_train)\n",
        "    y_test_enc = le.transform(y_test)\n",
        "\n",
        "    # 8.4 Modell-Definition: CNN + LSTM\n",
        "    model = models.Sequential([\n",
        "        layers.Conv1D(64, 3, activation='relu', input_shape=X_train.shape[1:]),\n",
        "        layers.Conv1D(64, 3, activation='relu'),\n",
        "        layers.MaxPooling1D(pool_size=2),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.LSTM(64),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(100, activation='relu'),\n",
        "        layers.Dense(len(le.classes_), activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    # 8.5 Training (mit 10 % Validierungssplit aus Trainingsdaten)\n",
        "\n",
        "    from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "    import os\n",
        "\n",
        "    # 1. üìÅ Sicherstellen, dass Speicherort existiert\n",
        "    checkpoint_dir = \"/content/drive/MyDrive/mtb_project/checkpoints\"\n",
        "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "    # 2. üéØ Callback definieren\n",
        "    checkpoint_cb = ModelCheckpoint(\n",
        "        filepath = os.path.join(checkpoint_dir, f\"{sess_name}_epoch_{{epoch:02d}}.keras\"),\n",
        "        save_best_only=False,         # du bekommst jedes Epoch-Modell\n",
        "        save_weights_only=False,      # speichert das ganze Modell, nicht nur Gewichte\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "# 3. üöÄ Training starten (Callback hinzuf√ºgen!)\n",
        "\n",
        "\n",
        "    # mit checkpoints zum speichern\n",
        "    history = model.fit(\n",
        "        X_train, y_train_enc,\n",
        "        validation_data=(X_val, y_val),\n",
        "        epochs=50,\n",
        "        batch_size=64,\n",
        "        callbacks=[checkpoint_cb] #-> automatische zwischenspeicherung\n",
        "    )\n",
        "\n",
        "    # 8.6 Evaluation auf Test-Session\n",
        "    test_loss, test_acc = model.evaluate(X_test, y_test_enc, verbose=0)\n",
        "    print(f\"‚úÖ Test-Accuracy f√ºr {sess_name}: {test_acc:.2f}\")\n",
        "    all_accuracies.append(test_acc)\n",
        "    accuracy_summary['Session'].append(sess_name)\n",
        "    accuracy_summary['Accuracy'].append(test_acc)\n",
        "\n",
        "    # 8.7 Klassifikationsbericht & Confusion Matrix\n",
        "    # üîç Report berechnen\n",
        "    print(\"\\nKlassifikationsbericht:\")\n",
        "    report_text = classification_report(\n",
        "        y_test_enc,\n",
        "        y_pred_classes,\n",
        "        target_names=[le.classes_[i] for i in labels_present],\n",
        "        labels=labels_present\n",
        "    )\n",
        "    print(report_text)\n",
        "\n",
        "    # üíæ Bericht speichern (Textdatei)\n",
        "    os.makedirs(\"/content/drive/MyDrive/mtb_project/reports\", exist_ok=True)\n",
        "    with open(f\"/content/drive/MyDrive/mtb_project/reports/{sess_name}_classification_report.txt\", \"w\") as f:\n",
        "        f.write(report_text)\n",
        "\n",
        "    # üìä Confusion Matrix anzeigen & speichern\n",
        "    cm = confusion_matrix(y_test_enc, y_pred_classes, labels=labels_present)\n",
        "    fig, ax = plt.subplots(figsize=(8, 6))\n",
        "    disp = ConfusionMatrixDisplay(cm, display_labels=[le.classes_[i] for i in labels_present])\n",
        "    disp.plot(ax=ax, xticks_rotation=45)\n",
        "    plt.title(f\"Confusion Matrix ‚Äì {sess_name}\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"/content/drive/MyDrive/mtb_project/reports/{sess_name}_confusion_matrix.png\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "zlJAElwcE1L8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3d070d09-4510-4653-a616-71a4b627a919"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìå Teste auf Session (unbekannt): Session_01 (1/12)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5717 - loss: 1.0202\n",
            "Epoch 1: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_01.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 45ms/step - accuracy: 0.5718 - loss: 1.0200 - val_accuracy: 0.5855 - val_loss: 0.9273\n",
            "Epoch 2/50\n",
            "\u001b[1m329/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6225 - loss: 0.8839\n",
            "Epoch 2: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_02.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 42ms/step - accuracy: 0.6225 - loss: 0.8838 - val_accuracy: 0.6175 - val_loss: 0.8609\n",
            "Epoch 3/50\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6429 - loss: 0.8232\n",
            "Epoch 3: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_03.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 42ms/step - accuracy: 0.6429 - loss: 0.8232 - val_accuracy: 0.6352 - val_loss: 0.8286\n",
            "Epoch 4/50\n",
            "\u001b[1m329/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6582 - loss: 0.7952\n",
            "Epoch 4: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_04.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 43ms/step - accuracy: 0.6581 - loss: 0.7951 - val_accuracy: 0.6348 - val_loss: 0.8224\n",
            "Epoch 5/50\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6613 - loss: 0.7781\n",
            "Epoch 5: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_05.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 41ms/step - accuracy: 0.6613 - loss: 0.7780 - val_accuracy: 0.6421 - val_loss: 0.8242\n",
            "Epoch 6/50\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6776 - loss: 0.7500\n",
            "Epoch 6: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_06.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 42ms/step - accuracy: 0.6777 - loss: 0.7500 - val_accuracy: 0.6495 - val_loss: 0.8258\n",
            "Epoch 7/50\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6768 - loss: 0.7391\n",
            "Epoch 7: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_07.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 44ms/step - accuracy: 0.6768 - loss: 0.7391 - val_accuracy: 0.6517 - val_loss: 0.8004\n",
            "Epoch 8/50\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6813 - loss: 0.7357\n",
            "Epoch 8: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_08.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 41ms/step - accuracy: 0.6813 - loss: 0.7357 - val_accuracy: 0.6517 - val_loss: 0.7841\n",
            "Epoch 9/50\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6894 - loss: 0.7241\n",
            "Epoch 9: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_09.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 43ms/step - accuracy: 0.6894 - loss: 0.7241 - val_accuracy: 0.6452 - val_loss: 0.8039\n",
            "Epoch 10/50\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6928 - loss: 0.7141\n",
            "Epoch 10: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_10.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 45ms/step - accuracy: 0.6928 - loss: 0.7141 - val_accuracy: 0.6551 - val_loss: 0.8198\n",
            "Epoch 11/50\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6943 - loss: 0.7089\n",
            "Epoch 11: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_11.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 42ms/step - accuracy: 0.6943 - loss: 0.7089 - val_accuracy: 0.6642 - val_loss: 0.7875\n",
            "Epoch 12/50\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6950 - loss: 0.6939\n",
            "Epoch 12: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_12.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 40ms/step - accuracy: 0.6950 - loss: 0.6939 - val_accuracy: 0.6595 - val_loss: 0.7868\n",
            "Epoch 13/50\n",
            "\u001b[1m329/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7049 - loss: 0.6885\n",
            "Epoch 13: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_13.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 41ms/step - accuracy: 0.7049 - loss: 0.6885 - val_accuracy: 0.6621 - val_loss: 0.8394\n",
            "Epoch 14/50\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7031 - loss: 0.6850\n",
            "Epoch 14: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_14.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 43ms/step - accuracy: 0.7031 - loss: 0.6850 - val_accuracy: 0.6599 - val_loss: 0.8265\n",
            "Epoch 15/50\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7049 - loss: 0.6788\n",
            "Epoch 15: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_15.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 43ms/step - accuracy: 0.7049 - loss: 0.6788 - val_accuracy: 0.6556 - val_loss: 0.8464\n",
            "Epoch 16/50\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7067 - loss: 0.6721\n",
            "Epoch 16: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_16.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 43ms/step - accuracy: 0.7066 - loss: 0.6722 - val_accuracy: 0.6538 - val_loss: 0.8859\n",
            "Epoch 17/50\n",
            "\u001b[1m329/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6986 - loss: 0.6742\n",
            "Epoch 17: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_17.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 43ms/step - accuracy: 0.6986 - loss: 0.6743 - val_accuracy: 0.6430 - val_loss: 0.8478\n",
            "Epoch 18/50\n",
            "\u001b[1m329/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7032 - loss: 0.6836\n",
            "Epoch 18: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_18.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 43ms/step - accuracy: 0.7031 - loss: 0.6836 - val_accuracy: 0.6659 - val_loss: 0.8619\n",
            "Epoch 19/50\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7128 - loss: 0.6675\n",
            "Epoch 19: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_19.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 41ms/step - accuracy: 0.7127 - loss: 0.6675 - val_accuracy: 0.6776 - val_loss: 0.8383\n",
            "Epoch 20/50\n",
            "\u001b[1m329/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7157 - loss: 0.6599\n",
            "Epoch 20: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_20.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 42ms/step - accuracy: 0.7157 - loss: 0.6599 - val_accuracy: 0.6473 - val_loss: 0.8563\n",
            "Epoch 21/50\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7075 - loss: 0.6774\n",
            "Epoch 21: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_21.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 42ms/step - accuracy: 0.7075 - loss: 0.6774 - val_accuracy: 0.6621 - val_loss: 0.8443\n",
            "Epoch 22/50\n",
            "\u001b[1m329/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7168 - loss: 0.6579\n",
            "Epoch 22: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_22.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 42ms/step - accuracy: 0.7168 - loss: 0.6579 - val_accuracy: 0.6772 - val_loss: 0.8689\n",
            "Epoch 23/50\n",
            "\u001b[1m329/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7138 - loss: 0.6564\n",
            "Epoch 23: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_23.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 48ms/step - accuracy: 0.7138 - loss: 0.6564 - val_accuracy: 0.6733 - val_loss: 0.8491\n",
            "Epoch 24/50\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7176 - loss: 0.6538\n",
            "Epoch 24: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_24.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 43ms/step - accuracy: 0.7176 - loss: 0.6538 - val_accuracy: 0.6672 - val_loss: 0.8425\n",
            "Epoch 25/50\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7071 - loss: 0.6649\n",
            "Epoch 25: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_25.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 41ms/step - accuracy: 0.7071 - loss: 0.6649 - val_accuracy: 0.6876 - val_loss: 0.8408\n",
            "Epoch 26/50\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7149 - loss: 0.6520\n",
            "Epoch 26: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_26.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 41ms/step - accuracy: 0.7149 - loss: 0.6521 - val_accuracy: 0.6906 - val_loss: 0.8515\n",
            "Epoch 27/50\n",
            "\u001b[1m329/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7189 - loss: 0.6573\n",
            "Epoch 27: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_27.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 43ms/step - accuracy: 0.7189 - loss: 0.6572 - val_accuracy: 0.6820 - val_loss: 0.9324\n",
            "Epoch 28/50\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7151 - loss: 0.6538\n",
            "Epoch 28: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_28.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 44ms/step - accuracy: 0.7151 - loss: 0.6537 - val_accuracy: 0.7049 - val_loss: 0.8696\n",
            "Epoch 29/50\n",
            "\u001b[1m329/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7273 - loss: 0.6314\n",
            "Epoch 29: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_29.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 42ms/step - accuracy: 0.7273 - loss: 0.6314 - val_accuracy: 0.7014 - val_loss: 0.8505\n",
            "Epoch 30/50\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7288 - loss: 0.6337\n",
            "Epoch 30: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_30.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 41ms/step - accuracy: 0.7288 - loss: 0.6337 - val_accuracy: 0.7010 - val_loss: 0.8367\n",
            "Epoch 31/50\n",
            "\u001b[1m329/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7408 - loss: 0.6132\n",
            "Epoch 31: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_31.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 42ms/step - accuracy: 0.7408 - loss: 0.6132 - val_accuracy: 0.7122 - val_loss: 0.8613\n",
            "Epoch 32/50\n",
            "\u001b[1m329/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7305 - loss: 0.6314\n",
            "Epoch 32: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_32.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 42ms/step - accuracy: 0.7305 - loss: 0.6314 - val_accuracy: 0.7071 - val_loss: 0.8311\n",
            "Epoch 33/50\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7247 - loss: 0.6387\n",
            "Epoch 33: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_33.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 43ms/step - accuracy: 0.7247 - loss: 0.6387 - val_accuracy: 0.7045 - val_loss: 0.7961\n",
            "Epoch 34/50\n",
            "\u001b[1m329/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7413 - loss: 0.6111\n",
            "Epoch 34: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_34.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 48ms/step - accuracy: 0.7413 - loss: 0.6112 - val_accuracy: 0.6971 - val_loss: 0.8569\n",
            "Epoch 35/50\n",
            "\u001b[1m329/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7363 - loss: 0.6216\n",
            "Epoch 35: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_35.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 40ms/step - accuracy: 0.7363 - loss: 0.6216 - val_accuracy: 0.6988 - val_loss: 0.8012\n",
            "Epoch 36/50\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7389 - loss: 0.6176\n",
            "Epoch 36: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_36.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 40ms/step - accuracy: 0.7389 - loss: 0.6176 - val_accuracy: 0.7049 - val_loss: 0.7753\n",
            "Epoch 37/50\n",
            "\u001b[1m329/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7411 - loss: 0.6263\n",
            "Epoch 37: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_37.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 42ms/step - accuracy: 0.7411 - loss: 0.6262 - val_accuracy: 0.7101 - val_loss: 0.8593\n",
            "Epoch 38/50\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7458 - loss: 0.6112\n",
            "Epoch 38: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_38.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 40ms/step - accuracy: 0.7458 - loss: 0.6112 - val_accuracy: 0.7127 - val_loss: 0.8166\n",
            "Epoch 39/50\n",
            "\u001b[1m329/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7271 - loss: 0.6270\n",
            "Epoch 39: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_39.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 42ms/step - accuracy: 0.7271 - loss: 0.6270 - val_accuracy: 0.7135 - val_loss: 0.8409\n",
            "Epoch 40/50\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7474 - loss: 0.6016\n",
            "Epoch 40: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_40.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 43ms/step - accuracy: 0.7474 - loss: 0.6016 - val_accuracy: 0.7135 - val_loss: 0.8805\n",
            "Epoch 41/50\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7433 - loss: 0.6148\n",
            "Epoch 41: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_41.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 43ms/step - accuracy: 0.7433 - loss: 0.6148 - val_accuracy: 0.7161 - val_loss: 0.8881\n",
            "Epoch 42/50\n",
            "\u001b[1m329/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7496 - loss: 0.5991\n",
            "Epoch 42: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_42.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 43ms/step - accuracy: 0.7495 - loss: 0.5991 - val_accuracy: 0.7096 - val_loss: 0.8199\n",
            "Epoch 43/50\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7471 - loss: 0.6065\n",
            "Epoch 43: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_43.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 42ms/step - accuracy: 0.7471 - loss: 0.6066 - val_accuracy: 0.7209 - val_loss: 0.8502\n",
            "Epoch 44/50\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7534 - loss: 0.6121\n",
            "Epoch 44: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_44.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 43ms/step - accuracy: 0.7534 - loss: 0.6121 - val_accuracy: 0.7114 - val_loss: 0.8444\n",
            "Epoch 45/50\n",
            "\u001b[1m329/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7462 - loss: 0.6069\n",
            "Epoch 45: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_45.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 43ms/step - accuracy: 0.7462 - loss: 0.6069 - val_accuracy: 0.7179 - val_loss: 0.8301\n",
            "Epoch 46/50\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7475 - loss: 0.6056\n",
            "Epoch 46: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_46.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 49ms/step - accuracy: 0.7475 - loss: 0.6056 - val_accuracy: 0.7304 - val_loss: 0.8615\n",
            "Epoch 47/50\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7539 - loss: 0.5965\n",
            "Epoch 47: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_47.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 43ms/step - accuracy: 0.7539 - loss: 0.5965 - val_accuracy: 0.7170 - val_loss: 0.8421\n",
            "Epoch 48/50\n",
            "\u001b[1m329/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7503 - loss: 0.5974\n",
            "Epoch 48: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_48.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 43ms/step - accuracy: 0.7503 - loss: 0.5974 - val_accuracy: 0.7179 - val_loss: 0.8241\n",
            "Epoch 49/50\n",
            "\u001b[1m329/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7492 - loss: 0.6045\n",
            "Epoch 49: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_49.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 42ms/step - accuracy: 0.7492 - loss: 0.6045 - val_accuracy: 0.7283 - val_loss: 0.8237\n",
            "Epoch 50/50\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7557 - loss: 0.5972\n",
            "Epoch 50: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_50.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 42ms/step - accuracy: 0.7557 - loss: 0.5972 - val_accuracy: 0.7252 - val_loss: 0.8899\n",
            "‚úÖ Test-Accuracy f√ºr Session_01: 0.18\n",
            "\n",
            "Klassifikationsbericht:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Found input variables with inconsistent numbers of samples: [1997, 2311]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-c2fdafc1b0bd>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;31m# üîç Report berechnen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nKlassifikationsbericht:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     report_text = classification_report(\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0my_test_enc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0my_pred_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2670\u001b[0m     \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattach_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2671\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2673\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \"\"\"\n\u001b[1;32m     97\u001b[0m     \u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_namespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_pred\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1997, 2311]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(\"/content/drive/MyDrive/mtb_project/reports\", exist_ok=True)\n"
      ],
      "metadata": {
        "id": "VJz6n-8PZWui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import io\n",
        "\n",
        "# Klassifikationsbericht als Text speichern\n",
        "report_text = classification_report(y_test_enc, y_pred_classes, target_names=le.classes_)\n",
        "with open(f\"/content/drive/MyDrive/mtb_project/reports/{sess_name}_classification_report.txt\", \"w\") as f:\n",
        "    f.write(report_text)\n",
        "\n",
        "\n",
        "\n",
        "#confusion matrix als bild speicheern\n",
        "fig, ax = plt.subplots(figsize=(8,6))\n",
        "disp = ConfusionMatrixDisplay(cm, display_labels=le.classes_)\n",
        "disp.plot(ax=ax, xticks_rotation=45)\n",
        "plt.title(f\"Confusion Matrix ‚Äì {sess_name}\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"/content/drive/MyDrive/mtb_project/reports/{sess_name}_confusion_matrix.png\")\n",
        "plt.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "id": "WbIb7duxZKhi",
        "outputId": "b9adb0b6-e7b8-4028-a624-9859e53165f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'y_test_enc' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-7fdf3c318432>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Klassifikationsbericht als Text speichern\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mreport_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_enc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"/content/drive/MyDrive/mtb_project/reports/{sess_name}_classification_report.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y_test_enc' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary = {'Session': [], 'Accuracy': []}\n",
        "for i, acc in enumerate(all_accuracies):\n",
        "    summary['Session'].append(f\"Session_{i+1}\")\n",
        "    summary['Accuracy'].append(acc)\n",
        "\n",
        "df_summary = pd.DataFrame(summary)\n",
        "df_summary.to_csv(\"session_accuracy_report.csv\", index=False)\n",
        "print(\"üìÅ Bericht gespeichert als session_accuracy_report.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "2OdK8qjZXRKk",
        "outputId": "18b5bf4b-4b6e-4410-d1f2-545bcd9ce25b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'all_accuracies' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-f8b81594ffea>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'Session'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_accuracies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0msummary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Session'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Session_{i+1}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msummary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'all_accuracies' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üßæ Zusammenfassung nach dem Training:\n",
        "\n",
        "Nach der Schleife kannst du am Ende folgendes hinzuf√ºgen, um einen Bericht zu erzeugen:\n",
        "\n",
        "üìä Bonus: CSV speichern (optional)"
      ],
      "metadata": {
        "id": "G6M9hNEyTzn0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Durchschnittliche Accuracy √ºber alle Sessions\n",
        "mean_acc = np.mean(all_accuracies)\n",
        "print(\"\\nüìà Zusammenfassung:\")\n",
        "for i, acc in enumerate(all_accuracies):\n",
        "    print(f\"  Session {i+1}: Accuracy = {acc:.2f}\")\n",
        "print(f\"\\n‚úÖ Durchschnittliche Test-Accuracy √ºber alle Sessions: {mean_acc:.2f}\")\n",
        "\n",
        "\n",
        "\n",
        "#üìä Bonus: CSV speichern (optional)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "summary = {'Session': [], 'Accuracy': []}\n",
        "for i, acc in enumerate(all_accuracies):\n",
        "    summary['Session'].append(f\"Session_{i+1}\")\n",
        "    summary['Accuracy'].append(acc)\n",
        "\n",
        "df_summary = pd.DataFrame(summary)\n",
        "df_summary.to_csv(\"session_accuracy_report.csv\", index=False)\n",
        "print(\"üìÅ Bericht gespeichert als session_accuracy_report.csv\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "g9eFJGGxTutz",
        "outputId": "7e0765df-5645-4ea0-ad23-c0b8026c998d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'all_accuracies' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-bb964def7d64>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Durchschnittliche Accuracy √ºber alle Sessions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmean_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_accuracies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nüìà Zusammenfassung:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_accuracies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"  Session {i+1}: Accuracy = {acc:.2f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'all_accuracies' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üíæ II. Modell speichern & sp√§ter wieder laden (z.‚ÄØB. nach Training)\n",
        "\n",
        "##üîê Speichern mit TensorFlow/**Keras**"
      ],
      "metadata": {
        "id": "rbaE9UFeMQ8r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Nach dem Training:\n",
        "#speichert mit timestamp\n",
        "#model.save(\"SenseCap_Eventdetection_Model.keras\")  # speichert nur in colab kurzzeitig\n",
        "import time\n",
        "timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "model.save(f\"/content/drive/MyDrive/ML-MTB-Modell/ML-Model_trained/SenseCap_Model_{timestamp}.keras\")\n",
        "\n"
      ],
      "metadata": {
        "id": "9f0wu8rYM2P3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##üîÑ Laden\n",
        "\n",
        "Das speichert das gesamte Modell inkl. Architektur, Gewichten und Optimizer-Zustand ‚Äìexakt da weitermachen, wo man aufgeh√∂rt hast."
      ],
      "metadata": {
        "id": "Fe6SLk39NNOz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model(\"/content/drive/MyDrive/ML-MTB-Modell/ML-Model_trained/SenseCap_Eventdetection_Model1.keras\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puTdBnHsNHsC",
        "outputId": "e01895fd-40b2-435b-a7f7-44950f5ebdf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 24 variables whereas the saved optimizer has 2 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_accuracies = []\n",
        "\n",
        "for i in range(len(test_sessions_X)):\n",
        "    X_test = test_sessions_X[i]\n",
        "    y_test = test_sessions_y[i]\n",
        "\n",
        "    _, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "    all_accuracies.append(acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "0FK9HYSaUOP0",
        "outputId": "0bb3586c-14d1-4009-e85c-573951307718"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'test_sessions_X' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-49eeb814a429>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mall_accuracies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sessions_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_sessions_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_sessions_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'test_sessions_X' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Durchschnittliche Accuracy √ºber alle Sessions\n",
        "mean_acc = np.mean(all_accuracies)\n",
        "print(\"\\nüìà Zusammenfassung:\")\n",
        "for i, acc in enumerate(all_accuracies):\n",
        "    print(f\"  Session {i+1}: Accuracy = {acc:.2f}\")\n",
        "print(f\"\\n‚úÖ Durchschnittliche Test-Accuracy √ºber alle Sessions: {mean_acc:.2f}\")\n",
        "\n",
        "\n",
        "\n",
        "#üìä Bonus: CSV speichern (optional)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "summary = {'Session': [], 'Accuracy': []}\n",
        "for i, acc in enumerate(all_accuracies):\n",
        "    summary['Session'].append(f\"Session_{i+1}\")\n",
        "    summary['Accuracy'].append(acc)\n",
        "\n",
        "df_summary = pd.DataFrame(summary)\n",
        "df_summary.to_csv(\"session_accuracy_report.csv\", index=False)\n",
        "print(\"üìÅ Bericht gespeichert als session_accuracy_report.csv\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cce6369-7927-49d7-a612-51daac80c42b",
        "id": "p3xuxyPOUOsO"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìà Zusammenfassung:\n",
            "\n",
            "‚úÖ Durchschnittliche Test-Accuracy √ºber alle Sessions: nan\n",
            "üìÅ Bericht gespeichert als session_accuracy_report.csv\n"
          ]
        }
      ]
    }
  ]
}