{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPY6x26ntzPbo064BqqooHR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prinzessinmarlenifee/SenseCap/blob/main/SenseCap_v4_dataaugment_global_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Global Model with Data Augmentation"
      ],
      "metadata": {
        "id": "O-KhIWTdEWH7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##short overview"
      ],
      "metadata": {
        "id": "zvIFoNcZEchA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Saving model and checkpoints for Zwischenspeicherung\n",
        "\n",
        "CSV-sensor data sheet\n",
        "1.   wrist\n",
        "2.   seat\n",
        "3.  head\n",
        "-> 3 Sensoren, 9 Spalten\n",
        "-> checkt erste und zweite Zeile für header (da unterschiedlich)\n",
        "\n",
        "*   hot encoding for labeling\n",
        " Action, Pedaling, Resting, Pushing\n",
        "\n",
        " Summary at end with\n",
        "\n",
        "\n",
        "*   test accuracy\n",
        "*   confusion matrix\n",
        "\n",
        "-> saved and stored in Drive as csv and png file\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "all data is stored in Drive"
      ],
      "metadata": {
        "id": "YGXLzAGkEDb8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model Choice"
      ],
      "metadata": {
        "id": "cXQYTbV4RFPd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "✅ Teil 2: Ist CNN + LSTM eine gute Architektur für IMU-Zeitreihendaten?\n",
        "\n",
        "Ja, das ist eine bewährte Kombination – besonders bei IMU-Daten (z. B. Accelerometer/Gyroscope), weil:\n",
        "🔎 Warum CNN?\n",
        "\n",
        "    Erkennt lokale Muster in kurzen Zeitfenstern (z. B. Bewegungsphasen)\n",
        "\n",
        "    Spart Rechenzeit, da es weniger Parameter hat als ein reines LSTM\n",
        "\n",
        "🔁 Warum LSTM?\n",
        "\n",
        "    Erkennt zeitliche Abhängigkeiten (z. B. Bewegungsabfolgen)\n",
        "\n",
        "    Ideal für sequentielle Daten, wie du sie hast\n",
        "\n",
        "✅ Alternativen oder Erweiterungen\n",
        "\n",
        "Falls du später mehr Leistung brauchst:\n",
        "\n",
        "    Bidirectional LSTM → besser für symmetrische Bewegungsabfolgen\n",
        "\n",
        "    Residual CNN Blocks → für tiefere Netzwerke\n",
        "\n",
        "    Transformer → wenn du sehr viele Daten und lange Sequenzen hast"
      ],
      "metadata": {
        "id": "hPnuFv-Z_HO0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup und Vorbereitung"
      ],
      "metadata": {
        "id": "Q9w-zEMK_K7s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ZQ6FA7vvAKfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Trouble-shooting google drive"
      ],
      "metadata": {
        "id": "3e0otLy6ANTn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#lölscht colab cache\n",
        "!rm -rf /content/drive\n"
      ],
      "metadata": {
        "id": "IwQkZbqz9wF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0l0Ldss-9cb6",
        "outputId": "a697bb52-0451-4074-da81-0325b187c5d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "if os.path.ismount('/content/drive'):\n",
        "    print(\"Drive ist schon gemountet – wird entmountet.\")\n",
        "    drive.flush_and_unmount()\n",
        "\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "s_faCfsS8zFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Packeages and setup"
      ],
      "metadata": {
        "id": "wvh-ULrzAVlo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import packages\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "layers = tf.keras.layers\n",
        "models = tf.keras.models\n"
      ],
      "metadata": {
        "id": "OtTD-qyzDXoH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- PARAMETER ---\n",
        "sampling_rate = 60       # 60 Hz nach SDI-Algorithmus\n",
        "window_size = 60         # 1 Sekunde = 60 Frames\n",
        "step_size = 30           # 50% Überlappung\n",
        "\n",
        "# Basisverzeichnis (sollte die 18 Session-Ordner enthalten)\n",
        "base_dir = '/content/drive/MyDrive/ML-MTB-Modell/IMU-Sessions/'\n"
      ],
      "metadata": {
        "id": "8d9oN1zpDqKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sessions einlesen"
      ],
      "metadata": {
        "id": "bcvlHHFOD36z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#prints founded sessions below\n",
        "session_dirs = sorted([\n",
        "    d for d in os.listdir(base_dir)\n",
        "    if os.path.isdir(os.path.join(base_dir, d))\n",
        "])\n",
        "print(f\"Gefundene Sessions: {len(session_dirs)} -> {session_dirs}\")\n"
      ],
      "metadata": {
        "id": "sqMHmK7wD2YX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fuktionen zum LAbel-Parsing und Datei finden"
      ],
      "metadata": {
        "id": "8puFV7gaEAMI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5.1 parse_hot_labels: Liest die _hot.json-Datei ein, erstellt für jeden Frame ein Label\n",
        "def parse_hot_labels(json_path, total_frames):\n",
        "    with open(json_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "    entries = data['button_presses'].strip().split(';')\n",
        "\n",
        "    label_changes = []\n",
        "    for entry in entries:\n",
        "        if ':' in entry:\n",
        "            label, frame = entry.strip().split(':')\n",
        "            label = label.strip()\n",
        "            # Korrigiere evtl. \"Peadling\" → \"Pedaling\"\n",
        "            if label.lower() == 'peadling':\n",
        "                label = 'Pedaling'\n",
        "            label_changes.append((int(frame.strip()), label))\n",
        "\n",
        "    frame_labels = ['Unknown'] * total_frames\n",
        "    for i, (start_frame, label) in enumerate(label_changes):\n",
        "        end_frame = label_changes[i + 1][0] if i + 1 < len(label_changes) else total_frames\n",
        "        for f in range(start_frame, min(end_frame, total_frames)):\n",
        "            frame_labels[f] = label\n",
        "    return frame_labels\n",
        "\n",
        "# 5.2 find_sensor_file: Findet CSV-Datei, deren Name mit dem Prefix beginnt (Head_, Wrist_, Seat_)\n",
        "def find_sensor_file(folder, prefix):\n",
        "    for f in os.listdir(folder):\n",
        "        if f.lower().startswith(prefix.lower()):\n",
        "            return os.path.join(folder, f)\n",
        "    raise FileNotFoundError(f\"❌ Keine Datei mit Prefix '{prefix}' in {folder} gefunden.\")\n",
        "\n",
        "# 5.3 find_hot_file: Findet JSON-Datei, deren Name auf \"_hot.json\" endet\n",
        "def find_hot_file(folder):\n",
        "    for f in os.listdir(folder):\n",
        "        if f.lower().endswith('_hot.json'):\n",
        "            return os.path.join(folder, f)\n",
        "    raise FileNotFoundError(f\"❌ Keine Datei mit Suffix '_hot.json' in {folder} gefunden.\")\n"
      ],
      "metadata": {
        "id": "lo3wDSUeD-TT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Fensterung für drei Sensoren kombinieren"
      ],
      "metadata": {
        "id": "FYZhfgCTESe4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def window_data_multiple_sensors(head_data, wrist_data, seat_data, frame_labels):\n",
        "    X_windows, y_windows = [], []\n",
        "    total_frames = len(frame_labels)\n",
        "\n",
        "    # Annahme: head_data, wrist_data, seat_data haben alle dieselbe Anzahl Zeilen = total_frames\n",
        "    for start in range(0, total_frames - window_size + 1, step_size):\n",
        "        end = start + window_size\n",
        "\n",
        "        win_h = head_data[start:end]    # (window_size, 6)\n",
        "        win_w = wrist_data[start:end]\n",
        "        win_s = seat_data[start:end]\n",
        "        window = np.concatenate([win_h, win_w, win_s], axis=1)  # → (window_size, 18)\n",
        "\n",
        "        label_window = frame_labels[start:end]\n",
        "        dominant_label = Counter(label_window).most_common(1)[0][0]\n",
        "        if dominant_label == 'Unknown':\n",
        "            continue\n",
        "\n",
        "        X_windows.append(window)\n",
        "        y_windows.append(dominant_label)\n",
        "\n",
        "    return np.array(X_windows), np.array(y_windows)\n"
      ],
      "metadata": {
        "id": "_RKQP4OGEKi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#7. Daten einlesen und Fenster / Labels erzeugen\n",
        "→ Nach Ausführung siehst du für jede Session etwa: “→ 153 Fenster, 3 Klassen” etc."
      ],
      "metadata": {
        "id": "yjBHXCZBEaWp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Vorbereitung\n",
        "sessions_X = []\n",
        "sessions_y = []\n",
        "valid_sessions = []  # <- neue Liste! mit nur valid sessions\n",
        "skipped_sessions = []\n",
        "\n",
        "#features definieren:\n",
        "features = ['Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z']\n",
        "\n",
        "#Funktionen für Daten einlesen\n",
        "def smart_feature_filter(df):\n",
        "    # alles lowercase und leerzeichenfrei vergleichen\n",
        "    keep = [col for col in df.columns if any(kw in col.lower() for kw in ['euler', 'acc', 'gyr'])]\n",
        "    return df[keep]\n",
        "\n",
        "def print_csv_headers(path, label):\n",
        "    with open(path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "    print(f\"\\n📋 {label} → Datei: {os.path.basename(path)}\")\n",
        "    print(\"   Zeile 0:\", lines[0].strip())\n",
        "    print(\"   Zeile 1:\", lines[1].strip())\n",
        "\n",
        "\n",
        "def inspect_sensor_csv(path):\n",
        "    df = pd.read_csv(path, sep=',', skiprows=1)\n",
        "    df.columns = df.columns.str.strip()\n",
        "    print(f\"📊 {os.path.basename(path)}: {df.shape[1]} Spalten\")\n",
        "    print(\"   → Spaltennamen:\", df.columns.tolist())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def load_sensor_csv(path):\n",
        "  import csv\n",
        "\n",
        "  # Erste zwei Zeilen lesen\n",
        "  with open(path, 'r') as f:\n",
        "      reader = csv.reader(f)\n",
        "      first_line = next(reader)\n",
        "      second_line = next(reader)\n",
        "\n",
        "  # Prüfen ob erste Zeile ein Header ist (z. B. mit bekannten Schlüsselwörtern)\n",
        "  first_line_str = \",\".join(first_line).lower()\n",
        "  if any(kw in first_line_str for kw in ['euler', 'acc', 'gyr']):\n",
        "      skip = 0\n",
        "  else:\n",
        "      skip = 1\n",
        "\n",
        "  # Einlesen\n",
        "  df = pd.read_csv(path, sep=',', skiprows=skip)\n",
        "  df.columns = df.columns.str.strip()\n",
        "\n",
        "  # Features filtern\n",
        "  df = smart_feature_filter(df)\n",
        "\n",
        "  # Numerisch umwandeln und NaN behandeln\n",
        "  df = df.apply(pd.to_numeric, errors='coerce').fillna(0).astype(np.float32)\n",
        "\n",
        "  return df.values\n",
        "\n",
        "  print(f\"🔍 {os.path.basename(path)}: Header {'erste Zeile' if skip==0 else 'zweite Zeile'}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# --- Hauptschleife ---\n",
        "for sess_dir in session_dirs:\n",
        "    print(f\"\\n📂 Lade Session: {sess_dir}\")\n",
        "    session_path = os.path.join(base_dir, sess_dir)\n",
        "\n",
        "\n",
        "    # 7.1 Sensor-Dateien finden\n",
        "    head_path  = find_sensor_file(session_path, 'Head_')\n",
        "    wrist_path = find_sensor_file(session_path, 'Wrist_')\n",
        "    seat_path  = find_sensor_file(session_path, 'Seat_')\n",
        "\n",
        "    # 7.2 Hot-JSON-Datei finden\n",
        "    hot_path = find_hot_file(session_path)\n",
        "\n",
        "    inspect_sensor_csv(head_path)\n",
        "    inspect_sensor_csv(wrist_path)\n",
        "    inspect_sensor_csv(seat_path)\n",
        "\n",
        "\n",
        "    #print csv-heads for debugging & checking (oben definierte function print_csv_headers)\n",
        "    #print_csv_headers(head_path, 'Head')\n",
        "    #print_csv_headers(wrist_path, 'Wrist')\n",
        "    #print_csv_headers(seat_path, 'Seat')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # 7.3 IMU-Daten laden\n",
        "    #funktion um imu laden\n",
        "    #aktuelles Problem: header in der zweiten Zeile, seperator ',' , erkennt nur zwei spalten beim einlesen\n",
        "\n",
        "\n",
        "\n",
        "    head_data  = load_sensor_csv(head_path)\n",
        "    wrist_data = load_sensor_csv(wrist_path)\n",
        "    seat_data  = load_sensor_csv(seat_path)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    print(f\"📊 Sensorlängen: Head={head_data.shape}, Wrist={wrist_data.shape}, Seat={seat_data.shape}\")\n",
        "\n",
        "    #expected_features = 27  # 3 Sensoren × 9 Features (oben definiert)\n",
        "   # if X_win.shape[1:] != (window_size, expected_features):\n",
        "    #      print(f\"⚠️ Session {sess_dir} hat Format {X_win.shape[1:]}, wird übersprungen.\")\n",
        "     #     skipped_sessions.append(sess_dir)\n",
        "      #    continue\n",
        "\n",
        "\n",
        "\n",
        "    #7.4 Labels laden\n",
        "    total_frames = min(head_data.shape[0], wrist_data.shape[0], seat_data.shape[0])\n",
        "    frame_labels = parse_hot_labels(hot_path, total_frames)\n",
        "\n",
        "\n",
        "\n",
        "    # 7.5 Sicherheitskürzung (später optional mit synch.json ersetzen)\n",
        "    head_data  = head_data[:total_frames]\n",
        "    wrist_data = wrist_data[:total_frames]\n",
        "    seat_data  = seat_data[:total_frames]\n",
        "    frame_labels = frame_labels[:total_frames]\n",
        "\n",
        "\n",
        "    # 7.6 Fensterung & Label-Zuweisung\n",
        "    X_win, y_win = window_data_multiple_sensors(head_data, wrist_data, seat_data, frame_labels)\n",
        "\n",
        "    # 5. Gültigkeit prüfen\n",
        "    if len(X_win) == 0:\n",
        "        print(f\"⚠️  Session {sess_dir} übersprungen – keine gültigen Fenster.\")\n",
        "        skipped_sessions.append(sess_dir)\n",
        "        continue\n",
        "\n",
        "    expected_features = 27  # oder dynamisch aus den Daten\n",
        "\n",
        "    if X_win.shape[1:] != (window_size, expected_features):\n",
        "        print(f\"⚠️  Session {sess_dir} hat Format {X_win.shape[1:]}, wird übersprungen.\")\n",
        "        skipped_sessions.append(sess_dir)\n",
        "        continue\n",
        "\n",
        "\n",
        "        # 6. Speichern\n",
        "    sessions_X.append(X_win)\n",
        "    sessions_y.append(y_win)\n",
        "    valid_sessions.append(sess_dir)\n",
        "    print(f\"✅ Session {sess_dir}: {len(X_win)} Fenster, {len(np.unique(y_win))} Klassen\")\n",
        "\n",
        "# --- Zusammenfassung ---\n",
        "print(\"\\n✅ Verwendete Sessions:\")\n",
        "for idx, sess in enumerate(valid_sessions):\n",
        "    print(f\"  {sess}: {sessions_X[idx].shape}\")\n",
        "\n",
        "if skipped_sessions:\n",
        "    print(\"\\n⛔️ Übersprungene Sessions:\")\n",
        "    for s in skipped_sessions:\n",
        "        print(f\"  {s}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hAmaAMFEKM_",
        "outputId": "2a43847d-2384-4ecc-b0e5-b9fef5930c92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📂 Lade Session: Session_01\n",
            "📊 Head_D422CD00563B_20230713_082527.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Wrist_D422CD004550_20230713_082527.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Seat_D422CD00456D_20230713_082527.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Sensorlängen: Head=(60077, 9), Wrist=(60078, 9), Seat=(60075, 9)\n",
            "✅ Session Session_01: 1997 Fenster, 3 Klassen\n",
            "\n",
            "📂 Lade Session: Session_02\n",
            "📊 Head_D422CD00563B_20230713_085629.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Wrist_D422CD004550_20230713_085629.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Seat_D422CD00456D_20230713_085629.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Sensorlängen: Head=(48792, 9), Wrist=(48792, 9), Seat=(48784, 9)\n",
            "✅ Session Session_02: 1621 Fenster, 3 Klassen\n",
            "\n",
            "📂 Lade Session: Session_04\n",
            "📊 Head_D422CD00563B_20230717_070932.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Wrist_D422CD004550_20230717_070932.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Seat_D422CD00456D_20230717_070932.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Sensorlängen: Head=(56013, 9), Wrist=(56019, 9), Seat=(56015, 9)\n",
            "✅ Session Session_04: 1864 Fenster, 3 Klassen\n",
            "\n",
            "📂 Lade Session: Session_05\n",
            "📊 Head_D422CD00563B_20230717_070932.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Wrist_D422CD004550_20230717_070932.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Seat_D422CD00456D_20230717_070932.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Sensorlängen: Head=(56013, 9), Wrist=(56019, 9), Seat=(56015, 9)\n",
            "✅ Session Session_05: 1858 Fenster, 4 Klassen\n",
            "\n",
            "📂 Lade Session: Session_06\n",
            "📊 Head_D422CD00563B_20230720_074713.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Wrist_D422CD004550_20230720_074713.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Seat_D422CD00456D_20230720_074713.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Sensorlängen: Head=(64027, 9), Wrist=(64026, 9), Seat=(64025, 9)\n",
            "✅ Session Session_06: 2116 Fenster, 4 Klassen\n",
            "\n",
            "📂 Lade Session: Session_07\n",
            "📊 Head_D422CD00563B_20230720_082728.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Wrist_D422CD004550_20230720_082728.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Seat_D422CD00456D_20230720_082728.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Sensorlängen: Head=(59920, 9), Wrist=(59917, 9), Seat=(59921, 9)\n",
            "✅ Session Session_07: 1991 Fenster, 4 Klassen\n",
            "\n",
            "📂 Lade Session: Session_09\n",
            "📊 Head_D422CD00563B_20230724_072319.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Wrist_D422CD004550_20230724_072319.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Seat_D422CD00456D_20230724_072319.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Sensorlängen: Head=(59464, 9), Wrist=(59465, 9), Seat=(59468, 9)\n",
            "✅ Session Session_09: 1979 Fenster, 4 Klassen\n",
            "\n",
            "📂 Lade Session: Session_10\n",
            "📊 Head_D422CD004576_20230725_070718.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Wrist_D422CD004550_20230725_070718.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Seat_D422CD00456D_20230725_070718.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n",
            "📊 Sensorlängen: Head=(62167, 9), Wrist=(62163, 9), Seat=(62163, 9)\n",
            "✅ Session Session_10: 2061 Fenster, 4 Klassen\n",
            "\n",
            "📂 Lade Session: Session_11\n",
            "📊 Head_D422CD004576_20230727_073528.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-36-bde1625cbf8d>:25: DtypeWarning: Columns (5,6,7,8,9,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(path, sep=',', skiprows=1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Wrist_D422CD004550_20230727_073528.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-36-bde1625cbf8d>:25: DtypeWarning: Columns (5,6,7,8,9,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(path, sep=',', skiprows=1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Seat_D422CD00456D_20230727_073528.csv: 12 Spalten\n",
            "   → Spaltennamen: ['PacketCounter', 'SampleTimeFine', 'Euler_X', 'Euler_Y', 'Euler_Z', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Unnamed: 11']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-36-bde1625cbf8d>:50: DtypeWarning: Columns (5,6,7,8,9,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(path, sep=',', skiprows=skip)\n",
            "<ipython-input-36-bde1625cbf8d>:50: DtypeWarning: Columns (5,6,7,8,9,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(path, sep=',', skiprows=skip)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Sensorlängen: Head=(65763, 9), Wrist=(65763, 9), Seat=(65763, 9)\n",
            "✅ Session Session_11: 2181 Fenster, 4 Klassen\n",
            "\n",
            "📂 Lade Session: Session_12\n",
            "📊 Head_D422CD004576_20230801_075834.csv: 12 Spalten\n",
            "   → Spaltennamen: ['0', '416010770', '-4.522172451019287', '48.04213333129883', '21.0351619720459', '0', '0.1', '0.2', '0.3', '0.4', '0.5', '']\n",
            "📊 Wrist_D422CD004550_20230801_075834.csv: 12 Spalten\n",
            "   → Spaltennamen: ['0', '532295258', '-42.42717361450195', '45.996009826660156', '-55.192440032958984', '0', '0.1', '0.2', '0.3', '0.4', '0.5', '']\n",
            "📊 Seat_D422CD00456D_20230801_075834.csv: 11 Spalten\n",
            "   → Spaltennamen: ['0', '409881162', '2202328491210930', '-6035955047607420', '-8357672119140620', '0.00000000000000', '0.00000000000000.1', '0.00000000000000.2', '0.00000000000000.3', '0.00000000000000.4', '0.00000000000000.5']\n",
            "📊 Sensorlängen: Head=(59523, 9), Wrist=(59524, 9), Seat=(59514, 9)\n",
            "✅ Session Session_12: 1967 Fenster, 4 Klassen\n",
            "\n",
            "📂 Lade Session: Session_13\n",
            "📊 Head_D422CD004576_20230802_080027.csv: 12 Spalten\n",
            "   → Spaltennamen: ['0', '209493532', '-7.16727876663208', '47.413570404052734', '-87.12100219726562', '0', '0.1', '0.2', '0.3', '0.4', '0.5', '']\n",
            "📊 Wrist_D422CD004550_20230802_080027.csv: 12 Spalten\n",
            "   → Spaltennamen: ['0', '358144070', '-41.73847198486328', '23.458871841430664', '-68.4642105102539', '0', '0.1', '0.2', '0.3', '0.4', '0.5', '']\n",
            "📊 Seat_D422CD00456D_20230802_080027.csv: 11 Spalten\n",
            "   → Spaltennamen: ['0', '435628135', '199753963947296', '-6415881347656250', '-16434582519531200', '0.00000000000000', '0.00000000000000.1', '0.00000000000000.2', '0.00000000000000.3', '0.00000000000000.4', '0.00000000000000.5']\n",
            "📊 Sensorlängen: Head=(65046, 9), Wrist=(66494, 9), Seat=(65037, 9)\n",
            "✅ Session Session_13: 2161 Fenster, 4 Klassen\n",
            "\n",
            "📂 Lade Session: Session_14\n",
            "📊 Head_D422CD004576_20230803_073423.csv: 12 Spalten\n",
            "   → Spaltennamen: ['0', '23311239', '5.965623378753662', '-45.560245513916016', '164.4220428466797', '0', '0.1', '0.2', '0.3', '0.4', '0.5', '']\n",
            "📊 Wrist_D422CD004550_20230803_073423.csv: 12 Spalten\n",
            "   → Spaltennamen: ['0', '177062498', '78.41714477539062', '7.847972869873047', '119.1408920288086', '0', '0.1', '0.2', '0.3', '0.4', '0.5', '']\n",
            "📊 Seat_D422CD00456D_20230803_073423.csv: 11 Spalten\n",
            "   → Spaltennamen: ['0', '310191965', '7921337127685540', '-2267286872863770', '-12943373107910100', '0.00000000000000', '0.00000000000000.1', '0.00000000000000.2', '0.00000000000000.3', '0.00000000000000.4', '0.00000000000000.5']\n",
            "📊 Sensorlängen: Head=(58097, 9), Wrist=(58096, 9), Seat=(58086, 9)\n",
            "✅ Session Session_14: 1869 Fenster, 4 Klassen\n",
            "\n",
            "✅ Verwendete Sessions:\n",
            "  Session_01: (1997, 60, 27)\n",
            "  Session_02: (1621, 60, 27)\n",
            "  Session_04: (1864, 60, 27)\n",
            "  Session_05: (1858, 60, 27)\n",
            "  Session_06: (2116, 60, 27)\n",
            "  Session_07: (1991, 60, 27)\n",
            "  Session_09: (1979, 60, 27)\n",
            "  Session_10: (2061, 60, 27)\n",
            "  Session_11: (2181, 60, 27)\n",
            "  Session_12: (1967, 60, 27)\n",
            "  Session_13: (2161, 60, 27)\n",
            "  Session_14: (1869, 60, 27)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "🧠 Dann ist deine Fensterform:\n",
        "\n",
        "    3 Sensoren × 9 Spalten = 27 Features\n",
        "    → Fenster-Shape: (window_size, 27) = (60, 27)\n",
        "\n",
        "\n",
        "Euler_X, Euler_Y, Euler_Z\n",
        "\n",
        "\n",
        "Acc_X, Acc_Y, Acc_Z\n",
        "\n",
        "Gyr_X, Gyr_Y, Gyr_Z\n",
        "\n",
        "→ = 9 physikalisch sinnvolle Spalten pro Sensor"
      ],
      "metadata": {
        "id": "VEmZyAMMpyKX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#8. Global Model: Training and Evaluation\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8szKmR2qE5RI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Schritt-für-Schritt Erklärung\n",
        "\n",
        "  **1. Daten zusammenführen**\n",
        "\n",
        "    Alle Sessions werden zu einem großen Datensatz verbunden, damit das Modell aus allen Beispielen lernt.\n",
        "\n",
        " **2. Label-Encoding**\n",
        "\n",
        "\n",
        "    Die Labels (z.B. verschiedene Aktivitäten) werden in numerische Werte umgewandelt, da das Modell nur mit Zahlen arbeitet.\n",
        "\n",
        " **3. Trainings- und Validierungs-Split**\n",
        "\n",
        "    Der Datensatz wird in Training (90%) und Validation (10%) aufgeteilt. Validation wird genutzt, um das Modell während des Trainings zu überprüfen.\n",
        "\n",
        "  **4. Modell erstellen**\n",
        "\n",
        "    Das Modell kombiniert Convolutional Layers (um lokale Muster in den Zeitreihen zu erkennen) mit LSTM (um zeitliche Abhängigkeiten zu lernen). Dropout wird eingesetzt, um Überanpassung zu vermeiden.\n",
        "\n",
        "  **5. Checkpoint Callback**\n",
        "\n",
        "    Während des Trainings werden Modelle nach jeder Epoche gespeichert (nur die besten, basierend auf Validierungsleistung).\n",
        "\n",
        "  **6. Training**\n",
        "  \n",
        "    Das Modell lernt über 50 Epochen, wobei Trainings- und Validierungsdaten genutzt werden.\n",
        "\n",
        "  **7. Finales Modell speichern**\n",
        "\n",
        "    Das finale Modell wird nach dem Training gespeichert,\n",
        "    um es später laden und nutzen zu können.\n",
        "\n",
        "  **8. Evaluation auf Validierungsdaten**\n",
        "\n",
        "    Das Modell wird auf den Validation-Daten getestet,\n",
        "    um die Genauigkeit zu ermitteln.\n",
        "\n",
        "  **9.  Vorhersagen erzeugen**\n",
        "\n",
        "    Die Wahrscheinlichkeiten für jede Klasse werden ermittelt und in Klassen umgewandelt (höchste Wahrscheinlichkeit = Vorhersage).\n",
        "\n",
        "  **10.  Labels prüfen**\n",
        "\n",
        "    Nur die tatsächlich in den Validierungsdaten vorhandenen Klassen werden für den Bericht verwendet.\n",
        "\n",
        " **11.  Classification Report**\n",
        "\n",
        "    Präzision, Recall, F1-Score und Support für jede Klasse werden ausgegeben — wichtige Kennzahlen für die Modellgüte.\n",
        "\n",
        "  **12.  Confusion Matrix**\n",
        "\n",
        "    Visualisiert die Fehler des Modells,\n",
        "    zeigt welche Klassen oft verwechselt werden.\n"
      ],
      "metadata": {
        "id": "7OWIFUnm-UGI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Code"
      ],
      "metadata": {
        "id": "dz3KLBco-ig9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "import time\n",
        "timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "\n",
        "# 💾 Speicherpfade anlegen\n",
        "checkpoint_dir = \"/content/drive/MyDrive/mtb_project/checkpoints_global\"\n",
        "final_model_dir = \"/content/drive/MyDrive/mtb_project/final_models_global\"\n",
        "report_dir = \"/content/drive/MyDrive/mtb_project/reports_global\"\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "os.makedirs(final_model_dir, exist_ok=True)\n",
        "os.makedirs(report_dir, exist_ok=True)\n",
        "\n",
        "# 🔁 Augmentierungsfunktion\n",
        "def augment_data(X, y, noise_std=0.01, time_shift_max=5):\n",
        "    X_aug, y_aug = [], []\n",
        "    for xi, yi in zip(X, y):\n",
        "      # 1. Leichtes Rauschen hinzufügen\n",
        "        noisy = xi + np.random.normal(0, noise_std, xi.shape)\n",
        "      # 2. Zufälliges Zeitverschieben\n",
        "        shift = np.random.randint(-time_shift_max, time_shift_max)\n",
        "        shifted = np.roll(noisy, shift, axis=0)\n",
        "        # Optional: Padding beim Rollen (statt wrap-around)\n",
        "        if shift > 0:\n",
        "            shifted[:shift, :] = 0\n",
        "        elif shift < 0:\n",
        "            shifted[shift:, :] = 0\n",
        "        X_aug.append(shifted)\n",
        "        y_aug.append(yi)\n",
        "    return np.array(X_aug), np.array(y_aug)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 1️⃣ Sessions zusammenführen (dieser Teil muss mit deinen Daten ergänzt werden!)\n",
        "# Beispiel:\n",
        "X_all = np.concatenate(sessions_X)\n",
        "y_all = np.concatenate(sessions_y)\n",
        "\n",
        "# 2️⃣ Labels encoden\n",
        "le = LabelEncoder()\n",
        "y_all_enc = le.fit_transform(y_all)\n",
        "\n",
        "# 3️⃣ Train/Val-Split\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_all, y_all_enc, test_size=0.1, random_state=42, stratify=y_all_enc\n",
        ")\n",
        "\n",
        "# 4️⃣ Augmentieren – auf Original-Labels\n",
        "y_train_original = le.inverse_transform(y_train)\n",
        "X_aug, y_aug = augment_data(X_train, y_train_original)\n",
        "y_aug_enc = le.transform(y_aug)\n",
        "\n",
        "# 🔀 Kombinieren\n",
        "X_train_combined = np.concatenate([X_train, X_aug])\n",
        "y_train_combined = np.concatenate([y_train, y_aug_enc])\n",
        "\n",
        "# 5️⃣ Modell bauen\n",
        "model = models.Sequential([\n",
        "    layers.Conv1D(64, 3, activation='relu', input_shape=X_train.shape[1:]),\n",
        "    layers.Conv1D(64, 3, activation='relu'),\n",
        "    layers.MaxPooling1D(pool_size=2),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.LSTM(64),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(100, activation='relu'),\n",
        "    layers.Dense(len(le.classes_), activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 6️⃣ Callback für Checkpoints\n",
        "checkpoint_cb = ModelCheckpoint(\n",
        "    filepath=os.path.join(checkpoint_dir, \"global_epoch_{epoch:02d}.keras\"),\n",
        "    save_best_only=True, save_weights_only=False, verbose=1\n",
        ")\n",
        "\n",
        "# 7️⃣ Training\n",
        "history = model.fit(\n",
        "    X_train_combined, y_train_combined,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=50, batch_size=64,\n",
        "    callbacks=[checkpoint_cb]\n",
        ")\n",
        "\n",
        "# 8️⃣ Speichern des finalen Modells\n",
        "model.save(os.path.join(final_model_dir, \"global_model_v4_augment_{timestamp}.keras\"))\n",
        "\n",
        "# 9️⃣ Evaluation\n",
        "val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
        "print(f\"\\n✅ Validation Accuracy: {val_acc:.2f}\")\n",
        "\n",
        "# 🔮 Vorhersagen\n",
        "y_pred_probs = model.predict(X_val, verbose=0)\n",
        "y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "# 📊 Report + Matrix\n",
        "labels_present = unique_labels(y_val, y_pred_classes)\n",
        "report_text = classification_report(\n",
        "    y_val, y_pred_classes,\n",
        "    labels=labels_present,\n",
        "    target_names=[le.classes_[i] for i in labels_present]\n",
        ")\n",
        "print(\"\\n📄 Classification Report:\\n\")\n",
        "print(report_text)\n",
        "\n",
        "# 💾 Speichern als Text\n",
        "with open(os.path.join(report_dir, \"global_model_classification_report_{timestamp}.txt\"), \"w\") as f:\n",
        "    f.write(report_text)\n",
        "\n",
        "# 📈 Confusion Matrix\n",
        "cm = confusion_matrix(y_val, y_pred_classes, labels=labels_present)\n",
        "disp = ConfusionMatrixDisplay(cm, display_labels=[le.classes_[i] for i in labels_present])\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "disp.plot(ax=ax, xticks_rotation=45)\n",
        "plt.title(\"Confusion Matrix – Global Model Validation\")\n",
        "\n",
        "# 💾 Speichern als PNG\n",
        "plt.savefig(os.path.join(report_dir, \"global_model_confusion_matrix_{timestamp}.png\"))\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "rxVuQEL74mVh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8f1d4c4d-27cc-4395-af8c-7d65c5941d4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m665/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5493 - loss: 1.0439\n",
            "Epoch 1: val_loss improved from inf to 0.87584, saving model to /content/drive/MyDrive/mtb_project/checkpoints_global/global_epoch_01.keras\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 47ms/step - accuracy: 0.5494 - loss: 1.0437 - val_accuracy: 0.6210 - val_loss: 0.8758\n",
            "Epoch 2/50\n",
            "\u001b[1m665/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5933 - loss: 0.8939\n",
            "Epoch 2: val_loss improved from 0.87584 to 0.86314, saving model to /content/drive/MyDrive/mtb_project/checkpoints_global/global_epoch_02.keras\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 46ms/step - accuracy: 0.5933 - loss: 0.8939 - val_accuracy: 0.6257 - val_loss: 0.8631\n",
            "Epoch 3/50\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6049 - loss: 0.8535\n",
            "Epoch 3: val_loss improved from 0.86314 to 0.82063, saving model to /content/drive/MyDrive/mtb_project/checkpoints_global/global_epoch_03.keras\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 57ms/step - accuracy: 0.6049 - loss: 0.8535 - val_accuracy: 0.6096 - val_loss: 0.8206\n",
            "Epoch 4/50\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.6354 - loss: 0.8060\n",
            "Epoch 4: val_loss improved from 0.82063 to 0.81743, saving model to /content/drive/MyDrive/mtb_project/checkpoints_global/global_epoch_04.keras\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 66ms/step - accuracy: 0.6354 - loss: 0.8060 - val_accuracy: 0.6443 - val_loss: 0.8174\n",
            "Epoch 5/50\n",
            "\u001b[1m665/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.6452 - loss: 0.7794\n",
            "Epoch 5: val_loss improved from 0.81743 to 0.76229, saving model to /content/drive/MyDrive/mtb_project/checkpoints_global/global_epoch_05.keras\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 55ms/step - accuracy: 0.6452 - loss: 0.7794 - val_accuracy: 0.6760 - val_loss: 0.7623\n",
            "Epoch 6/50\n",
            "\u001b[1m665/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.6568 - loss: 0.7591\n",
            "Epoch 6: val_loss did not improve from 0.76229\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 54ms/step - accuracy: 0.6568 - loss: 0.7591 - val_accuracy: 0.6646 - val_loss: 0.7868\n",
            "Epoch 7/50\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6543 - loss: 0.7640\n",
            "Epoch 7: val_loss improved from 0.76229 to 0.75568, saving model to /content/drive/MyDrive/mtb_project/checkpoints_global/global_epoch_07.keras\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 47ms/step - accuracy: 0.6543 - loss: 0.7640 - val_accuracy: 0.6409 - val_loss: 0.7557\n",
            "Epoch 8/50\n",
            "\u001b[1m665/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6516 - loss: 0.7611\n",
            "Epoch 8: val_loss improved from 0.75568 to 0.75229, saving model to /content/drive/MyDrive/mtb_project/checkpoints_global/global_epoch_08.keras\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 57ms/step - accuracy: 0.6516 - loss: 0.7611 - val_accuracy: 0.6831 - val_loss: 0.7523\n",
            "Epoch 9/50\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.6622 - loss: 0.7539\n",
            "Epoch 9: val_loss improved from 0.75229 to 0.72280, saving model to /content/drive/MyDrive/mtb_project/checkpoints_global/global_epoch_09.keras\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 55ms/step - accuracy: 0.6622 - loss: 0.7539 - val_accuracy: 0.7009 - val_loss: 0.7228\n",
            "Epoch 10/50\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.6682 - loss: 0.7477\n",
            "Epoch 10: val_loss improved from 0.72280 to 0.70671, saving model to /content/drive/MyDrive/mtb_project/checkpoints_global/global_epoch_10.keras\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 67ms/step - accuracy: 0.6682 - loss: 0.7477 - val_accuracy: 0.7114 - val_loss: 0.7067\n",
            "Epoch 11/50\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.6865 - loss: 0.7302\n",
            "Epoch 11: val_loss did not improve from 0.70671\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 53ms/step - accuracy: 0.6865 - loss: 0.7302 - val_accuracy: 0.7161 - val_loss: 0.7258\n",
            "Epoch 12/50\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6828 - loss: 0.7328\n",
            "Epoch 12: val_loss improved from 0.70671 to 0.69934, saving model to /content/drive/MyDrive/mtb_project/checkpoints_global/global_epoch_12.keras\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 46ms/step - accuracy: 0.6828 - loss: 0.7328 - val_accuracy: 0.7005 - val_loss: 0.6993\n",
            "Epoch 13/50\n",
            "\u001b[1m665/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.6850 - loss: 0.7197\n",
            "Epoch 13: val_loss did not improve from 0.69934\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 73ms/step - accuracy: 0.6850 - loss: 0.7197 - val_accuracy: 0.6971 - val_loss: 0.7210\n",
            "Epoch 14/50\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6713 - loss: 0.7256\n",
            "Epoch 14: val_loss improved from 0.69934 to 0.69844, saving model to /content/drive/MyDrive/mtb_project/checkpoints_global/global_epoch_14.keras\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 47ms/step - accuracy: 0.6713 - loss: 0.7256 - val_accuracy: 0.7127 - val_loss: 0.6984\n",
            "Epoch 15/50\n",
            "\u001b[1m665/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6846 - loss: 0.7206\n",
            "Epoch 15: val_loss improved from 0.69844 to 0.69293, saving model to /content/drive/MyDrive/mtb_project/checkpoints_global/global_epoch_15.keras\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 47ms/step - accuracy: 0.6846 - loss: 0.7206 - val_accuracy: 0.7241 - val_loss: 0.6929\n",
            "Epoch 16/50\n",
            "\u001b[1m665/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.6826 - loss: 0.7121\n",
            "Epoch 16: val_loss improved from 0.69293 to 0.66116, saving model to /content/drive/MyDrive/mtb_project/checkpoints_global/global_epoch_16.keras\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 66ms/step - accuracy: 0.6826 - loss: 0.7121 - val_accuracy: 0.7334 - val_loss: 0.6612\n",
            "Epoch 17/50\n",
            "\u001b[1m665/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.6920 - loss: 0.7171\n",
            "Epoch 17: val_loss did not improve from 0.66116\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 55ms/step - accuracy: 0.6920 - loss: 0.7171 - val_accuracy: 0.7360 - val_loss: 0.6785\n",
            "Epoch 18/50\n",
            "\u001b[1m665/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.6847 - loss: 0.7070\n",
            "Epoch 18: val_loss did not improve from 0.66116\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 55ms/step - accuracy: 0.6847 - loss: 0.7070 - val_accuracy: 0.7376 - val_loss: 0.6730\n",
            "Epoch 19/50\n",
            "\u001b[1m665/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.6895 - loss: 0.6991\n",
            "Epoch 19: val_loss did not improve from 0.66116\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 68ms/step - accuracy: 0.6895 - loss: 0.6990 - val_accuracy: 0.7224 - val_loss: 0.6774\n",
            "Epoch 20/50\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6900 - loss: 0.6963\n",
            "Epoch 20: val_loss did not improve from 0.66116\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 46ms/step - accuracy: 0.6900 - loss: 0.6963 - val_accuracy: 0.7098 - val_loss: 0.6895\n",
            "Epoch 21/50\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.6819 - loss: 0.7007\n",
            "Epoch 21: val_loss did not improve from 0.66116\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 53ms/step - accuracy: 0.6820 - loss: 0.7007 - val_accuracy: 0.6988 - val_loss: 0.6755\n",
            "Epoch 22/50\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.6800 - loss: 0.7058\n",
            "Epoch 22: val_loss did not improve from 0.66116\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 50ms/step - accuracy: 0.6800 - loss: 0.7058 - val_accuracy: 0.7220 - val_loss: 0.6855\n",
            "Epoch 23/50\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6840 - loss: 0.6977\n",
            "Epoch 23: val_loss did not improve from 0.66116\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 49ms/step - accuracy: 0.6840 - loss: 0.6977 - val_accuracy: 0.7051 - val_loss: 0.6839\n",
            "Epoch 24/50\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6868 - loss: 0.6985\n",
            "Epoch 24: val_loss did not improve from 0.66116\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 46ms/step - accuracy: 0.6868 - loss: 0.6985 - val_accuracy: 0.7140 - val_loss: 0.6972\n",
            "Epoch 25/50\n",
            "\u001b[1m665/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6942 - loss: 0.6926\n",
            "Epoch 25: val_loss improved from 0.66116 to 0.66058, saving model to /content/drive/MyDrive/mtb_project/checkpoints_global/global_epoch_25.keras\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 46ms/step - accuracy: 0.6942 - loss: 0.6926 - val_accuracy: 0.7343 - val_loss: 0.6606\n",
            "Epoch 26/50\n",
            "\u001b[1m665/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6973 - loss: 0.6952\n",
            "Epoch 26: val_loss improved from 0.66058 to 0.66043, saving model to /content/drive/MyDrive/mtb_project/checkpoints_global/global_epoch_26.keras\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 46ms/step - accuracy: 0.6973 - loss: 0.6952 - val_accuracy: 0.7292 - val_loss: 0.6604\n",
            "Epoch 27/50\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6940 - loss: 0.6908\n",
            "Epoch 27: val_loss did not improve from 0.66043\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 45ms/step - accuracy: 0.6940 - loss: 0.6907 - val_accuracy: 0.7076 - val_loss: 0.6771\n",
            "Epoch 28/50\n",
            "\u001b[1m665/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7107 - loss: 0.6814\n",
            "Epoch 28: val_loss did not improve from 0.66043\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 45ms/step - accuracy: 0.7107 - loss: 0.6815 - val_accuracy: 0.7165 - val_loss: 0.6924\n",
            "Epoch 29/50\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6905 - loss: 0.6994\n",
            "Epoch 29: val_loss did not improve from 0.66043\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 46ms/step - accuracy: 0.6905 - loss: 0.6994 - val_accuracy: 0.7076 - val_loss: 0.6819\n",
            "Epoch 30/50\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7036 - loss: 0.6759\n",
            "Epoch 30: val_loss did not improve from 0.66043\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 46ms/step - accuracy: 0.7036 - loss: 0.6759 - val_accuracy: 0.6920 - val_loss: 0.6831\n",
            "Epoch 31/50\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.6913 - loss: 0.6846\n",
            "Epoch 31: val_loss improved from 0.66043 to 0.65471, saving model to /content/drive/MyDrive/mtb_project/checkpoints_global/global_epoch_31.keras\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 57ms/step - accuracy: 0.6913 - loss: 0.6846 - val_accuracy: 0.7300 - val_loss: 0.6547\n",
            "Epoch 32/50\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.6989 - loss: 0.6813\n",
            "Epoch 32: val_loss did not improve from 0.65471\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 65ms/step - accuracy: 0.6989 - loss: 0.6813 - val_accuracy: 0.7245 - val_loss: 0.6737\n",
            "Epoch 33/50\n",
            "\u001b[1m665/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7062 - loss: 0.6716\n",
            "Epoch 33: val_loss did not improve from 0.65471\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 61ms/step - accuracy: 0.7062 - loss: 0.6716 - val_accuracy: 0.7123 - val_loss: 0.6910\n",
            "Epoch 34/50\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.6938 - loss: 0.6882\n",
            "Epoch 34: val_loss did not improve from 0.65471\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 59ms/step - accuracy: 0.6938 - loss: 0.6882 - val_accuracy: 0.7076 - val_loss: 0.6701\n",
            "Epoch 35/50\n",
            "\u001b[1m665/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7014 - loss: 0.6796\n",
            "Epoch 35: val_loss improved from 0.65471 to 0.65216, saving model to /content/drive/MyDrive/mtb_project/checkpoints_global/global_epoch_35.keras\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 46ms/step - accuracy: 0.7014 - loss: 0.6796 - val_accuracy: 0.7186 - val_loss: 0.6522\n",
            "Epoch 36/50\n",
            "\u001b[1m665/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7105 - loss: 0.6667\n",
            "Epoch 36: val_loss did not improve from 0.65216\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 46ms/step - accuracy: 0.7105 - loss: 0.6667 - val_accuracy: 0.7229 - val_loss: 0.6528\n",
            "Epoch 37/50\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7166 - loss: 0.6645\n",
            "Epoch 37: val_loss did not improve from 0.65216\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 46ms/step - accuracy: 0.7166 - loss: 0.6645 - val_accuracy: 0.7313 - val_loss: 0.6673\n",
            "Epoch 38/50\n",
            "\u001b[1m665/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.7098 - loss: 0.6716\n",
            "Epoch 38: val_loss did not improve from 0.65216\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 49ms/step - accuracy: 0.7098 - loss: 0.6716 - val_accuracy: 0.7157 - val_loss: 0.6661\n",
            "Epoch 39/50\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7174 - loss: 0.6606\n",
            "Epoch 39: val_loss did not improve from 0.65216\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 47ms/step - accuracy: 0.7174 - loss: 0.6606 - val_accuracy: 0.7076 - val_loss: 0.6714\n",
            "Epoch 40/50\n",
            "\u001b[1m665/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7138 - loss: 0.6721\n",
            "Epoch 40: val_loss did not improve from 0.65216\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 46ms/step - accuracy: 0.7138 - loss: 0.6721 - val_accuracy: 0.7064 - val_loss: 0.6671\n",
            "Epoch 41/50\n",
            "\u001b[1m665/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7052 - loss: 0.6755\n",
            "Epoch 41: val_loss did not improve from 0.65216\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 45ms/step - accuracy: 0.7052 - loss: 0.6755 - val_accuracy: 0.7064 - val_loss: 0.6848\n",
            "Epoch 42/50\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7056 - loss: 0.6707\n",
            "Epoch 42: val_loss did not improve from 0.65216\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 45ms/step - accuracy: 0.7056 - loss: 0.6707 - val_accuracy: 0.7005 - val_loss: 0.6664\n",
            "Epoch 43/50\n",
            "\u001b[1m665/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7012 - loss: 0.6742\n",
            "Epoch 43: val_loss did not improve from 0.65216\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 45ms/step - accuracy: 0.7012 - loss: 0.6742 - val_accuracy: 0.7123 - val_loss: 0.6734\n",
            "Epoch 44/50\n",
            "\u001b[1m665/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7052 - loss: 0.6783\n",
            "Epoch 44: val_loss did not improve from 0.65216\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 46ms/step - accuracy: 0.7052 - loss: 0.6783 - val_accuracy: 0.7123 - val_loss: 0.6622\n",
            "Epoch 45/50\n",
            "\u001b[1m665/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7144 - loss: 0.6696\n",
            "Epoch 45: val_loss did not improve from 0.65216\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 46ms/step - accuracy: 0.7144 - loss: 0.6696 - val_accuracy: 0.7144 - val_loss: 0.6574\n",
            "Epoch 46/50\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7117 - loss: 0.6651\n",
            "Epoch 46: val_loss did not improve from 0.65216\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 46ms/step - accuracy: 0.7117 - loss: 0.6651 - val_accuracy: 0.7055 - val_loss: 0.6664\n",
            "Epoch 47/50\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7118 - loss: 0.6658\n",
            "Epoch 47: val_loss improved from 0.65216 to 0.65178, saving model to /content/drive/MyDrive/mtb_project/checkpoints_global/global_epoch_47.keras\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 46ms/step - accuracy: 0.7118 - loss: 0.6658 - val_accuracy: 0.7267 - val_loss: 0.6518\n",
            "Epoch 48/50\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7065 - loss: 0.6770\n",
            "Epoch 48: val_loss did not improve from 0.65178\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 46ms/step - accuracy: 0.7065 - loss: 0.6770 - val_accuracy: 0.7245 - val_loss: 0.6684\n",
            "Epoch 49/50\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7008 - loss: 0.6793\n",
            "Epoch 49: val_loss did not improve from 0.65178\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 51ms/step - accuracy: 0.7008 - loss: 0.6793 - val_accuracy: 0.7051 - val_loss: 0.6638\n",
            "Epoch 50/50\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6959 - loss: 0.6860\n",
            "Epoch 50: val_loss did not improve from 0.65178\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 47ms/step - accuracy: 0.6959 - loss: 0.6860 - val_accuracy: 0.7144 - val_loss: 0.6682\n",
            "\n",
            "✅ Validation Accuracy: 0.71\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📄 Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Action       0.61      0.67      0.64       766\n",
            "    Pedaling       0.00      0.00      0.00        73\n",
            "     Pushing       0.76      0.52      0.62       225\n",
            "     Resting       0.78      0.82      0.79      1303\n",
            "\n",
            "    accuracy                           0.71      2367\n",
            "   macro avg       0.54      0.50      0.51      2367\n",
            "weighted avg       0.70      0.71      0.70      2367\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#🧾 Zusammenfassung Modeltraining\n",
        "##📊 1. Durchschnittliche Accuracy über alle Sessions:"
      ],
      "metadata": {
        "id": "q-yhvJmXzOjU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#📊 1. Durchschnittliche Accuracy über alle Sessions:\n",
        "\n",
        "mean_acc = np.mean(all_accuracies)\n",
        "print(\"\\n📈 Zusammenfassung:\")\n",
        "for i, acc in enumerate(all_accuracies):\n",
        "    print(f\"  Session {i+1}: Accuracy = {acc:.2f}\")\n",
        "print(f\"\\n✅ Durchschnittliche Test-Accuracy über alle Sessions: {mean_acc:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "5ZKwF6fOy75p",
        "outputId": "0ea2850d-5897-444f-bbea-611e688ec0d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'all_accuracies' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-ff1e0f4f9e92>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#📊 1. Durchschnittliche Accuracy über alle Sessions:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmean_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_accuracies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n📈 Zusammenfassung:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_accuracies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'all_accuracies' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##📁 2. CSV speichern (falls nicht schon vorhanden):"
      ],
      "metadata": {
        "id": "Evqv6rIczcn0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#📁 2. CSV speichern (falls nicht schon vorhanden):\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df_summary = pd.DataFrame(accuracy_summary)\n",
        "df_summary['Session'] = [f\"Session_{i+1}\" for i in range(len(all_accuracies))]\n",
        "df_summary.to_csv(\"/content/drive/MyDrive/mtb_project/session_accuracy_report.csv\", index=False)\n",
        "print(\"✅ Bericht gespeichert unter: session_accuracy_report.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AxzlH2XzXA9",
        "outputId": "cc0684b5-4bd9-428b-b823-35d8283e50d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Bericht gespeichert unter: session_accuracy_report.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "all_accuracies = []\n",
        "accuracy_summary = {'Session': [], 'Accuracy': []}\n",
        "\n",
        "for test_idx in range(len(sessions_X)):\n",
        "    sess_name = session_dirs[test_idx]\n",
        "    print(f\"\\n📌 Teste auf Session (unbekannt): {sess_name} ({test_idx+1}/{len(sessions_X)})\")\n",
        "\n",
        "    # 8.1 Test-Daten definieren\n",
        "    X_test = sessions_X[test_idx]\n",
        "    y_test = sessions_y[test_idx]\n",
        "\n",
        "\n",
        "\n",
        "    # 8.2 Train-Daten: alle anderen Sessions zusammenschneiden\n",
        "    X_train = np.concatenate([x for i, x in enumerate(sessions_X) if i != test_idx])\n",
        "    y_train = np.concatenate([y for i, y in enumerate(sessions_y) if i != test_idx])\n",
        "\n",
        "    # 8.3 Label-Encoding (fit auf Trainingsdaten, transform auf beides)\n",
        "    le = LabelEncoder()\n",
        "    y_train_enc = le.fit_transform(y_train)\n",
        "    y_test_enc = le.transform(y_test)\n",
        "\n",
        "    # 8.4 Modell-Definition: CNN + LSTM\n",
        "    model = models.Sequential([\n",
        "        layers.Conv1D(64, 3, activation='relu', input_shape=X_train.shape[1:]),\n",
        "        layers.Conv1D(64, 3, activation='relu'),\n",
        "        layers.MaxPooling1D(pool_size=2),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.LSTM(64),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(100, activation='relu'),\n",
        "        layers.Dense(len(le.classes_), activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    # 8.5 Training (mit 10 % Validierungssplit aus Trainingsdaten)\n",
        "\n",
        "    from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "    import os\n",
        "\n",
        "    # 1. 📁 Sicherstellen, dass Speicherort existiert\n",
        "    checkpoint_dir = \"/content/drive/MyDrive/mtb_project/checkpoints\"\n",
        "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "    # 2. 🎯 Callback definieren\n",
        "    checkpoint_cb = ModelCheckpoint(\n",
        "        filepath = os.path.join(checkpoint_dir, f\"{sess_name}_epoch_{{epoch:02d}}.keras\"),\n",
        "        save_best_only=False,         # du bekommst jedes Epoch-Modell\n",
        "        save_weights_only=False,      # speichert das ganze Modell, nicht nur Gewichte\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "# 3. 🚀 Training starten (Callback hinzufügen!)\n",
        "\n",
        "\n",
        "    # mit checkpoints zum speichern\n",
        "    history = model.fit(\n",
        "        X_train, y_train_enc,\n",
        "        validation_data=(X_val, y_val),\n",
        "        epochs=50,\n",
        "        batch_size=64,\n",
        "        callbacks=[checkpoint_cb] #-> automatische zwischenspeicherung\n",
        "    )\n",
        "\n",
        "    # 8.6 Evaluation auf Test-Session\n",
        "    test_loss, test_acc = model.evaluate(X_test, y_test_enc, verbose=0)\n",
        "    print(f\"✅ Test-Accuracy für {sess_name}: {test_acc:.2f}\")\n",
        "    all_accuracies.append(test_acc)\n",
        "    accuracy_summary['Session'].append(sess_name)\n",
        "    accuracy_summary['Accuracy'].append(test_acc)\n",
        "\n",
        "    import time\n",
        "    timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "    # 8.7 Klassifikationsbericht & Confusion Matrix\n",
        "    # 🔍 Report berechnen\n",
        "    print(\"\\nKlassifikationsbericht:\")\n",
        "    report_text = classification_report(\n",
        "        y_test_enc,\n",
        "        y_pred_classes,\n",
        "        target_names=[le.classes_[i] for i in labels_present],\n",
        "        labels=labels_present\n",
        "    )\n",
        "    print(report_text)\n",
        "\n",
        "    # 💾 Bericht speichern (Textdatei)\n",
        "    os.makedirs(\"/content/drive/MyDrive/mtb_project/reports\", exist_ok=True)\n",
        "    with open(f\"/content/drive/MyDrive/mtb_project/reports/{timestamp}_v4_classification_report_augment.txt\", \"w\") as f:\n",
        "        f.write(report_text)\n",
        "        print(f\"📁 Bericht für {timestamp} gespeichert.\")\n",
        "\n",
        "\n",
        "    # 📊 Confusion Matrix anzeigen & speichern\n",
        "    cm = confusion_matrix(y_test_enc, y_pred_classes, labels=labels_present)\n",
        "    fig, ax = plt.subplots(figsize=(8, 6))\n",
        "    disp = ConfusionMatrixDisplay(cm, display_labels=[le.classes_[i] for i in labels_present])\n",
        "    disp.plot(ax=ax, xticks_rotation=45)\n",
        "    plt.title(f\"Confusion Matrix – {timestamp}\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"/content/drive/MyDrive/mtb_project/reports/{timestamp}_v4_confusion_matrix_augment.png\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "zlJAElwcE1L8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3d070d09-4510-4653-a616-71a4b627a919"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📌 Teste auf Session (unbekannt): Session_01 (1/12)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5717 - loss: 1.0202\n",
            "Epoch 1: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_01.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 45ms/step - accuracy: 0.5718 - loss: 1.0200 - val_accuracy: 0.5855 - val_loss: 0.9273\n",
            "Epoch 2/50\n",
            "\u001b[1m329/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6225 - loss: 0.8839\n",
            "Epoch 2: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_02.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 42ms/step - accuracy: 0.6225 - loss: 0.8838 - val_accuracy: 0.6175 - val_loss: 0.8609\n",
            "Epoch 3/50\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6429 - loss: 0.8232\n",
            "Epoch 3: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_03.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 42ms/step - accuracy: 0.6429 - loss: 0.8232 - val_accuracy: 0.6352 - val_loss: 0.8286\n",
            "Epoch 4/50\n",
            "\u001b[1m329/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6582 - loss: 0.7952\n",
            "Epoch 4: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_04.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 43ms/step - accuracy: 0.6581 - loss: 0.7951 - val_accuracy: 0.6348 - val_loss: 0.8224\n",
            "Epoch 5/50\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6613 - loss: 0.7781\n",
            "Epoch 5: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_05.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 41ms/step - accuracy: 0.6613 - loss: 0.7780 - val_accuracy: 0.6421 - val_loss: 0.8242\n",
            "Epoch 6/50\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6776 - loss: 0.7500\n",
            "Epoch 6: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_06.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 42ms/step - accuracy: 0.6777 - loss: 0.7500 - val_accuracy: 0.6495 - val_loss: 0.8258\n",
            "Epoch 7/50\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6768 - loss: 0.7391\n",
            "Epoch 7: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_07.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 44ms/step - accuracy: 0.6768 - loss: 0.7391 - val_accuracy: 0.6517 - val_loss: 0.8004\n",
            "Epoch 8/50\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6813 - loss: 0.7357\n",
            "Epoch 8: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_08.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 41ms/step - accuracy: 0.6813 - loss: 0.7357 - val_accuracy: 0.6517 - val_loss: 0.7841\n",
            "Epoch 9/50\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6894 - loss: 0.7241\n",
            "Epoch 9: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_09.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 43ms/step - accuracy: 0.6894 - loss: 0.7241 - val_accuracy: 0.6452 - val_loss: 0.8039\n",
            "Epoch 10/50\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6928 - loss: 0.7141\n",
            "Epoch 10: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_10.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 45ms/step - accuracy: 0.6928 - loss: 0.7141 - val_accuracy: 0.6551 - val_loss: 0.8198\n",
            "Epoch 11/50\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6943 - loss: 0.7089\n",
            "Epoch 11: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_11.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 42ms/step - accuracy: 0.6943 - loss: 0.7089 - val_accuracy: 0.6642 - val_loss: 0.7875\n",
            "Epoch 12/50\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6950 - loss: 0.6939\n",
            "Epoch 12: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_12.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 40ms/step - accuracy: 0.6950 - loss: 0.6939 - val_accuracy: 0.6595 - val_loss: 0.7868\n",
            "Epoch 13/50\n",
            "\u001b[1m329/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7049 - loss: 0.6885\n",
            "Epoch 13: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_13.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 41ms/step - accuracy: 0.7049 - loss: 0.6885 - val_accuracy: 0.6621 - val_loss: 0.8394\n",
            "Epoch 14/50\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7031 - loss: 0.6850\n",
            "Epoch 14: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_14.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 43ms/step - accuracy: 0.7031 - loss: 0.6850 - val_accuracy: 0.6599 - val_loss: 0.8265\n",
            "Epoch 15/50\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7049 - loss: 0.6788\n",
            "Epoch 15: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_15.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 43ms/step - accuracy: 0.7049 - loss: 0.6788 - val_accuracy: 0.6556 - val_loss: 0.8464\n",
            "Epoch 16/50\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7067 - loss: 0.6721\n",
            "Epoch 16: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_16.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 43ms/step - accuracy: 0.7066 - loss: 0.6722 - val_accuracy: 0.6538 - val_loss: 0.8859\n",
            "Epoch 17/50\n",
            "\u001b[1m329/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6986 - loss: 0.6742\n",
            "Epoch 17: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_17.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 43ms/step - accuracy: 0.6986 - loss: 0.6743 - val_accuracy: 0.6430 - val_loss: 0.8478\n",
            "Epoch 18/50\n",
            "\u001b[1m329/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7032 - loss: 0.6836\n",
            "Epoch 18: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_18.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 43ms/step - accuracy: 0.7031 - loss: 0.6836 - val_accuracy: 0.6659 - val_loss: 0.8619\n",
            "Epoch 19/50\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7128 - loss: 0.6675\n",
            "Epoch 19: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_19.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 41ms/step - accuracy: 0.7127 - loss: 0.6675 - val_accuracy: 0.6776 - val_loss: 0.8383\n",
            "Epoch 20/50\n",
            "\u001b[1m329/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7157 - loss: 0.6599\n",
            "Epoch 20: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_20.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 42ms/step - accuracy: 0.7157 - loss: 0.6599 - val_accuracy: 0.6473 - val_loss: 0.8563\n",
            "Epoch 21/50\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7075 - loss: 0.6774\n",
            "Epoch 21: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_21.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 42ms/step - accuracy: 0.7075 - loss: 0.6774 - val_accuracy: 0.6621 - val_loss: 0.8443\n",
            "Epoch 22/50\n",
            "\u001b[1m329/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7168 - loss: 0.6579\n",
            "Epoch 22: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_22.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 42ms/step - accuracy: 0.7168 - loss: 0.6579 - val_accuracy: 0.6772 - val_loss: 0.8689\n",
            "Epoch 23/50\n",
            "\u001b[1m329/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7138 - loss: 0.6564\n",
            "Epoch 23: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_23.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 48ms/step - accuracy: 0.7138 - loss: 0.6564 - val_accuracy: 0.6733 - val_loss: 0.8491\n",
            "Epoch 24/50\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7176 - loss: 0.6538\n",
            "Epoch 24: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_24.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 43ms/step - accuracy: 0.7176 - loss: 0.6538 - val_accuracy: 0.6672 - val_loss: 0.8425\n",
            "Epoch 25/50\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7071 - loss: 0.6649\n",
            "Epoch 25: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_25.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 41ms/step - accuracy: 0.7071 - loss: 0.6649 - val_accuracy: 0.6876 - val_loss: 0.8408\n",
            "Epoch 26/50\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7149 - loss: 0.6520\n",
            "Epoch 26: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_26.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 41ms/step - accuracy: 0.7149 - loss: 0.6521 - val_accuracy: 0.6906 - val_loss: 0.8515\n",
            "Epoch 27/50\n",
            "\u001b[1m329/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7189 - loss: 0.6573\n",
            "Epoch 27: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_27.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 43ms/step - accuracy: 0.7189 - loss: 0.6572 - val_accuracy: 0.6820 - val_loss: 0.9324\n",
            "Epoch 28/50\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7151 - loss: 0.6538\n",
            "Epoch 28: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_28.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 44ms/step - accuracy: 0.7151 - loss: 0.6537 - val_accuracy: 0.7049 - val_loss: 0.8696\n",
            "Epoch 29/50\n",
            "\u001b[1m329/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7273 - loss: 0.6314\n",
            "Epoch 29: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_29.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 42ms/step - accuracy: 0.7273 - loss: 0.6314 - val_accuracy: 0.7014 - val_loss: 0.8505\n",
            "Epoch 30/50\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7288 - loss: 0.6337\n",
            "Epoch 30: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_30.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 41ms/step - accuracy: 0.7288 - loss: 0.6337 - val_accuracy: 0.7010 - val_loss: 0.8367\n",
            "Epoch 31/50\n",
            "\u001b[1m329/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7408 - loss: 0.6132\n",
            "Epoch 31: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_31.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 42ms/step - accuracy: 0.7408 - loss: 0.6132 - val_accuracy: 0.7122 - val_loss: 0.8613\n",
            "Epoch 32/50\n",
            "\u001b[1m329/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7305 - loss: 0.6314\n",
            "Epoch 32: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_32.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 42ms/step - accuracy: 0.7305 - loss: 0.6314 - val_accuracy: 0.7071 - val_loss: 0.8311\n",
            "Epoch 33/50\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7247 - loss: 0.6387\n",
            "Epoch 33: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_33.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 43ms/step - accuracy: 0.7247 - loss: 0.6387 - val_accuracy: 0.7045 - val_loss: 0.7961\n",
            "Epoch 34/50\n",
            "\u001b[1m329/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7413 - loss: 0.6111\n",
            "Epoch 34: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_34.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 48ms/step - accuracy: 0.7413 - loss: 0.6112 - val_accuracy: 0.6971 - val_loss: 0.8569\n",
            "Epoch 35/50\n",
            "\u001b[1m329/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7363 - loss: 0.6216\n",
            "Epoch 35: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_35.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 40ms/step - accuracy: 0.7363 - loss: 0.6216 - val_accuracy: 0.6988 - val_loss: 0.8012\n",
            "Epoch 36/50\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7389 - loss: 0.6176\n",
            "Epoch 36: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_36.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 40ms/step - accuracy: 0.7389 - loss: 0.6176 - val_accuracy: 0.7049 - val_loss: 0.7753\n",
            "Epoch 37/50\n",
            "\u001b[1m329/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7411 - loss: 0.6263\n",
            "Epoch 37: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_37.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 42ms/step - accuracy: 0.7411 - loss: 0.6262 - val_accuracy: 0.7101 - val_loss: 0.8593\n",
            "Epoch 38/50\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7458 - loss: 0.6112\n",
            "Epoch 38: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_38.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 40ms/step - accuracy: 0.7458 - loss: 0.6112 - val_accuracy: 0.7127 - val_loss: 0.8166\n",
            "Epoch 39/50\n",
            "\u001b[1m329/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7271 - loss: 0.6270\n",
            "Epoch 39: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_39.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 42ms/step - accuracy: 0.7271 - loss: 0.6270 - val_accuracy: 0.7135 - val_loss: 0.8409\n",
            "Epoch 40/50\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7474 - loss: 0.6016\n",
            "Epoch 40: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_40.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 43ms/step - accuracy: 0.7474 - loss: 0.6016 - val_accuracy: 0.7135 - val_loss: 0.8805\n",
            "Epoch 41/50\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7433 - loss: 0.6148\n",
            "Epoch 41: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_41.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 43ms/step - accuracy: 0.7433 - loss: 0.6148 - val_accuracy: 0.7161 - val_loss: 0.8881\n",
            "Epoch 42/50\n",
            "\u001b[1m329/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7496 - loss: 0.5991\n",
            "Epoch 42: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_42.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 43ms/step - accuracy: 0.7495 - loss: 0.5991 - val_accuracy: 0.7096 - val_loss: 0.8199\n",
            "Epoch 43/50\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7471 - loss: 0.6065\n",
            "Epoch 43: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_43.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 42ms/step - accuracy: 0.7471 - loss: 0.6066 - val_accuracy: 0.7209 - val_loss: 0.8502\n",
            "Epoch 44/50\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7534 - loss: 0.6121\n",
            "Epoch 44: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_44.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 43ms/step - accuracy: 0.7534 - loss: 0.6121 - val_accuracy: 0.7114 - val_loss: 0.8444\n",
            "Epoch 45/50\n",
            "\u001b[1m329/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7462 - loss: 0.6069\n",
            "Epoch 45: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_45.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 43ms/step - accuracy: 0.7462 - loss: 0.6069 - val_accuracy: 0.7179 - val_loss: 0.8301\n",
            "Epoch 46/50\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7475 - loss: 0.6056\n",
            "Epoch 46: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_46.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 49ms/step - accuracy: 0.7475 - loss: 0.6056 - val_accuracy: 0.7304 - val_loss: 0.8615\n",
            "Epoch 47/50\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7539 - loss: 0.5965\n",
            "Epoch 47: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_47.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 43ms/step - accuracy: 0.7539 - loss: 0.5965 - val_accuracy: 0.7170 - val_loss: 0.8421\n",
            "Epoch 48/50\n",
            "\u001b[1m329/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7503 - loss: 0.5974\n",
            "Epoch 48: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_48.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 43ms/step - accuracy: 0.7503 - loss: 0.5974 - val_accuracy: 0.7179 - val_loss: 0.8241\n",
            "Epoch 49/50\n",
            "\u001b[1m329/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7492 - loss: 0.6045\n",
            "Epoch 49: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_49.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 42ms/step - accuracy: 0.7492 - loss: 0.6045 - val_accuracy: 0.7283 - val_loss: 0.8237\n",
            "Epoch 50/50\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7557 - loss: 0.5972\n",
            "Epoch 50: saving model to /content/drive/MyDrive/mtb_project/checkpoints/Session_01_epoch_50.keras\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 42ms/step - accuracy: 0.7557 - loss: 0.5972 - val_accuracy: 0.7252 - val_loss: 0.8899\n",
            "✅ Test-Accuracy für Session_01: 0.18\n",
            "\n",
            "Klassifikationsbericht:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Found input variables with inconsistent numbers of samples: [1997, 2311]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-c2fdafc1b0bd>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;31m# 🔍 Report berechnen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nKlassifikationsbericht:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     report_text = classification_report(\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0my_test_enc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0my_pred_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2670\u001b[0m     \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattach_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2671\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2673\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \"\"\"\n\u001b[1;32m     97\u001b[0m     \u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_namespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_pred\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1997, 2311]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(\"/content/drive/MyDrive/mtb_project/reports\", exist_ok=True)\n"
      ],
      "metadata": {
        "id": "VJz6n-8PZWui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🧾 Zusammenfassung nach dem Training:\n",
        "\n",
        "Nach der Schleife kannst du am Ende folgendes hinzufügen, um einen Bericht zu erzeugen:\n",
        "\n",
        "📊 Bonus: CSV speichern (optional)"
      ],
      "metadata": {
        "id": "G6M9hNEyTzn0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Durchschnittliche Accuracy über alle Sessions\n",
        "mean_acc = np.mean(all_accuracies)\n",
        "print(\"\\n📈 Zusammenfassung:\")\n",
        "for i, acc in enumerate(all_accuracies):\n",
        "    print(f\"  Session {i+1}: Accuracy = {acc:.2f}\")\n",
        "print(f\"\\n✅ Durchschnittliche Test-Accuracy über alle Sessions: {mean_acc:.2f}\")\n",
        "\n",
        "\n",
        "\n",
        "#📊 Bonus: CSV speichern (optional)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "summary = {'Session': [], 'Accuracy': []}\n",
        "for i, acc in enumerate(all_accuracies):\n",
        "    summary['Session'].append(f\"Session_{i+1}\")\n",
        "    summary['Accuracy'].append(acc)\n",
        "\n",
        "df_summary = pd.DataFrame(summary)\n",
        "df_summary.to_csv(\"session_accuracy_report.csv\", index=False)\n",
        "print(\"📁 Bericht gespeichert als session_accuracy_report.csv\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "g9eFJGGxTutz",
        "outputId": "7e0765df-5645-4ea0-ad23-c0b8026c998d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'all_accuracies' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-bb964def7d64>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Durchschnittliche Accuracy über alle Sessions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmean_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_accuracies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n📈 Zusammenfassung:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_accuracies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"  Session {i+1}: Accuracy = {acc:.2f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'all_accuracies' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#💾 II. Modell speichern & später wieder laden (z. B. nach Training)\n",
        "\n",
        "##🔐 Speichern mit TensorFlow/**Keras**"
      ],
      "metadata": {
        "id": "rbaE9UFeMQ8r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Nach dem Training:\n",
        "#speichert mit timestamp\n",
        "#model.save(\"SenseCap_Eventdetection_Model.keras\")  # speichert nur in colab kurzzeitig\n",
        "import time\n",
        "timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "model.save(f\"/content/drive/MyDrive/ML-MTB-Modell/ML-Model_trained/SenseCap_Model_v4_augment_{timestamp}.keras\")\n",
        "\n"
      ],
      "metadata": {
        "id": "9f0wu8rYM2P3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##🔄 Laden\n",
        "\n",
        "Das speichert das gesamte Modell inkl. Architektur, Gewichten und Optimizer-Zustand –exakt da weitermachen, wo man aufgehört hast."
      ],
      "metadata": {
        "id": "Fe6SLk39NNOz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model(\"/content/drive/MyDrive/ML-MTB-Modell/ML-Model_trained/SenseCap_Eventdetection_Model1.keras\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puTdBnHsNHsC",
        "outputId": "e01895fd-40b2-435b-a7f7-44950f5ebdf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 24 variables whereas the saved optimizer has 2 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_accuracies = []\n",
        "\n",
        "for i in range(len(test_sessions_X)):\n",
        "    X_test = test_sessions_X[i]\n",
        "    y_test = test_sessions_y[i]\n",
        "\n",
        "    _, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "    all_accuracies.append(acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "0FK9HYSaUOP0",
        "outputId": "0bb3586c-14d1-4009-e85c-573951307718"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'test_sessions_X' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-49eeb814a429>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mall_accuracies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sessions_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_sessions_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_sessions_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'test_sessions_X' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Durchschnittliche Accuracy über alle Sessions\n",
        "mean_acc = np.mean(all_accuracies)\n",
        "print(\"\\n📈 Zusammenfassung:\")\n",
        "for i, acc in enumerate(all_accuracies):\n",
        "    print(f\"  Session {i+1}: Accuracy = {acc:.2f}\")\n",
        "print(f\"\\n✅ Durchschnittliche Test-Accuracy über alle Sessions: {mean_acc:.2f}\")\n",
        "\n",
        "\n",
        "\n",
        "#📊 Bonus: CSV speichern (optional)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "summary = {'Session': [], 'Accuracy': []}\n",
        "for i, acc in enumerate(all_accuracies):\n",
        "    summary['Session'].append(f\"Session_{i+1}\")\n",
        "    summary['Accuracy'].append(acc)\n",
        "\n",
        "df_summary = pd.DataFrame(summary)\n",
        "df_summary.to_csv(\"session_accuracy_report.csv\", index=False)\n",
        "print(\"📁 Bericht gespeichert als session_accuracy_report.csv\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cce6369-7927-49d7-a612-51daac80c42b",
        "id": "p3xuxyPOUOsO"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📈 Zusammenfassung:\n",
            "\n",
            "✅ Durchschnittliche Test-Accuracy über alle Sessions: nan\n",
            "📁 Bericht gespeichert als session_accuracy_report.csv\n"
          ]
        }
      ]
    }
  ]
}